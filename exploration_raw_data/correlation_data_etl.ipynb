{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ce7c7-6cde-4c96-9c04-526e1394cb60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "from pprint import pformat\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import silhouette_score, make_scorer\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import fbeta_score\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"/workspace/correlation-change-predict/utils\")\n",
    "from utils import calc_corr_ser_property\n",
    "from gen_data import gen_corr_dist_mat\n",
    "from cluster_utils import (calc_silhouette_label_freq_std, hrchy_clustering_distance_threshold_rs, hrchy_clustering_n_cluster_gs,\n",
    "                           obs_hrchy_cluster_instances, hrchy_cluster_fixed_n_cluster, plot_cluster_labels_distribution)\n",
    "\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "data_config_path = current_dir / \"../config/data_config.yaml\"\n",
    "with open(data_config_path) as f:\n",
    "    data_cfg_yaml = dynamic_yaml.load(f)\n",
    "    data_cfg = yaml.full_load(dynamic_yaml.dump(data_cfg_yaml))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "matplotlib_logger = logging.getLogger(\"matplotlib\")\n",
    "matplotlib_logger.setLevel(logging.ERROR)\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# logger_list = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "# print(logger_list)\n",
    "\n",
    "# %load_ext pycodestyle_magic\n",
    "# %pycodestyle_on --ignore E501\n",
    "logging.debug(pformat(data_cfg, indent=1, width=100, compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651a732-13ea-40cc-b683-99fcec1ee8c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ac923-2662-45b3-aab2-46cd99bef517",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data implement & output setting & testset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8fbe48-0772-489a-acbc-c2c786050f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data implement setting\n",
    "data_implement = \"SP500_20082017\"  # watch options by printing /config/data_config.yaml/[\"DATASETS\"].keys()\n",
    "# print(data_cfg[\"DATASETS\"].keys())\n",
    "# etl set setting\n",
    "etl_items_setting = \"-train_all\"  # -train_train|-train_all\n",
    "# data split period setting, only suit for only settings of Korean paper\n",
    "data_split_setting = \"data_sp_test2\"\n",
    "# set CORR_WINDOW and CORR_STRIDE length\n",
    "w_l=50 ; s_l = 1\n",
    "# Decide how to calculate corr_ser\n",
    "corr_ser_clac_method = \"corr_ser_calc_regular\" # corr_ser_calc_regular|corr_ser_calc_abs\n",
    "# Decide composition of correlation_matrix\n",
    "corr_mat_compo = \"sim\"\n",
    "# Decide correlation series reduction method\n",
    "corr_ser_reduction_method = \"corr_ser_std\" # \"corr_ser_std\" | \"corr_ser_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46abb02-e668-4ebf-9c26-173323cef343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(data_cfg[\"DATASETS\"][data_implement]['FILE_PATH'])\n",
    "dataset_df = dataset_df.set_index('Date')\n",
    "all_set = list(dataset_df.columns)  # all data\n",
    "train_set = data_cfg[\"DATASETS\"][data_implement]['TRAIN_SET']\n",
    "test_set = data_cfg['DATASETS'][data_implement]['TEST_SET'] if data_cfg['DATASETS'][data_implement].get('TEST_SET') else [p for p in all_set if p not in train_set]  # all data - train data\n",
    "logging.info(f\"===== len(train_set): {len(train_set)}, len(all_set): {len(all_set)}, len(test_set): {len(test_set)} =====\")\n",
    "\n",
    "# test items implement settings\n",
    "items_implement = train_set if etl_items_setting == \"-train_train\" else all_set\n",
    "logging.info(f\"===== len(etl set): {len(items_implement)} =====\")\n",
    "\n",
    "# setting of name of output files and pictures title\n",
    "output_file_name = data_cfg[\"DATASETS\"][data_implement]['OUTPUT_FILE_NAME_BASIS'] + etl_items_setting\n",
    "fig_title = f\"{data_implement}{etl_items_setting}-{data_split_setting}\"\n",
    "logging.info(f\"===== file_name basis:{output_file_name}, fig_title basis:{fig_title} =====\")\n",
    "# display(dataset_df)\n",
    "\n",
    "# input folder settings\n",
    "corr_data_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/corr_data\"\n",
    "assert corr_data_dir.exists(), f\"\\nOperate data_module.py to generate correlation data first, operate command:\\n    python data_module.py --data_implement SP500_20082017 --train_items_setting -train_all --data_split_setting -data_sp_test2 --graph_mat_compo sim --save_corr_data\"\n",
    "\n",
    "# output folder settings\n",
    "res_dir = Path(f'./results/{output_file_name}/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}/{corr_mat_compo}')\n",
    "res_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d7485-bf75-440f-9232-c10ceab8f40d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load or Create Correlation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd4a41-0fbd-4918-90f3-c23d8d776005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_path = corr_data_dir/f\"corr_s{s_l}_w{w_l}_train.csv\"\n",
    "dev_df_path = corr_data_dir/f\"corr_s{s_l}_w{w_l}_dev.csv\"\n",
    "test1_df_path = corr_data_dir/f\"corr_s{s_l}_w{w_l}_test1.csv\"\n",
    "test2_df_path = corr_data_dir/f\"corr_s{s_l}_w{w_l}_test2.csv\"\n",
    "if data_split_setting == \"data_sp_train\":\n",
    "    df_path = train_df_path\n",
    "elif data_split_setting == \"data_sp_valid\":\n",
    "    df_path = dev_df_path\n",
    "elif data_split_setting == \"data_sp_test1\":\n",
    "    df_path = test1_df_path\n",
    "elif data_split_setting == \"data_sp_test2\":\n",
    "    df_path = test2_df_path\n",
    "corr_dataset = pd.read_csv(df_path, index_col=[\"items\"])\n",
    "logging.info(f\"corr_dataset.shape:{corr_dataset.shape}\")\n",
    "display(corr_dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2a8ce0-d589-4cb6-b585-ea7878c86946",
   "metadata": {},
   "source": [
    "# Observe correlation series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12b78e-5309-4a96-af09-0384f12bea08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_pair = \"EXR & RCL_0\"\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(corr_dataset.loc[item_pair, ::].T)\n",
    "plt.title(f\"{item_pair} with corr_s{s_l}_w{w_l}\", fontsize=20)\n",
    "plt.xticks(np.arange(0, corr_dataset.shape[1], 250), rotation=45)\n",
    "plt.show()\n",
    "plt.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48c13c-7752-4105-bd68-205b0763cbaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate properties of Corrlelation series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aca586-6ce7-4ff8-bc64-fc1b07d996f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if corr_ser_clac_method == \"corr_ser_calc_regular\":\n",
    "    corr_property_df_path = res_dir/f\"{output_file_name}-{data_split_setting}-corr_series_property.csv\"\n",
    "    corr_property_df = calc_corr_ser_property(corr_dataset=corr_dataset, corr_property_df_path=corr_property_df_path)\n",
    "elif corr_ser_clac_method == \"corr_ser_calc_abs\":\n",
    "    # calculate corr_property_df with abs(corr_dataset)\n",
    "    corr_property_df_path = res_dir/f\"{output_file_name}-{data_split_setting}-corr_series_abs_property.csv\"\n",
    "    corr_property_df = calc_corr_ser_property(corr_dataset=corr_dataset.abs(), corr_property_df_path=corr_property_df_path)\n",
    "\n",
    "corr_property_df_mean_reduct_series = corr_property_df.mean(axis=0)\n",
    "corr_property_df_mean_reduct_series.name = \"corr_property_df_mean_reduct_series\"\n",
    "corr_property_df_std_reduct_series = corr_property_df.std(axis=0)\n",
    "corr_property_df_std_reduct_series.name = \"corr_property_df_std_reduct_series\"\n",
    "\n",
    "logging.info(f\"{fig_title} + corr_w{w_l} + corr_s{s_l} + corr_ser_clac_method:{corr_ser_clac_method}\")\n",
    "logging.info(f\"Min of corr_ser_mean:{corr_property_df.loc[::,'corr_ser_mean'].min()}\")\n",
    "display(corr_property_df.head())\n",
    "print(\"=\"*50)\n",
    "display(corr_property_df_mean_reduct_series)\n",
    "print(\"=\"*50)\n",
    "display(corr_property_df_std_reduct_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b7022-6869-4990-bf4d-49bd97b239db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clustring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cf997-4986-4a35-b75c-f01fb2f659d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## calculate dissimilarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226fa6a-9702-46f7-a425-a88d79342b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_ser_std = corr_property_df.loc[::,\"corr_ser_std\"]\n",
    "corr_ser_mean = corr_property_df.loc[::,\"corr_ser_mean\"]\n",
    "corr_reduction_ser = corr_ser_std if corr_ser_reduction_method == \"corr_ser_std\" else corr_ser_mean\n",
    "selected_dataset_df = dataset_df.loc[::, items_implement]\n",
    "distance_mat = gen_corr_dist_mat(corr_reduction_ser, selected_dataset_df, out_mat_compo=corr_mat_compo)\n",
    "# test\n",
    "# test_stock_tickers = [\"ED\", \"BAC\", \"XEL\", \"MA\"]\n",
    "# test_distance_mat = distance_mat.loc[test_stock_tickers, test_stock_tickers]\n",
    "# display(test_distance_mat)  # comlpete: (ED, BAC), (XEL), (MA) -> (ED, BAC), (XEL, MA)  -> (ED, BAC, XEL, MA)\n",
    "#                             # single: (ED, BAC), (XEL), (MA) -> (ED, BAC, XEL), (MA)  -> (ED, BAC, XEL, MA)\n",
    "logging.info(f\"Min of distance_mat:{distance_mat.min()}\")\n",
    "display(distance_mat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61189a-728e-44d1-8ecb-8e42b0ca92fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## calculate cluster label for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a073dbd-cae4-4c0e-b6ab-b39c05329fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_hrchy_cluster_instances(distance_mat)\n",
    "num_clusters = 10  # Determin by observe result of obs_hrchy_cluster_instances()\n",
    "fixed_n_cluster_hrchy_cluster = hrchy_cluster_fixed_n_cluster(distance_mat, n=num_clusters)\n",
    "# distance_threshold_hrchy_cluster = hrchy_clustering_distance_threshold_rs(dissimilarity_mat, verbose=0)\n",
    "# n_cluster_hrchy_cluster = hrchy_clustering_n_cluster_gs(distance_mat, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63eab05-a4d7-416d-817d-118f83e0f32f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## plot cluster label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fbbb8-a060-4c7e-957d-ff8671151ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_cluster_labels_distribution(fixed_n_cluster_hrchy_cluster, cluster_name=f\"Hirerarchy clustering with {num_clusters} n_clusters\", fig_title=fig_title)\n",
    "# plot_cluster_labels_distribution(n_cluster_hrchy_cluster, \"Hirerarchy clustering with n_clusters\")\n",
    "# plot_cluster_labels_distribution(distance_threshold_hrchy_cluster, \"Hirerarchy clustering with distance threshold\")\n",
    "# print(hrchy_cluster_labels_df.loc[hrchy_cluster_labels_df[\"hrchy_cluster_label\"]==4, \"items\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc31dae-4ad5-4974-be50-6e99cbfedd09",
   "metadata": {},
   "source": [
    "## output cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d684cf2-abc2-44dd-bc3f-6579a2a6bffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_items_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/cluster/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}\"\n",
    "cluster_items_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if num_clusters:\n",
    "    output_cluster = fixed_n_cluster_hrchy_cluster  # the value of output_cluster depend on performance which shows in plot cluster label distribution\n",
    "    output_cluster_name = f\"corr_mat_hrchy_{num_clusters}_cluster\"\n",
    "\n",
    "hrchy_cluster_labels_df = pd.DataFrame(output_cluster.labels_, index=distance_mat.index, columns=[f\"{output_cluster_name}_label\"]).reset_index()\n",
    "hrchy_cluster_labels_df.to_csv(cluster_items_dir/f\"{output_cluster_name}.csv\")\n",
    "logging.info(f\"{output_cluster_name}.csv has been save to {cluster_items_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa1eaf-3921-4f56-9fe9-169e19c50f67",
   "metadata": {
    "tags": []
   },
   "source": [
    "# plot correlation coffecient distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8ab23-bd5c-4e24-92b5-a61c4fcea458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {'train_data--comb(150,2)': train_corr_series_concat, 'all_data--comb(445,2)': all_corr_series_concat, 'other_data--comb(295,2)': other_corr_series_concat}\n",
    "etl_types = [\"boxplot\", \"histogram\", \"qqplot\", \"Emprical Cumulative Density\"]\n",
    "fig, axes = plt.subplots(figsize=(20, 20),nrows=len(etl_types), ncols=len(datasets), sharex=False, sharey=False, dpi=100)\n",
    "\n",
    "for row, etl_type in enumerate(etl_types):\n",
    "    for col,dataset_key in enumerate(datasets):\n",
    "        # print(row, etl_type, col, dataset_key, datasets[dataset_key])\n",
    "        s = axes[row, col]\n",
    "        s.set_title(f\"{dataset_key}: \\n{etl_type}\", fontsize=24)\n",
    "        if etl_type==\"boxplot\":\n",
    "            s.boxplot(datasets[dataset_key], showmeans=True)\n",
    "        elif etl_type==\"histogram\":\n",
    "            s.hist(datasets[dataset_key], bins=[b/10 for b in range(-13,14)])\n",
    "        elif etl_type==\"qqplot\":\n",
    "            percents = [0.001, 0.2, 0.5, 0.8, 0.999]\n",
    "            #x,y = [norm.ppf(p) for p in percents], [np.quantile(train_corr_series_concat, p) for p in percents]\n",
    "            x,y = [norm.ppf(p) for p in percents], [np.quantile(datasets[dataset_key], p) for p in percents]\n",
    "            sm.qqplot(datasets[dataset_key], line='q', ax=s)\n",
    "            s.scatter(x,y, c='m', marker='x', s=300)\n",
    "        elif etl_type==\"Emprical Cumulative Density\":\n",
    "            pd.Series(datasets[dataset_key]).value_counts().sort_index().cumsum().plot(ax=s)\n",
    "\n",
    "# 分開, 避免子圖標籤互相重疊\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/dataset_exploration.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bdbb5-58e5-4529-bd8d-781395f18015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[dataset_key, datasets[dataset_key].std()] for dataset_key in datasets], \n",
    "                  columns=['Dataset', 'Standard deviation'])\n",
    "ax = sns.barplot(x='Dataset', y='Standard deviation', data=df)\n",
    "ax.set_title('std of correlation')\n",
    "ax.set(ylim=[0.47, 0.475])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xticks(rotation=60)\n",
    "plt.savefig(\"./results/dataset_exploration_2.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924fcc9-455d-42b1-b08f-ced180ce03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_corr_series_concat)\n",
    "# plt.hist(train_corr_series, bins=[b/10 for b in range(-13,14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e0835-ae6c-4cca-969b-e2e33f608f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr_series_df = gen_corr_series(None, \"train_dataset.csv\", from_file=True, concat_all=False)\n",
    "all_corr_series_df = gen_corr_series(None, \"445_dataset.csv\", from_file=True, concat_all=False)\n",
    "other_corr_series_df = gen_corr_series(None, \"295_dataset.csv\", from_file=True, concat_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5754944-5cd5-41f1-8c37-e607ba544e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {'train_data--comb(150,2)': train_corr_series_df, 'all_data--comb(445,2)': all_corr_series_df, 'other_data--comb(295,2)': other_corr_series_df}\n",
    "etl_types = [\"boxplot\", \"histogram\"]\n",
    "static_types = [\"mean\", \"std\"]\n",
    "fig, axes = plt.subplots(figsize=(30, 30),nrows=len(list(product(etl_types, static_types))), ncols=len(datasets), sharex=False, sharey=False, dpi=100)\n",
    "\n",
    "for row, (etl_type, static_type) in enumerate(product(etl_types, static_types)):\n",
    "    for col,dataset_key in enumerate(datasets):\n",
    "        s = axes[row, col]\n",
    "        s.set_title(f\"{dataset_key}: \\n{etl_type}_{static_type}\", fontsize=24)\n",
    "        if etl_type==\"boxplot\":\n",
    "            s.boxplot(datasets[dataset_key].iloc[:, ::5].describe().loc[static_type,:], showmeans=True)\n",
    "        elif etl_type==\"histogram\":\n",
    "            s.hist(datasets[dataset_key].iloc[:, ::5].describe().loc[static_type,:], bins=[b/10 for b in range(-13,14)])\n",
    "\n",
    "fig.suptitle(f\"Each correlation_series static property _20220718\", fontsize=24)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# 分開, 避免子圖標籤互相重疊\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"./results/dataset_exploration_3.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3beb76-3499-4905-96cc-4d208947a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_corr_series_df)\n",
    "display(train_corr_series_df.iloc[:,::5])\n",
    "display(train_corr_series_df.iloc[:,::5].describe())\n",
    "display(train_corr_series_df.iloc[:,::5].describe().loc['std',:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

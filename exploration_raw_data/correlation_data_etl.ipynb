{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28ce7c7-6cde-4c96-9c04-526e1394cb60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import logging\n",
    "from pprint import pformat\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import silhouette_score, make_scorer\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import fbeta_score\n",
    "import networkx as nx\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"/workspace/correlation-change-predict/utils\")\n",
    "from utils import calc_corr_ser_property\n",
    "from gen_corr_graph_data import gen_corr_dist_mat\n",
    "from cluster_utils import (calc_silhouette_label_freq_std, hrchy_clustering_distance_threshold_rs, hrchy_clustering_n_cluster_gs,\n",
    "                           obs_hrchy_cluster_instances, hrchy_cluster_fixed_n_cluster, filter_distance_mat, plot_cluster_labels_distribution, plot_dendrogram)\n",
    "\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "data_config_path = current_dir / \"../config/data_config.yaml\"\n",
    "with open(data_config_path) as f:\n",
    "    data_cfg_yaml = dynamic_yaml.load(f)\n",
    "    data_cfg = yaml.full_load(dynamic_yaml.dump(data_cfg_yaml))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "matplotlib_logger = logging.getLogger(\"matplotlib\")\n",
    "matplotlib_logger.setLevel(logging.ERROR)\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# logger_list = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "# print(logger_list)\n",
    "\n",
    "# %load_ext pycodestyle_magic\n",
    "# %pycodestyle_on --ignore E501\n",
    "logging.debug(pformat(data_cfg, indent=1, width=100, compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651a732-13ea-40cc-b683-99fcec1ee8c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ac923-2662-45b3-aab2-46cd99bef517",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data implement & output setting & testset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8fbe48-0772-489a-acbc-c2c786050f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data implement setting\n",
    "data_implement = \"SP500_20112015\"  # watch options by printing /config/data_config.yaml/[\"DATASETS\"].keys()\n",
    "# print(data_cfg[\"DATASETS\"].keys())\n",
    "# etl set setting\n",
    "etl_items_setting = \"-train_all\"  # -train_train|-train_all\n",
    "# data split period setting, only suit for only settings of Korean paper\n",
    "data_split_setting = \"data_sp_test2\"\n",
    "# set correlation type\n",
    "corr_type = \"pearson\"  # \"pearson\" | \"cross_corr\"\n",
    "# set CORR_WINDOW and CORR_STRIDE length\n",
    "w_l=50 ; s_l = 1\n",
    "# Decide how to calculate corr_ser\n",
    "corr_ser_clac_method = \"corr_ser_calc_regular\"  # corr_ser_calc_regular|corr_ser_calc_abs\n",
    "# Decide correlation series reduction method\n",
    "corr_ser_reduction_method = \"corr_ser_std\" # \"corr_ser_std\" | \"corr_ser_mean\"\n",
    "# Decide composition of correlation_matrix\n",
    "corr_mat_compo = \"sim\"\n",
    "# Decide how to filter distanc_mat\n",
    "filtered_distance_mat_method = \"negative_corr_ser_mean_filtered\"  # no_filtered|large_corr_ser_mean_filtered|small_corr_ser_mean_filtered|positive_corr_ser_mean_filtered|negative_corr_ser_mean_filtered\n",
    "# Decide whether save output or not\n",
    "is_save_output = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46abb02-e668-4ebf-9c26-173323cef343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(data_cfg[\"DATASETS\"][data_implement]['FILE_PATH'])\n",
    "dataset_df = dataset_df.set_index('Date')\n",
    "all_set = list(dataset_df.columns)  # all data\n",
    "train_set = data_cfg[\"DATASETS\"][data_implement]['TRAIN_SET']\n",
    "test_set = data_cfg['DATASETS'][data_implement]['TEST_SET'] if data_cfg['DATASETS'][data_implement].get('TEST_SET') else [p for p in all_set if p not in train_set]  # all data - train data\n",
    "logging.info(f\"===== len(train_set): {len(train_set)}, len(all_set): {len(all_set)}, len(test_set): {len(test_set)} =====\")\n",
    "\n",
    "# test items implement settings\n",
    "items_implement = train_set if etl_items_setting == \"-train_train\" else all_set\n",
    "logging.info(f\"===== len(etl set): {len(items_implement)} =====\")\n",
    "\n",
    "# setting of name of output files and pictures title\n",
    "output_file_name = data_cfg[\"DATASETS\"][data_implement]['OUTPUT_FILE_NAME_BASIS'] + etl_items_setting\n",
    "fig_title = f\"{data_implement}{etl_items_setting}-{data_split_setting}\"\n",
    "logging.info(f\"===== file_name basis:{output_file_name}, fig_title basis:{fig_title} =====\")\n",
    "# display(dataset_df)\n",
    "\n",
    "# input folder settings\n",
    "corr_data_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/{corr_type}/corr_data\"\n",
    "assert corr_data_dir.exists(), f\"\\nOperate data_module.py to generate correlation data first, operate command:\\n    python data_module.py --data_implement SP500_20082017 --train_items_setting -train_all --data_split_setting -data_sp_test2 --graph_mat_compo sim --save_corr_data\"\n",
    "\n",
    "# output folder settings\n",
    "res_dir= Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/{corr_type}/corr_property/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}\"\n",
    "cluster_items_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/{corr_type}/cluster/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}/{corr_ser_reduction_method}/{corr_mat_compo}/{filtered_distance_mat_method}\"\n",
    "res_dir.mkdir(parents=True, exist_ok=True)\n",
    "cluster_items_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d7485-bf75-440f-9232-c10ceab8f40d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load or Create Correlation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bd4a41-0fbd-4918-90f3-c23d8d776005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df_path = corr_data_dir/f\"corr_s{s_l}_w{w_l}_train.csv\"\n",
    "dev_df_path = corr_data_dir/f\"corr_s{s_l}_w{w_l}_dev.csv\"\n",
    "test1_df_path = corr_data_dir/f\"corr_s{s_l}_w{w_l}_test1.csv\"\n",
    "test2_df_path = corr_data_dir/f\"corr_s{s_l}_w{w_l}_test2.csv\"\n",
    "if data_split_setting == \"data_sp_train\":\n",
    "    df_path = train_df_path\n",
    "elif data_split_setting == \"data_sp_valid\":\n",
    "    df_path = dev_df_path\n",
    "elif data_split_setting == \"data_sp_test1\":\n",
    "    df_path = test1_df_path\n",
    "elif data_split_setting == \"data_sp_test2\":\n",
    "    df_path = test2_df_path\n",
    "corr_dataset = pd.read_csv(df_path, index_col=[\"items\"])\n",
    "logging.info(f\"corr_dataset.shape:{corr_dataset.shape}\")\n",
    "display(corr_dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a12b78e-5309-4a96-af09-0384f12bea08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "item_pair = \"EXR & RCL_0\"  #  set by chooing one of column `items` of `corr_dataset`\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(corr_dataset.loc[item_pair, ::].T)\n",
    "plt.title(f\"{item_pair} with corr_s{s_l}_w{w_l}\", fontsize=20)\n",
    "plt.xticks(np.arange(0, corr_dataset.shape[1], 250), rotation=45)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab48c13c-7752-4105-bd68-205b0763cbaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate properties of Corrlelation series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aca586-6ce7-4ff8-bc64-fc1b07d996f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if corr_ser_clac_method == \"corr_ser_calc_regular\":\n",
    "    corr_property_df_path = res_dir/f\"{output_file_name}-{data_split_setting}-corr_series_property.csv\"\n",
    "    corr_property_df = calc_corr_ser_property(corr_dataset=corr_dataset, corr_property_df_path=corr_property_df_path)\n",
    "elif corr_ser_clac_method == \"corr_ser_calc_abs\":\n",
    "    # calculate corr_property_df with abs(corr_dataset)\n",
    "    corr_property_df_path = res_dir/f\"{output_file_name}-{data_split_setting}-corr_series_abs_property.csv\"\n",
    "    corr_property_df = calc_corr_ser_property(corr_dataset=corr_dataset.abs(), corr_property_df_path=corr_property_df_path)\n",
    "\n",
    "corr_property_df_mean_reduct_series = corr_property_df.mean(axis=0)\n",
    "corr_property_df_mean_reduct_series.name = \"corr_property_df_mean_reduct_series\"\n",
    "corr_property_df_std_reduct_series = corr_property_df.std(axis=0)\n",
    "corr_property_df_std_reduct_series.name = \"corr_property_df_std_reduct_series\"\n",
    "\n",
    "logging.info(f\"{fig_title} + corr_w{w_l} + corr_s{s_l} + corr_ser_clac_method:{corr_ser_clac_method}\")\n",
    "logging.info(f\"Min of corr_ser_mean:{corr_property_df.loc[::,'corr_ser_mean'].min()}\")\n",
    "display(corr_property_df.head())\n",
    "print(\"=\"*50)\n",
    "display(corr_property_df_mean_reduct_series)\n",
    "print(\"=\"*50)\n",
    "display(corr_property_df_std_reduct_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde31acc-8272-4469-8fb1-57de88df8fb3",
   "metadata": {},
   "source": [
    "## plot distribution of all correlation of all item_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee793bf-b085-42e5-bab3-893de16b9ee4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=1)\n",
    "fig.set_size_inches(6, 10)\n",
    "all_item_pair_corrs = np.hstack(corr_dataset.values)\n",
    "axes[0].hist(all_item_pair_corrs, bins=20)\n",
    "axes[0].xaxis.set_tick_params(labelsize=18)\n",
    "axes[1].boxplot(all_item_pair_corrs)\n",
    "axes[1].yaxis.set_tick_params(labelsize=18)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1b7022-6869-4990-bf4d-49bd97b239db",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clustring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cf997-4986-4a35-b75c-f01fb2f659d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## calculate distance matrix and\n",
    "## output distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226fa6a-9702-46f7-a425-a88d79342b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr_ser_std = corr_property_df.loc[::, \"corr_ser_std\"]\n",
    "corr_ser_mean = corr_property_df.loc[::, \"corr_ser_mean\"]\n",
    "corr_reduction_ser = corr_ser_std if corr_ser_reduction_method == \"corr_ser_std\" else corr_ser_mean\n",
    "selected_dataset_df = dataset_df.loc[::, items_implement]\n",
    "distance_mat = gen_corr_dist_mat(corr_reduction_ser, selected_dataset_df, out_mat_compo=corr_mat_compo)\n",
    "corr_ser_mean_q2 = corr_property_df['corr_ser_mean'].quantile(0.5)\n",
    "filtered_distance_mat_settings = {\"large_corr_ser_mean_filtered\": ~(gen_corr_dist_mat(corr_ser_mean, selected_dataset_df, out_mat_compo=corr_mat_compo) > corr_ser_mean_q2),\n",
    "                                  \"small_corr_ser_mean_filtered\": ~(gen_corr_dist_mat(corr_ser_mean, selected_dataset_df, out_mat_compo=corr_mat_compo) < corr_ser_mean_q2),\n",
    "                                  \"positive_corr_ser_mean_filtered\": ~(gen_corr_dist_mat(corr_ser_mean, selected_dataset_df, out_mat_compo=corr_mat_compo) > 0),\n",
    "                                  \"negative_corr_ser_mean_filtered\": ~(gen_corr_dist_mat(corr_ser_mean, selected_dataset_df, out_mat_compo=corr_mat_compo) < 0)}\n",
    "\n",
    "filter_mask = filtered_distance_mat_settings.get(filtered_distance_mat_method)\n",
    "# print(distance_mat)\n",
    "# print(\"-\"*20)\n",
    "distance_mat, max_clique = filter_distance_mat(distance_mat, filter_mask, cluster_items_dir)\n",
    "# if (filter_mask := filtered_distance_mat_settings.get(filtered_distance_mat_method)) is not None:\n",
    "#     distance_mat[filter_mask] = 0\n",
    "#     G = nx.from_pandas_adjacency(distance_mat)\n",
    "#     max_clique = []\n",
    "#     for i, clique in enumerate(nx.find_cliques(G)):\n",
    "#         logging.info(f\"{i}th clique: {clique}\")\n",
    "#         if len(clique) > len(max_clique):\n",
    "#             max_clique = clique\n",
    "#             with open(cluster_items_dir/\"tmp_max_clique_nodes.txt\", \"w\") as f:\n",
    "#                 f.write(str(max_clique))\n",
    "#     distance_mat = distance_mat.loc[max_clique, max_clique]\n",
    "\n",
    "display(distance_mat.head())\n",
    "if is_save_output:\n",
    "    distance_mat.to_csv(cluster_items_dir/\"distance_mat.csv\")\n",
    "    logging.info(f\"distance_mat.csv has been save to {cluster_items_dir}\")\n",
    "    with open(cluster_items_dir/\"max_clique_nodes.txt\", \"w\") as f:\n",
    "        f.write(str(max_clique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6641df-0b7b-48de-beeb-e7a6e5b0e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "# test_stock_tickers = [\"ED\", \"BAC\", \"XEL\", \"MA\"]\n",
    "# test_distance_mat = distance_mat.loc[test_stock_tickers, test_stock_tickers]\n",
    "# display(test_distance_mat)  # comlpete: (ED, BAC), (XEL), (MA) -> (ED, BAC), (XEL, MA)  -> (ED, BAC, XEL, MA)\n",
    "#                             # single: (ED, BAC), (XEL), (MA) -> (ED, BAC, XEL), (MA)  -> (ED, BAC, XEL, MA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd61189a-728e-44d1-8ecb-8e42b0ca92fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## calculate cluster label for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a073dbd-cae4-4c0e-b6ab-b39c05329fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if distance_mat.shape[0] > 50:\n",
    "    obs_hrchy_cluster_instances(distance_mat)\n",
    "    num_clusters = 11  # Determin by observe result of obs_hrchy_cluster_instances()\n",
    "    fixed_n_cluster_hrchy_cluster = hrchy_cluster_fixed_n_cluster(distance_mat, n=num_clusters)\n",
    "# distance_threshold_hrchy_cluster = hrchy_clustering_distance_threshold_rs(dissimilarity_mat, verbose=0)\n",
    "# n_cluster_hrchy_cluster = hrchy_clustering_n_cluster_gs(distance_mat, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc31dae-4ad5-4974-be50-6e99cbfedd09",
   "metadata": {},
   "source": [
    "## output cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d684cf2-abc2-44dd-bc3f-6579a2a6bffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if locals().get('num_clusters'):\n",
    "    output_cluster = fixed_n_cluster_hrchy_cluster  # the value of output_cluster depend on performance which shows in plot cluster label distribution\n",
    "    output_cluster_name = f\"corr_mat_hrchy_{num_clusters}_cluster\"\n",
    "    hrchy_cluster_labels_df = pd.DataFrame(output_cluster.labels_, index=distance_mat.index, columns=[f\"{output_cluster_name}_label\"]).reset_index()\n",
    "    if is_save_output:\n",
    "        hrchy_cluster_labels_df.to_csv(cluster_items_dir/f\"{output_cluster_name}.csv\")\n",
    "        logging.info(f\"{output_cluster_name}.csv has been save to {cluster_items_dir}\")\n",
    "else:\n",
    "    no_cluster_df = pd.DataFrame(np.ones(distance_mat.shape[0]), index=distance_mat.index, columns=[\"no_cluter\"]).reset_index()\n",
    "    if is_save_output:\n",
    "        no_cluster_df.to_csv(cluster_items_dir/f\"no_cluster.csv\")\n",
    "        logging.info(f\"no_cluster.csv has been save to {cluster_items_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63eab05-a4d7-416d-817d-118f83e0f32f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## plot cluster info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6fbbb8-a060-4c7e-957d-ff8671151ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot cluster label distribution\n",
    "plot_cluster_labels_distribution(output_cluster, cluster_name=f\"Hirerarchy clustering with {num_clusters} n_clusters\", fig_title=fig_title, save_dir=cluster_items_dir)\n",
    "plot_dendrogram(output_cluster, truncate_mode=\"level\", p=4, save_dir=cluster_items_dir)\n",
    "\n",
    "hrchy_cluster_labels_df = hrchy_cluster_labels_df.set_index(\"items\") if \"items\" in hrchy_cluster_labels_df.columns else hrchy_cluster_labels_df\n",
    "for cluster_label in range(output_cluster.n_clusters_):\n",
    "    same_cluster_items = hrchy_cluster_labels_df.where(hrchy_cluster_labels_df == cluster_label).dropna(thresh=1).index\n",
    "    same_cluster_distance_mat = distance_mat.loc[same_cluster_items, same_cluster_items]\n",
    "    print(\"The distance_mat of cluster_{cluster_label}:\")\n",
    "    display(same_cluster_distance_mat)\n",
    "    if is_save_output:\n",
    "        same_cluster_distance_mat.to_csv(cluster_items_dir/f\"distance_mat-{output_cluster_name}-cluster_label_{cluster_label}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa1eaf-3921-4f56-9fe9-169e19c50f67",
   "metadata": {
    "tags": []
   },
   "source": [
    "# plot correlation coffecient distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f8ab23-bd5c-4e24-92b5-a61c4fcea458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {'train_data--comb(150,2)': train_corr_series_concat, 'all_data--comb(445,2)': all_corr_series_concat, 'other_data--comb(295,2)': other_corr_series_concat}\n",
    "etl_types = [\"boxplot\", \"histogram\", \"qqplot\", \"Emprical Cumulative Density\"]\n",
    "fig, axes = plt.subplots(figsize=(20, 20),nrows=len(etl_types), ncols=len(datasets), sharex=False, sharey=False, dpi=100)\n",
    "\n",
    "for row, etl_type in enumerate(etl_types):\n",
    "    for col,dataset_key in enumerate(datasets):\n",
    "        # print(row, etl_type, col, dataset_key, datasets[dataset_key])\n",
    "        s = axes[row, col]\n",
    "        s.set_title(f\"{dataset_key}: \\n{etl_type}\", fontsize=24)\n",
    "        if etl_type==\"boxplot\":\n",
    "            s.boxplot(datasets[dataset_key], showmeans=True)\n",
    "        elif etl_type==\"histogram\":\n",
    "            s.hist(datasets[dataset_key], bins=[b/10 for b in range(-13,14)])\n",
    "        elif etl_type==\"qqplot\":\n",
    "            percents = [0.001, 0.2, 0.5, 0.8, 0.999]\n",
    "            #x,y = [norm.ppf(p) for p in percents], [np.quantile(train_corr_series_concat, p) for p in percents]\n",
    "            x,y = [norm.ppf(p) for p in percents], [np.quantile(datasets[dataset_key], p) for p in percents]\n",
    "            sm.qqplot(datasets[dataset_key], line='q', ax=s)\n",
    "            s.scatter(x,y, c='m', marker='x', s=300)\n",
    "        elif etl_type==\"Emprical Cumulative Density\":\n",
    "            pd.Series(datasets[dataset_key]).value_counts().sort_index().cumsum().plot(ax=s)\n",
    "\n",
    "# 分開, 避免子圖標籤互相重疊\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./results/dataset_exploration.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5bdbb5-58e5-4529-bd8d-781395f18015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[dataset_key, datasets[dataset_key].std()] for dataset_key in datasets], \n",
    "                  columns=['Dataset', 'Standard deviation'])\n",
    "ax = sns.barplot(x='Dataset', y='Standard deviation', data=df)\n",
    "ax.set_title('std of correlation')\n",
    "ax.set(ylim=[0.47, 0.475])\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.xticks(rotation=60)\n",
    "plt.savefig(\"./results/dataset_exploration_2.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924fcc9-455d-42b1-b08f-ced180ce03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train_corr_series_concat)\n",
    "# plt.hist(train_corr_series, bins=[b/10 for b in range(-13,14)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e0835-ae6c-4cca-969b-e2e33f608f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr_series_df = gen_corr_series(None, \"train_dataset.csv\", from_file=True, concat_all=False)\n",
    "all_corr_series_df = gen_corr_series(None, \"445_dataset.csv\", from_file=True, concat_all=False)\n",
    "other_corr_series_df = gen_corr_series(None, \"295_dataset.csv\", from_file=True, concat_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5754944-5cd5-41f1-8c37-e607ba544e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets = {'train_data--comb(150,2)': train_corr_series_df, 'all_data--comb(445,2)': all_corr_series_df, 'other_data--comb(295,2)': other_corr_series_df}\n",
    "etl_types = [\"boxplot\", \"histogram\"]\n",
    "static_types = [\"mean\", \"std\"]\n",
    "fig, axes = plt.subplots(figsize=(30, 30),nrows=len(list(product(etl_types, static_types))), ncols=len(datasets), sharex=False, sharey=False, dpi=100)\n",
    "\n",
    "for row, (etl_type, static_type) in enumerate(product(etl_types, static_types)):\n",
    "    for col,dataset_key in enumerate(datasets):\n",
    "        s = axes[row, col]\n",
    "        s.set_title(f\"{dataset_key}: \\n{etl_type}_{static_type}\", fontsize=24)\n",
    "        if etl_type==\"boxplot\":\n",
    "            s.boxplot(datasets[dataset_key].iloc[:, ::5].describe().loc[static_type,:], showmeans=True)\n",
    "        elif etl_type==\"histogram\":\n",
    "            s.hist(datasets[dataset_key].iloc[:, ::5].describe().loc[static_type,:], bins=[b/10 for b in range(-13,14)])\n",
    "\n",
    "fig.suptitle(f\"Each correlation_series static property _20220718\", fontsize=24)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "# 分開, 避免子圖標籤互相重疊\n",
    "# plt.tight_layout()\n",
    "plt.savefig(\"./results/dataset_exploration_3.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3beb76-3499-4905-96cc-4d208947a5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(train_corr_series_df)\n",
    "display(train_corr_series_df.iloc[:,::5])\n",
    "display(train_corr_series_df.iloc[:,::5].describe())\n",
    "display(train_corr_series_df.iloc[:,::5].describe().loc['std',:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

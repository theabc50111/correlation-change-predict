{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50940a49-f60b-4b72-8931-545ba7e8b190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import logging\n",
    "from io import StringIO\n",
    "import pprint\n",
    "from pprint import pformat\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "# import wfdb\n",
    "\n",
    "sys.path.append(\"/workspace/correlation-change-predict/utils\")\n",
    "from utils import calc_corr_ser_property\n",
    "from gen_corr_graph_data import gen_corr_dist_mat\n",
    "\n",
    "with open('../config/data_config.yaml') as f:\n",
    "    data = dynamic_yaml.load(f)\n",
    "    data_cfg = yaml.full_load(dynamic_yaml.dump(data))\n",
    "\n",
    "output_buf = StringIO()\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "logging.debug(pformat(data_cfg, indent=1, width=100, compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb514b57-347a-4ba1-ac30-276699ab9fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# preprocess setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76bbd7-3b9e-4432-b8d6-29a2b5ce1b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_selection = True\n",
    "raw_file_dir = Path(data_cfg['DIRS']['DATASET_DIR'])/f\"raw_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9bb34-3692-4f7e-baa8-10adb602fceb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Randon pick items for trainset # Not always necessary to operate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047bdef-b21c-4b49-b024-6c8afc9fdba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_random_trainset(all_items: list, train_set_len: int = 100, verbose: int = 0):\n",
    "    random.seed(10)\n",
    "    train_set = sorted(random.sample(all_items, train_set_len))\n",
    "\n",
    "    if verbose==1:\n",
    "        print(f\"len(train_set):{len(train_set)}\")\n",
    "        pp = pprint.PrettyPrinter(width=500, compact=True)\n",
    "        pp.pprint(train_set)\n",
    "\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558af2d0-7c93-4d84-9121-1b38b9d4c145",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tetuan City power consumption Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfabc626-6ac4-4cd3-979c-5952703eecac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_file_name = 'Tetuan City power consumption.csv'\n",
    "file_name = 'tetuan_city_power_consumption.csv'\n",
    "raw_data = pd.read_csv(raw_file_dir/raw_file_name)\n",
    "raw_data['Date'] = pd.to_datetime(raw_data['Date'])\n",
    "raw_data = raw_data.set_index('Date')\n",
    "display(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c8ba6-119c-43e5-b339-1cec1c22b61b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b066e14-92f5-429d-b299-5c3158750fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_pre_df = raw_data.sort_values('Date')\n",
    "display(sort_pre_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ed99b-35cb-4ba6-8dea-5cbf262d1b6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba16aaa-a246-41d9-a03b-d58667e97378",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_mask = sort_pre_df.isna().sum() < len(raw_data)*0.01 # null values ratio==1%\n",
    "na_pre_df = sort_pre_df.iloc[::, na_mask.tolist()]\n",
    "na_pre_df = na_pre_df.fillna(method='ffill')\n",
    "na_pre_df = na_pre_df.fillna(method='bfill')\n",
    "if na_pre_df.isna().sum().sum() == 0:\n",
    "    output_df = na_pre_df\n",
    "else:\n",
    "    print(na_pre_df.iloc[::, (na_pre_df.isna().sum()>0).tolist()])\n",
    "    raise Exception(f'Still has {na_pre_df.isna().sum().sum()} null value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffad507-de76-4e6a-bdf4-8bde1e17a814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d4b2bd-ec51-4a32-a60c-1638936047ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_selection == True:\n",
    "    output_df = na_pre_df.iloc[::18, ::] # extract for every 3 hour\n",
    "    display(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bc077-42cd-4e4a-a3a5-e1e7e151391c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed70ae-93c1-47a1-860d-a43284fb6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(Path(raw_file_dir).parent/(str(Path(file_name).stem) + \"-pre\" + str(Path(file_name).suffix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990a845-d713-487e-b69d-89acd551aa78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Nvidia stock & Bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3433ed-426f-4bbb-85bb-1470e63e3197",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_file_name = 'bitcoin_20102022.csv'\n",
    "nvda_file_name = 'nvda_20102022.csv'\n",
    "file_name = \"bitcoin_nvda_20122022.csv\"\n",
    "bitcoin_raw_data = pd.read_csv(raw_file_dir/bitcoin_file_name)\n",
    "nvda_raw_data = pd.read_csv(raw_file_dir/nvda_file_name)\n",
    "bitcoin_raw_data['Date'] = pd.to_datetime(bitcoin_raw_data['Date'])\n",
    "nvda_raw_data['Date'] = pd.to_datetime(nvda_raw_data['Date'])\n",
    "\n",
    "raw_data = pd.merge(bitcoin_raw_data, nvda_raw_data, on=[\"Date\"], how=\"right\").set_index(\"Date\")\n",
    "\n",
    "logging.debug(f\"\\n {raw_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde43b18-e043-4681-87d8-6a4ea82375d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d958a57-9c30-47d2-bb99-0e95f659a4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sort_pre_df = raw_data.sort_values('Date')\n",
    "sort_pre_df.info(buf=output_buf)\n",
    "logging.debug(f\"\\n{sort_pre_df}\\n\" + \"=\"*50)\n",
    "logging.debug(f\"\\n{output_buf.getvalue()}\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71c71d-fc2f-48a3-9129-bcf916dac075",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67fdf1-d83b-4d4d-bed7-999d7b55cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if na exists\n",
    "logging.info(f\"\\n{sort_pre_df.isnull().any()}\\n\" + \"=\"*50)\n",
    "logging.info(f\"\\n{sort_pre_df.isnull().sum()}\\n\" + \"=\"*50)\n",
    "logging.info(f\"\\n{sort_pre_df.loc[raw_data.isnull().values, raw_data.isnull().any().values]}\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e3b662-a8bb-4770-b1a3-873a665fe719",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_mask = sort_pre_df.isna().sum() < len(raw_data)*0.01 # null values ratio==1%\n",
    "na_pre_df = sort_pre_df.iloc[::, na_mask.tolist()]\n",
    "na_pre_df = na_pre_df.fillna(method='ffill')\n",
    "na_pre_df = na_pre_df.fillna(method='bfill')\n",
    "if na_pre_df.isna().sum().sum() == 0:\n",
    "    output_df = na_pre_df\n",
    "else:\n",
    "    print(na_pre_df.iloc[::, (na_pre_df.isna().sum()>0).tolist()])\n",
    "    raise Exception(f'Still has {na_pre_df.isna().sum().sum()} null value')\n",
    "\n",
    "# test if na exists\n",
    "logging.info(f\"\\n{na_pre_df.isnull().any()}\\n\" + \"=\"*50)\n",
    "logging.info(f\"\\n{na_pre_df.isnull().sum()}\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7bdc4-2cbc-4be6-adc2-51994a8150d6",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3ff07-aebc-4305-890d-d72788c20597",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_selection == True:\n",
    "    output_df = na_pre_df.iloc[len(na_pre_df)-2519:, ::]\n",
    "    logging.info(f\"\\n{output_df}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eeb33c-52d5-4a16-bd27-9ae530a61d99",
   "metadata": {},
   "source": [
    "## Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abae538-9fd2-40a9-a76b-ff90862c8a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(Path(raw_file_dir).parent/(str(Path(file_name).stem) + \"_pre\" + str(Path(file_name).suffix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a677921-75f0-426c-ba0f-2e04864fd375",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Compute moving average of sp500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709ddcf8-5261-492c-8970-664668bc2679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T07:24:02.601309Z",
     "iopub.status.busy": "2023-07-23T07:24:02.600974Z",
     "iopub.status.idle": "2023-07-23T07:24:02.615436Z",
     "shell.execute_reply": "2023-07-23T07:24:02.614957Z",
     "shell.execute_reply.started": "2023-07-23T07:24:02.601281Z"
    },
    "tags": []
   },
   "source": [
    "## load sp500_hold_20082017-adj_close-pre.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c2ec41-7207-4849-baf2-8bff602ca6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp500_20082017_pre_file_name = Path(\"sp500_hold_20082017-adj_close-pre.csv\")\n",
    "sp500_20082017_df = pd.read_csv(raw_file_dir.parent/sp500_20082017_pre_file_name).set_index(\"Date\")\n",
    "sp500_20082017_tickers = set(sp500_20082017_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45d8ee-8079-4003-8457-b02280531300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(sp500_20082017_df)\n",
    "sp500_20082017_df.rolling(window=60, axis=0).mean()[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabde108-fe77-4d70-b0ad-56a0da32b186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f863fcc2-4752-408c-adbe-512aaf35f52f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Split sp500 by random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fca036-6753-431c-8e59-3fe6ae1e8d13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sp500_pre_file_name = Path(\"sp500_hold_20112015-adj_close-pre.csv\")\n",
    "sp500_df = pd.read_csv(raw_file_dir.parent/sp500_pre_file_name).set_index(\"Date\")\n",
    "sp500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a1b32-7e60-4959-9093-1e0c9982e411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_tickers = gen_random_trainset(list(sp500_20082017_df.columns), train_set_len=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41dc79e-69fb-48d4-b12b-a9aa7d7d3162",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Split sp500 constituent by GICS sector|sub_industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc4b563-163c-4f73-86af-b7d7022cb8ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Find number of tickers for each GICS_sector & GICS_sub_industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b78b0-85e5-4153-a34d-a64a91f32898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_name = \"sp500_constituent_gics.csv\"\n",
    "sp500_constituent_industry_df = pd.read_csv(raw_file_dir/file_name).set_index('Unnamed: 0')\n",
    "display(sp500_constituent_industry_df)\n",
    "display(sp500_constituent_industry_df.groupby(\"GICS_sector\")[\"ticker\"].count().sort_values(ascending=False))\n",
    "display(sp500_constituent_industry_df.groupby(\"GICS_sub_industry\")[\"ticker\"].count().sort_values(ascending=False))\n",
    "display(sp500_constituent_industry_df.groupby(\"GICS_sub_industry\")[\"ticker\"].count().sum())\n",
    "# display(sp500_constituent_industry_df.groupby(\"GICS_sector\")[\"ticker\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288c758-d672-4274-af51-d5148b4c5645",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering the tickers in `sp500_20082017-pre.csv` by GICS_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df5d7e-5c33-4743-8d74-22bdaf203fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_20082017_pre_file_name = Path(\"sp500_hold_20082017-adj_close-pre.csv\")\n",
    "sp500_20082017_df = pd.read_csv(raw_file_dir.parent/sp500_20082017_pre_file_name).set_index(\"Date\")\n",
    "consumer_discretionary_tickers = set(sp500_constituent_industry_df.loc[sp500_constituent_industry_df[\"GICS_sector\"]==\"Consumer Discretionary\", \"ticker\"])\n",
    "information_technology_tickers = set(sp500_constituent_industry_df.loc[sp500_constituent_industry_df[\"GICS_sector\"]==\"Information Technology\", \"ticker\"])\n",
    "financials_tickers = set(sp500_constituent_industry_df.loc[sp500_constituent_industry_df[\"GICS_sector\"]==\"Financials\", \"ticker\"])\n",
    "sp500_20082017_tickers = set(sp500_20082017_df.columns)\n",
    "sp500_20082017_consumer_discretionary_tickers = sp500_20082017_tickers.intersection(consumer_discretionary_tickers)\n",
    "sp500_20082017_information_technology_tickers = sp500_20082017_tickers.intersection(information_technology_tickers)\n",
    "sp500_20082017_financials_tickers = sp500_20082017_tickers.intersection(financials_tickers)\n",
    "logging.info(f\"consumer_discretionary_tickers in sp500: {len(consumer_discretionary_tickers)}, consumer_discretionary_tickers in sp500_pre {len(sp500_20082017_consumer_discretionary_tickers)}\")\n",
    "logging.info(f\"information_technology_tickers in sp500: {len(information_technology_tickers)}, information_technology_tickers in sp500_pre {len(sp500_20082017_information_technology_tickers)}\")\n",
    "logging.info(f\"financials_tickers in sp500: {len(financials_tickers)}, financials_tickers in sp500_pre {len(sp500_20082017_financials_tickers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49a9bb-fe20-4497-a03f-bb7c6cfddb9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3566d6-fdd7-4f43-9ce1-9feb9ac5f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_20082017_consumer_discretionary_df = sp500_20082017_df.loc[:, list(sp500_20082017_consumer_discretionary_tickers)]\n",
    "output_df = sp500_20082017_consumer_discretionary_df\n",
    "file_name = sp500_20082017_pre_file_name\n",
    "output_df.to_csv(Path(raw_file_dir).parent/(str(Path(file_name).stem).replace(\"-pre\", \"\") + \"-consumDiscretionary-pre\" + str(Path(file_name).suffix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9812c5a3-2aac-41f0-9ba6-84f8180e3251",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Split sp500 constituent by hierarchy clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad977f7e-55e0-416f-a7d2-7e94a03b502b",
   "metadata": {},
   "source": [
    "## Load cluster results and preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871bbdb3-136d-4da1-8f1d-30d6a42b2c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Watch the section \"## Data implement & output setting & testset setting\" of correlation_dat_etl.ipynb\n",
    "cluster_results_dir_base = \"sp500_20112015-train_all\"\n",
    "corr_type = \"pearson\"\n",
    "# window_setting = \"corr_s1_w50\"\n",
    "s_l = 1\n",
    "w_l = 50\n",
    "corr_ser_clac_method = \"corr_ser_calc_regular\"\n",
    "corr_ser_reduction_method = \"corr_ser_std\"\n",
    "corr_mat_compo = \"sim\"\n",
    "filtered_distance_mat_method = \"large_corr_ser_mean_filtered\"\n",
    "is_save_output = False\n",
    "\n",
    "cluster_results_dir = Path(data_cfg[\"DIRS\"]['PIPELINE_DATA_DIR'])/f\"{cluster_results_dir_base}/{corr_type}/cluster/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}/{corr_ser_reduction_method}/{corr_mat_compo}/{filtered_distance_mat_method}\"\n",
    "cluster_results_file_name = Path(\"corr_mat_hrchy_6_cluster.csv\")  # change this file if there is any better cluster results\n",
    "cluster_results_df = pd.read_csv(cluster_results_dir/cluster_results_file_name, index_col=\"Unnamed: 0\")\n",
    "cluster_label_col_name = cluster_results_file_name.stem+\"_label\"  # check label_col_name by cluster_results_df.columns\n",
    "\n",
    "sp500_pre_file_name = Path(\"sp500_hold_20112015-adj_close-pre.csv\")\n",
    "sp500_df = pd.read_csv(raw_file_dir.parent/sp500_pre_file_name).set_index(\"Date\")\n",
    "sp500_tickers = set(sp500_df.columns)\n",
    "display(sp500_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e254f-7fd1-4d48-af88-4b2ac8dd0e5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Find tickers with cluster label that have many nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b9e83-6710-4f9e-8197-dc7aa0067f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_labels_count_df = cluster_results_df.groupby([cluster_label_col_name]).count().sort_values(\"items\", ascending=False)\n",
    "num_clusters = cluster_labels_count_df.shape[0]\n",
    "frequent_cluster_info = {}\n",
    "for i, (cluster_label, num_nodes) in enumerate(cluster_labels_count_df.iterrows(), start=1):\n",
    "    if i < num_clusters:\n",
    "        frequent_cluster_info.update({f\"frequent_cluster_{i}th\": {\"cluster_label\": cluster_label, \"num_nodes\": num_nodes[0]}})\n",
    "    else:\n",
    "        frequent_cluster_info.update({f\"frequent_cluster_last\": {\"cluster_label\": cluster_label, \"num_nodes\": num_nodes[0]}})\n",
    "\n",
    "all_mix_cluster_df = cluster_results_df.groupby([cluster_label_col_name]).apply(lambda x: x.sample(n=1, random_state=0)).reset_index(drop=True)\n",
    "frequent_cluster_info.update({f\"frequent_cluster_all_mix\": {\"cluster_labels\": all_mix_cluster_df.loc[::, cluster_label_col_name].tolist(), \"num_nodes\": len(all_mix_cluster_df)}})\n",
    "\n",
    "mix_target_label = frequent_cluster_info['frequent_cluster_last']['cluster_label']\n",
    "not_target_mask = all_mix_cluster_df.loc[::,cluster_label_col_name]!=mix_target_label\n",
    "sameple_not_target_df = all_mix_cluster_df.loc[not_target_mask].sample(n=5, random_state=0)\n",
    "sample_target_df = cluster_results_df.loc[cluster_results_df[cluster_label_col_name]==mix_target_label, ::].sample(n=5, random_state=0)\n",
    "half_mix_cluster_df = pd.concat([sameple_not_target_df, sample_target_df])\n",
    "frequent_cluster_info.update({f\"frequent_cluster_half_mix\": {\"cluster_labels\": half_mix_cluster_df.loc[::, cluster_label_col_name].unique().tolist(), \"num_nodes\": len(half_mix_cluster_df)}})\n",
    "\n",
    "logging.info(f\"frequent_cluster_1th[cluster_label]: 【{frequent_cluster_info['frequent_cluster_1th']['cluster_label']}】, quantity of nodes with frequent_cluster_label_1th: {frequent_cluster_info['frequent_cluster_1th']['num_nodes']}\")\n",
    "logging.info(f\"frequent_cluster_2th[cluster_label]: 【{frequent_cluster_info['frequent_cluster_2th']['cluster_label']}】, quantity of nodes with frequent_cluster_label_2th: {frequent_cluster_info['frequent_cluster_2th']['num_nodes']}\")\n",
    "logging.info(f\"frequent_cluster_last[cluster_label]: 【{frequent_cluster_info['frequent_cluster_last']['cluster_label']}】, quantity of nodes with frequent_cluster_label_last: {frequent_cluster_info['frequent_cluster_last']['num_nodes']}\")\n",
    "logging.info(f\"frequent_cluster_all_mix[cluster_labels]: 【{frequent_cluster_info['frequent_cluster_all_mix']['cluster_labels']}】, quantity of nodes with frequent_cluster_all_mix: {frequent_cluster_info['frequent_cluster_all_mix']['num_nodes']}\")\n",
    "logging.info(f\"frequent_cluster_half_mix[cluster_labels]: 【{frequent_cluster_info['frequent_cluster_half_mix']['cluster_labels']}】, quantity of nodes with frequent_cluster_half_mix: {frequent_cluster_info['frequent_cluster_half_mix']['num_nodes']}\")\n",
    "display(\"cluster_results_df.head():\")\n",
    "display(cluster_results_df.head())\n",
    "display(\"cluster_labels_count_df:\")\n",
    "display(cluster_labels_count_df)\n",
    "display(\"all_mix_cluster_df:\")\n",
    "display(all_mix_cluster_df)\n",
    "display(\"half_mix_cluster_df:\")\n",
    "display(half_mix_cluster_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71260a1d-0478-4359-a569-6754cab8e11e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtering the tickers in `sp500_xxx-pre.csv` by tickers with cluster label that have many nodes and\n",
    "## Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe308716-33ca-475d-9ffe-f45aa9e38425",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_file_name = str(Path(sp500_pre_file_name).stem)\n",
    "save_dir = Path(raw_file_dir).parent/f\"{(src_file_name+'-extension')}/{corr_type}/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}/{corr_ser_reduction_method}/{corr_mat_compo}/{filtered_distance_mat_method}\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for frequent_cluster in frequent_cluster_info:\n",
    "    info = frequent_cluster_info[frequent_cluster]\n",
    "    if \"mix\" not in frequent_cluster:\n",
    "        all_tickers = cluster_results_df.loc[cluster_results_df[cluster_label_col_name]==info['cluster_label'], \"items\"]\n",
    "    elif \"all_mix\" in frequent_cluster:\n",
    "        all_tickers = all_mix_cluster_df.loc[::, \"items\"]\n",
    "    elif \"half_mix\" in frequent_cluster:\n",
    "        all_tickers = half_mix_cluster_df.loc[::, \"items\"]\n",
    "    assert len(sp500_tickers.intersection(all_tickers)) == len(all_tickers), \"The tickers of frequnt_cluster should contains in sp500 data, but it's not\"\n",
    "    frequent_cluster_info[frequent_cluster].update({\"tickers\": set(all_tickers)})\n",
    "    output_df = sp500_df.loc[:, list(all_tickers)]\n",
    "    freq_rank = frequent_cluster.replace(\"frequent_cluster_\", \"\")\n",
    "    file_name = cluster_results_file_name.stem+f\"_label_{freq_rank}-pre.csv\"\n",
    "    logging.info(f\"cluster name: {frequent_cluster}, len of tickers: {len(all_tickers)}\")\n",
    "    if is_save_output:\n",
    "        output_df.to_csv(save_dir/file_name)\n",
    "        logging.info(f\"{file_name} has been save to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c90d8b0-8aba-4a37-bb9a-87451151a5bf",
   "metadata": {},
   "source": [
    "## Randon pick items for trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b051c-20e6-444e-8845-bb2bebd32497",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selected_tickers = frequent_cluster_info[\"frequent_cluster_last\"][\"tickers\"]\n",
    "sample_df = gen_random_trainset(list(selected_tickers), train_set_len=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369b1410-e7c9-42df-86fe-eedf7be6e100",
   "metadata": {},
   "source": [
    "## Plot info of trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef585d-61b5-466f-9bef-badad092c94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distance matrix of `sample_df`\n",
    "distance_mat = pd.read_csv(cluster_results_dir/\"distance_mat.csv\", index_col=[\"items\"])\n",
    "# Observe other types of distance matrix\n",
    "data_implement = \"SP500_20112015\"  # watch options by printing /config/data_config.yaml/[\"DATASETS\"].keys()\n",
    "etl_items_setting = \"-train_all\"  # -train_train|-train_all\n",
    "# data split period setting, only suit for only settings of Korean paper\n",
    "data_split_setting = \"data_sp_test2\"\n",
    "dataset_df = pd.read_csv(data_cfg[\"DATASETS\"][data_implement]['FILE_PATH'])\n",
    "dataset_df = dataset_df.set_index('Date')\n",
    "all_set = list(dataset_df.columns)  # all data\n",
    "train_set = data_cfg[\"DATASETS\"][data_implement]['TRAIN_SET']\n",
    "# test items implement settings\n",
    "items_implement = train_set if etl_items_setting == \"-train_train\" else all_set\n",
    "output_file_name = data_cfg[\"DATASETS\"][data_implement]['OUTPUT_FILE_NAME_BASIS'] + etl_items_setting\n",
    "etl_res_dir= Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/{corr_type}/corr_property/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}\"\n",
    "if corr_ser_clac_method == \"corr_ser_calc_regular\":\n",
    "    corr_property_df_path = etl_res_dir/f\"{output_file_name}-{data_split_setting}-corr_series_property.csv\"\n",
    "elif corr_ser_clac_method == \"corr_ser_calc_abs\":\n",
    "    # calculate corr_property_df with abs(corr_dataset)\n",
    "    corr_property_df_path = etl_res_dir/f\"{output_file_name}-{data_split_setting}-corr_series_abs_property.csv\"\n",
    "corr_property_df = pd.read_csv(corr_property_df_path).set_index(\"items\")\n",
    "corr_ser_std = corr_property_df.loc[::, \"corr_ser_std\"]\n",
    "corr_ser_mean = corr_property_df.loc[::, \"corr_ser_mean\"]\n",
    "selected_dataset_df = dataset_df.loc[::, items_implement]\n",
    "obs_distance_mat_mean = gen_corr_dist_mat(corr_ser_mean, selected_dataset_df, out_mat_compo=corr_mat_compo).loc[sample_df, sample_df]\n",
    "obs_distance_mat_std = gen_corr_dist_mat(corr_ser_std, selected_dataset_df, out_mat_compo=corr_mat_compo).loc[sample_df, sample_df]\n",
    "obs_distance_mat_mean = obs_distance_mat_mean.style.set_caption(\"distance_mat_mean\").set_table_styles([{'selector': 'caption',\n",
    "                                                                                                        'props': [('color', 'red'),\n",
    "                                                                                                                  ('font-size', '24px')]}])\n",
    "obs_distance_mat_std = obs_distance_mat_std.style.set_caption(\"distance_mat_std\").set_table_styles([{'selector': 'caption',\n",
    "                                                                                                     'props': [('color', 'red'),\n",
    "                                                                                                               ('font-size', '24px')]}])\n",
    "\n",
    "\n",
    "# If items are constituent, observe their GICS sector|sub_industry\n",
    "obs_items = sample_df\n",
    "gics_df = pd.read_csv(Path(data_cfg[\"DIRS\"][\"DATASET_DIR\"])/\"raw_data/sp500_constituent_gics.csv\")\n",
    "mask = gics_df.loc[::, \"ticker\"].isin(obs_items)\n",
    "\n",
    "\n",
    "display(distance_mat.loc[sample_df, sample_df])\n",
    "display(obs_distance_mat_mean)\n",
    "display(obs_distance_mat_std)\n",
    "display(gics_df.iloc[mask.tolist(), ::])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f01e2-bdac-4728-8778-360c9cbbcbe2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Split sp500 constituent by filter and max_clique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288be7a-fc16-4784-91f6-3d3f19e5df13",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2924f134-1004-42db-84a5-1d25de9f1665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Watch the section \"## Data implement & output setting & testset setting\" of correlation_dat_etl.ipynb\n",
    "filter_clique_results_dir_base = \"sp500_20112015-train_all\"\n",
    "corr_type = \"pearson\"\n",
    "# window_setting = \"corr_s1_w50\"\n",
    "s_l = 1\n",
    "w_l = 50\n",
    "corr_ser_clac_method = \"corr_ser_calc_regular\"\n",
    "corr_ser_reduction_method = \"corr_ser_std\"\n",
    "corr_mat_compo = \"sim\"\n",
    "filtered_distance_mat_method = \"negative_corr_ser_mean_filtered\"\n",
    "is_save_output = False\n",
    "\n",
    "filter_clique_results_dir = Path(data_cfg[\"DIRS\"]['PIPELINE_DATA_DIR'])/f\"{filter_clique_results_dir_base}/{corr_type}/cluster/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}/{corr_ser_reduction_method}/{corr_mat_compo}/{filtered_distance_mat_method}\"\n",
    "filter_clique_results_file_name = Path(\"no_cluster.csv\")  # change this file if there is any better filter_clique results\n",
    "filter_clique_results_df = pd.read_csv(filter_clique_results_dir/filter_clique_results_file_name, index_col=\"Unnamed: 0\")\n",
    "# filter_clique_label_col_name = filter_clique_results_file_name.stem+\"_label\"  # check label_col_name by filter_clique_results_df.columns\n",
    "\n",
    "sp500_pre_file_name = Path(\"sp500_hold_20112015-adj_close-pre.csv\")\n",
    "sp500_df = pd.read_csv(raw_file_dir.parent/sp500_pre_file_name).set_index(\"Date\")\n",
    "sp500_tickers = set(sp500_df.columns)\n",
    "display(sp500_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed3c4ad-1202-48ff-b37c-c75fe70c72f1",
   "metadata": {},
   "source": [
    "## Filtering the tickers in `sp500_xxx-pre.csv` by tickers with `filter_clique_results_df` and\n",
    "## Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368a283c-23bb-470d-9296-ab59cb1a8a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_file_name = str(Path(sp500_pre_file_name).stem)\n",
    "save_dir = Path(raw_file_dir).parent/f\"{(src_file_name+'-extension')}/{corr_type}/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}/{corr_ser_reduction_method}/{corr_mat_compo}/{filtered_distance_mat_method}\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "all_tickers = filter_clique_results_df.loc[::, \"items\"]\n",
    "output_df = sp500_df.loc[:, list(all_tickers)]\n",
    "file_name = filter_clique_results_file_name.stem+\"-pre.csv\"\n",
    "logging.info(f\"len of tickers: {len(all_tickers)}\")\n",
    "if is_save_output:\n",
    "    output_df.to_csv(save_dir/file_name)\n",
    "    logging.info(f\"{file_name} has been save to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494587b-84ea-43fb-9b35-246dbf8782a4",
   "metadata": {},
   "source": [
    "## Show items for trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb77b4-5baf-4a06-8070-60bddcd8e545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_df = all_tickers.tolist()\n",
    "print(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb8fdc-f54c-48cc-82bf-7f8d02699659",
   "metadata": {},
   "source": [
    "## Plot info of trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30bfe32-46b1-43df-9a1e-a137152bf3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the distance matrix of `sample_df`\n",
    "distance_mat = pd.read_csv(filter_clique_results_dir/\"distance_mat.csv\", index_col=[\"items\"])\n",
    "# Observe other types of distance matrix\n",
    "data_implement = \"SP500_20112015\"  # watch options by printing /config/data_config.yaml/[\"DATASETS\"].keys()\n",
    "etl_items_setting = \"-train_all\"  # -train_train|-train_all\n",
    "# data split period setting, only suit for only settings of Korean paper\n",
    "data_split_setting = \"data_sp_test2\"\n",
    "dataset_df = pd.read_csv(data_cfg[\"DATASETS\"][data_implement]['FILE_PATH'])\n",
    "dataset_df = dataset_df.set_index('Date')\n",
    "all_set = list(dataset_df.columns)  # all data\n",
    "train_set = data_cfg[\"DATASETS\"][data_implement]['TRAIN_SET']\n",
    "# test items implement settings\n",
    "items_implement = train_set if etl_items_setting == \"-train_train\" else all_set\n",
    "output_file_name = data_cfg[\"DATASETS\"][data_implement]['OUTPUT_FILE_NAME_BASIS'] + etl_items_setting\n",
    "etl_res_dir= Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/{corr_type}/corr_property/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}\"\n",
    "if corr_ser_clac_method == \"corr_ser_calc_regular\":\n",
    "    corr_property_df_path = etl_res_dir/f\"{output_file_name}-{data_split_setting}-corr_series_property.csv\"\n",
    "elif corr_ser_clac_method == \"corr_ser_calc_abs\":\n",
    "    # calculate corr_property_df with abs(corr_dataset)\n",
    "    corr_property_df_path = etl_res_dir/f\"{output_file_name}-{data_split_setting}-corr_series_abs_property.csv\"\n",
    "corr_property_df = pd.read_csv(corr_property_df_path).set_index(\"items\")\n",
    "corr_ser_std = corr_property_df.loc[::, \"corr_ser_std\"]\n",
    "corr_ser_mean = corr_property_df.loc[::, \"corr_ser_mean\"]\n",
    "selected_dataset_df = dataset_df.loc[::, items_implement]\n",
    "obs_distance_mat_mean = gen_corr_dist_mat(corr_ser_mean, selected_dataset_df, out_mat_compo=corr_mat_compo).loc[sample_df, sample_df]\n",
    "obs_distance_mat_std = gen_corr_dist_mat(corr_ser_std, selected_dataset_df, out_mat_compo=corr_mat_compo).loc[sample_df, sample_df]\n",
    "obs_distance_mat_mean = obs_distance_mat_mean.style.set_caption(\"distance_mat_mean\").set_table_styles([{'selector': 'caption',\n",
    "                                                                                                        'props': [('color', 'red'),\n",
    "                                                                                                                  ('font-size', '24px')]}])\n",
    "obs_distance_mat_std = obs_distance_mat_std.style.set_caption(\"distance_mat_std\").set_table_styles([{'selector': 'caption',\n",
    "                                                                                                     'props': [('color', 'red'),\n",
    "                                                                                                               ('font-size', '24px')]}])\n",
    "\n",
    "# If items are constituent, observe their GICS sector|sub_industry\n",
    "obs_items = sample_df\n",
    "gics_df = pd.read_csv(Path(data_cfg[\"DIRS\"][\"DATASET_DIR\"])/\"raw_data/sp500_constituent_gics.csv\")\n",
    "mask = gics_df.loc[::, \"ticker\"].isin(obs_items)\n",
    "\n",
    "display(distance_mat.loc[sample_df, sample_df])\n",
    "display(obs_distance_mat_mean)\n",
    "display(obs_distance_mat_std)\n",
    "display(gics_df.iloc[mask.tolist(), ::])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3614381-c47a-4eb5-89d7-0747428dfbc2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f393a51-9d67-44bc-bafa-da12555cf7cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "synthetic_set = \"pw_constant\"\n",
    "dim = 70  # time_length(number of samples), number of variables(dimension)\n",
    "n_bkps, noise_std = 0, 10  # number of change points, noise standart deviation\n",
    "syn_file_name = Path(f\"{synthetic_set}-bkps{n_bkps}-noise_std{noise_std}.csv\")\n",
    "syn_df = pd.read_csv(raw_file_dir.parent/f\"synthetic/dim{dim}\"/syn_file_name).set_index(\"Date\")\n",
    "\n",
    "syn_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3500a9d-87a8-463a-a093-e4d77718b7ae",
   "metadata": {},
   "source": [
    "## Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270aa5f7-e2c0-4c74-92b8-09709f9eee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_results_dir = Path(data_cfg[\"DIRS\"]['PIPELINE_DATA_DIR'])/f\"sp500_20082017-train_all/cluster/corr_s1_w50/corr_ser_calc_regular\"\n",
    "cluster_results_file_name = Path(\"corr_mat_hrchy_10_cluster.csv\")  # change this file if there is any better cluster results\n",
    "cluster_results_df = pd.read_csv(cluster_results_dir/cluster_results_file_name, index_col=\"Unnamed: 0\")\n",
    "save_dir = Path(raw_file_dir).parent/f\"{src_file_name}/corr_s{s_l}_w{w_l}/{corr_ser_clac_method}/{corr_mat_compo}/{corr_ser_reduction_method}\"\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_df.to_csv(save_dir/file_name)\n",
    "logging.info(f\"{file_name} has been save to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa0821-5aca-400f-9fe8-86bbe935eed1",
   "metadata": {},
   "source": [
    "## Randon pick items for trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e9463-3aa0-422d-ac93-26236da16676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_train_set = sorted(gen_random_trainset(syn_df.columns.tolist(), train_set_len=60, verbose=1), key=lambda x:int(x.split(\"_\")[1]))\n",
    "print(sample_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d44cb-5236-43b2-9466-d3e61c72c2b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Mimic Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade71fee-a4b0-4751-bc2c-10087d40ce40",
   "metadata": {},
   "source": [
    "## visulization all patients' signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f189fe4-9632-4ffc-9ec3-9f97b8820426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerics_folder = Path(raw_file_dir/\"mimic-database-1.0.0\"/\"numerics\")\n",
    "numerics_files = [f.stem for f in numerics_folder.iterdir()]\n",
    "ignored_files = {\"HEADER\", \"ANNOTATORS\", \"RECORDS\", \".htaccess\", \".ipynb_checkpoints\"}\n",
    "records = sorted(set(numerics_files) - ignored_files)\n",
    "for i,rec in enumerate(records):\n",
    "    record = wfdb.rdrecord(numerics_folder/rec)\n",
    "    wfdb.plot_wfdb(record=record, title=f'{record.record_name}', figsize=(20, 20), sharex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a3f5d3-dbd4-436f-8752-68ec1f0e47e3",
   "metadata": {},
   "source": [
    "## visulization specific signal & time-period & annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cad692-e0fb-4328-a496-261790ad7b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "record_252n_abp = wfdb.rdrecord(numerics_folder/\"252n\", channels=[1,2], sampfrom=8000, sampto=9500)\n",
    "# display(record_252n_abp record_252n.__dict__)\n",
    "wfdb.plot_items(signal=record_252n_abp.p_signal, sig_name=record_252n_abp.sig_name, sig_units=record_252n_abp.units, title=f'{record_252n_abp.record_name}', figsize=(20, 8), sharex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720f15a-83a7-4a0d-aa55-b79ab3791c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics_folder = Path(raw_file_dir/\"mimic-database-1.0.0\"/\"numerics\")\n",
    "record_252n = wfdb.rdrecord(numerics_folder/\"252n\")\n",
    "ann_patient = wfdb.rdann(str(numerics_folder/\"252n\"), 'al', summarize_labels=True)  # al patient alarms\n",
    "ann_monitor = wfdb.rdann(str(numerics_folder/\"252n\"), 'in', summarize_labels=True)  # in monitor status alarms\n",
    "display(len(record_252n.p_signal))\n",
    "\n",
    "record_252n_fig = wfdb.plot_wfdb(record=record_252n, title=f'{record_252n.record_name}', figsize=(20, 20), sharex=True, return_fig=True)\n",
    "plt.xticks(range(0, 110001, 5000))\n",
    "display(ann_patient.description)\n",
    "# display(ann_patient.contained_labels)\n",
    "# display(ann_patient.chan)\n",
    "wfdb.plot_wfdb(annotation=ann_patient)\n",
    "wfdb.plot_wfdb(annotation=ann_monitor)\n",
    "\n",
    "# numpy.savetxt(\"252n.csv\", record_252n.p_signal, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9806e1e1-682a-42b4-a5c3-52d046f11f13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Observe correlation series record_252n_apb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795bbc13-0d25-474d-9525-a3800c10ad73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wfdb_fig, wfdb_axes = wfdb.plot_items(signal=record_252n.p_signal, sig_name=record_252n.sig_name, sig_units=record_252n.units, figsize=(20, 8), sharex=True, return_fig_axes=True)  # return matplotlib axes\n",
    "record_252n_abp_corr_series = pd.DataFrame(record_252n_abp.p_signal).rolling(window=100).corr().iloc[pd.IndexSlice[1::2],0].to_numpy()\n",
    "fig1, ax = plt.subplots(3, 1, figsize=(20,12), sharex=True)\n",
    "ax[0].plot(record_252n_abp.p_signal[:,0])\n",
    "ax[0].axvline(x = 1433, color = 'r', label = 'correlation change')\n",
    "# ax[0].axvline(x = 1564, color = 'r', label = 'correlation change')\n",
    "ax[1].plot(record_252n_abp.p_signal[:,1])\n",
    "ax[1].axvline(x = 1433, color = 'r', label = 'correlation change')\n",
    "# ax[1].axvline(x = 1564, color = 'r', label = 'correlation change')\n",
    "ax[2].plot(record_252n_abp_corr_series)\n",
    "ax[2].axvline(x = 1433, color = 'r', label = 'correlation change')\n",
    "# ax[2].axvline(x = 1564, color = 'r', label = 'correlation change')\n",
    "\n",
    "pd.DataFrame(record_252n.p_signal, columns=[\"ABPsys/mmHg\", \"ABBPdias/mmHg\"]).to_csv(\"../../tmp/252n.csv\")\n",
    "pd.DataFrame(record_252n_abp_corr_series, columns=[\"Pearson corr\"]).to_csv(\"../../tmp/252n_abp_corr.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57073392-04e2-4c10-8a2e-edf16ef34e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"/workspace/correlation-change-predict/utils\")\n",
    "from utils import convert_str_bins_list, split_and_norm_data\n",
    "\n",
    "data_config_path = Path(\"../config/data_config.yaml\")\n",
    "with open(data_config_path) as f:\n",
    "    data_cfg_yaml = dynamic_yaml.load(f)\n",
    "    data_cfg = yaml.full_load(dynamic_yaml.dump(data_cfg_yaml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9554653-6e93-4c2b-9e07-b22ebf7de69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "corr_type = \"pearson\"\n",
    "s_l = 1\n",
    "w_l = 50\n",
    "filt_mode = None\n",
    "quan_discrete_bins = None\n",
    "custom_discrete_bins = None\n",
    "graph_nodes_v_mode = None\n",
    "etl_items_setting = \"-train_train\"  # -train_train|-train_all\n",
    "target_mats_path = \"pearson/custom_discretize_graph_adj_mat/bins_-10_-025_025_10\"\n",
    "output_file_name = \"sp500_20112015_corr_ser_reg_std_corr_mat_large_filtered_hrchy_10_cluster_label_last_v2_negative_filtered\"+etl_items_setting\n",
    "can_count_square_graph = False\n",
    "can_count_upper_triangle = True\n",
    "count_one_edge_idx = None # 3*3 matrix as an example, idx:0 for (A & B), idx:1 for (A & C), idx:2 for (B & C)\n",
    "assert (bool(filt_mode) != bool(quan_discrete_bins)) or (filt_mode is None and quan_discrete_bins is None), \"filt_mode and quan_discrete_bins must be both not input or one input\"\n",
    "assert (can_count_square_graph+can_count_upper_triangle+bool(count_one_edge_idx is not None)) == 1, \"can_count_square_graph, can_count_upper_triangle and count_one_edge_idx, only one of them can be True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c08e4f4-71f2-46fd-8cb3-214e443e9ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if filt_mode:\n",
    "    graph_adj_mode_dir = f\"filtered_graph_adj_mat/{filt_mode}-quan{str(filt_quan).replace('.', '')}\"\n",
    "elif quan_discrete_bins:\n",
    "    graph_adj_mode_dir = f\"quan_discretize_graph_adj_mat/bins{quan_discrete_bins}\"\n",
    "elif custom_discrete_bins:\n",
    "    graph_adj_mode_dir = f\"custom_discretize_graph_adj_mat/bins_{'_'.join((str(f) for f in custom_discrete_bins)).replace('.', '')}\"\n",
    "else:\n",
    "    graph_adj_mode_dir = \"graph_adj_mat\"\n",
    "graph_adj_mat_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/{corr_type}/{graph_adj_mode_dir}\"\n",
    "graph_node_mat_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/graph_node_mat\"\n",
    "target_mat_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}/{target_mats_path}\"\n",
    "\n",
    "gra_edges_data_mats = np.load(graph_adj_mat_dir/f\"corr_s{s_l}_w{w_l}_adj_mat.npy\")\n",
    "gra_nodes_data_mats = np.load(graph_node_mat_dir/f\"{graph_nodes_v_mode}_s{s_l}_w{w_l}_nodes_mat.npy\") if graph_nodes_v_mode else np.ones((gra_edges_data_mats.shape[0], 1, gra_edges_data_mats.shape[2]))\n",
    "target_mats = np.load(target_mat_dir/f\"corr_s{s_l}_w{w_l}_adj_mat.npy\") if target_mats_path else None\n",
    "norm_train_dataset, norm_val_dataset, norm_test_dataset, scaler = split_and_norm_data(edges_mats=gra_edges_data_mats, nodes_mats=gra_nodes_data_mats, target_mats=target_mats, batch_size= batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e22646-d6f2-4d48-93fd-af525fd01233",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"================ edges ==================\")\n",
    "print(norm_train_dataset['edges'][:3])\n",
    "print(\"================ nodes ==================\")\n",
    "print(norm_train_dataset['nodes'][:3])\n",
    "print(\"================ target ==================\")\n",
    "print(norm_train_dataset['target'][:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40bdea4-5582-4d2b-812d-5fbd8f1d8f33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs_target = {\"train\": None, \"val\": None}\n",
    "obs_graphs_dict = {\"train\": norm_train_dataset['target'], \"val\": norm_val_dataset['target']}\n",
    "num_nodes = norm_train_dataset['target'][0].shape[0]\n",
    "graph_size = norm_train_dataset['target'][0].size\n",
    "upper_triangle_idxs = np.triu_indices(num_nodes, 1)\n",
    "for split, graph_adj_mats in obs_graphs_dict.items():\n",
    "    for i, graph_adj_t in enumerate(graph_adj_mats):\n",
    "        if can_count_upper_triangle:\n",
    "            obs_target[split] = graph_adj_t[upper_triangle_idxs].reshape(1, -1) if i == 0 else np.concatenate([obs_target[split], graph_adj_t[upper_triangle_idxs].reshape(1, -1)])\n",
    "        elif count_one_edge_idx is not None:\n",
    "            obs_target[split] = graph_adj_t[upper_triangle_idxs][count_one_edge_idx].reshape(1, -1) if i == 0 else np.concatenate([obs_target[split], graph_adj_t[upper_triangle_idxs][count_one_edge_idx].reshape(1, -1)])\n",
    "        else:\n",
    "            can_count_square_graph = True\n",
    "            break\n",
    "    if can_count_square_graph:\n",
    "        obs_target[split] =  graph_adj_mats\n",
    "print(f\"obs_target[train].shape:{obs_target['train'].shape}, obs_target[val].shape:{obs_target['val'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b3f0c1-4112-4aae-95d0-1f5575ff15d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_labels, tr_labels_freq_counts = np.unique(obs_target[\"train\"], return_counts=True)\n",
    "val_labels, val_labels_freq_counts = np.unique(obs_target[\"val\"], return_counts=True)\n",
    "print(f\"implement dataset:{output_file_name}\")\n",
    "tr_val_info = {\"train\": {\"dataset_target\": norm_train_dataset['target'],\n",
    "                         \"freq_info\": dict(zip(tr_labels, tr_labels_freq_counts))},\n",
    "               \"val\": {\"dataset_target\": norm_val_dataset['target'],\n",
    "                       \"freq_info\": dict(zip(val_labels, val_labels_freq_counts))}}\n",
    "for data_split in tr_val_info:\n",
    "    data_info = tr_val_info[data_split]\n",
    "    print(f\"norm_{data_split}_dataset[target]:\\n  shape: {data_info['dataset_target'].shape}\\n  size: {data_info['dataset_target'].size}\")\n",
    "    sum_num_freq_each_label = 0\n",
    "    print(f\"for obs_target:\")\n",
    "    for label, freq in data_info['freq_info'].items():\n",
    "        print(f\"  {data_split} label :{label}, frequency: {freq}\")\n",
    "        sum_num_freq_each_label += freq\n",
    "    print(f\"  {data_split} sum_num_freq_each_label:{sum_num_freq_each_label}\")\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9496d18-9316-42c9-bd72-52158613eb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if can_count_square_graph:\n",
    "    target_retrieve_setting = \"square\"\n",
    "elif can_count_upper_triangle:\n",
    "    target_retrieve_setting = \"upper_triangle\"\n",
    "elif count_one_edge_idx is not None:\n",
    "    target_retrieve_setting = f\"edge_idx_{count_one_edge_idx}\"\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,9))\n",
    "colors_labels_map = {\"-1.0\": \"lime\", \"0.0\": \"darkorange\", \"1.0\": \"dodgerblue\"}\n",
    "axes[0].pie(tr_labels_freq_counts, labels=tr_labels, autopct='%1.1f%%', textprops={'fontsize': 24}, colors=[colors_labels_map[str(label)] for label in tr_labels])\n",
    "axes[0].set_title(\"Train\", fontsize=32)\n",
    "axes[1].pie(val_labels_freq_counts, labels=val_labels, autopct='%1.1f%%', textprops={'fontsize': 24}, colors=[colors_labels_map[str(label)] for label in val_labels])\n",
    "axes[1].set_title(\"Validation\", fontsize=32)\n",
    "#fig.suptitle(f'Irrelevant keep({num_nodes} company) with {target_retrieve_setting}', fontsize=40)\n",
    "fig.suptitle(f'Positive_Negative keep({num_nodes} company)', fontsize=40)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d7e10-65c4-48e2-8fcd-bd84d4826963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

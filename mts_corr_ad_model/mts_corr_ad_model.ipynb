{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "333f12fa-b283-4785-9ff3-f92ee7611217",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [2190218856.py] {'CORR_STRIDE': 1, 'CORR_WINDOW': 5, 'DATA_DIV_STRIDE': 20, 'MAX_DATA_DIV_START_ADD': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.8 s (started: 2023-02-19 12:52:30 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import sys\n",
    "import logging\n",
    "from pprint import pformat\n",
    "from itertools import product, islice\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import torch\n",
    "from torch.nn import Linear, GRU, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, GINConv, global_mean_pool, global_add_pool, summary\n",
    "# from torchsummary import summary\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "\n",
    "sys.path.append(\"/workspace/correlation-change-predict/ywt_library\")\n",
    "import data_module\n",
    "from data_module import data_gen_cfg, gen_corr_mat_thru_t\n",
    "\n",
    "\n",
    "with open('../config/data_config.yaml') as f:\n",
    "    data = dynamic_yaml.load(f)\n",
    "    data_cfg = yaml.full_load(dynamic_yaml.dump(data))\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.basicConfig(format='%(levelname)-8s [%(filename)s] %(message)s',\n",
    "                    level=logging.INFO)\n",
    "matplotlib_logger = logging.getLogger(\"matplotlib\")\n",
    "matplotlib_logger.setLevel(logging.ERROR)\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "# logger_list = [logging.getLogger(name) for name in logging.root.manager.loggerDict]\n",
    "# loggin.debug(logger_list)\n",
    "\n",
    "# %load_ext pycodestyle_magic\n",
    "# %pycodestyle_on --ignore E501\n",
    "logging.debug(pformat(data_cfg, indent=1, width=100, compact=True))\n",
    "logging.info(pformat(data_gen_cfg, indent=1, width=100, compact=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9618165-42eb-4b2b-b691-f18bbdb85b6c",
   "metadata": {},
   "source": [
    "## Data implement & output setting & testset setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b164ae7b-db47-49ce-aae4-b8a80eb74f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [2257181884.py] ===== file_name basis:sp500_20082017_corr_ser_reg_corr_mat_hrchy_11_cluster-train_train =====\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.13 ms (started: 2023-02-19 12:52:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# data implement setting\n",
    "data_implement = \"SP500_20082017_CORR_SER_REG_CORR_MAT_HRCHY_11_CLUSTER\"  # watch options by operate: logging.info(data_cfg[\"DATASETS\"].keys())\n",
    "# train set setting\n",
    "train_items_setting = \"-train_train\"  # -train_train|-train_all\n",
    "# setting of name of output files and pictures title\n",
    "output_file_name = data_cfg[\"DATASETS\"][data_implement]['OUTPUT_FILE_NAME_BASIS'] + train_items_setting\n",
    "logging.info(f\"===== file_name basis:{output_file_name} =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc682cc-dc75-47e6-be5e-8f2b818e06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 798 µs (started: 2023-02-19 12:52:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "s_l, w_l = data_gen_cfg[\"CORR_STRIDE\"], data_gen_cfg[\"CORR_WINDOW\"]\n",
    "graph_data_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}-graph_data\"\n",
    "model_dir = Path(f'./save_models/{output_file_name}/corr_s{s_l}_w{w_l}')\n",
    "model_log_dir = Path(f'./save_models/{output_file_name}/corr_s{s_l}_w{w_l}/train_logs/')\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "model_log_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cb433-a7a3-421f-8642-0d42d5c715b9",
   "metadata": {},
   "source": [
    "## model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4a6e4e-e361-4b37-be10-8943c077c398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 597 µs (started: 2023-02-19 12:52:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "gin_enc_cfg = {\"num_gin_layers\": 1,  # range:1~n, for GIN after the second layer,\n",
    "               \"gin_dim_h\": 3,\n",
    "              }\n",
    "data_loader_cfg = {\"tr_loader_batch_size\": 12,  # each graph contains 5 days correlation, so 4 graphs means a month, 12 graphs means a quarter\n",
    "                   \"val_loader_batch_size\": 4,  # each graph contains 5 days correlation, so 4 graphs means a month, 12 graphs means a quarter\n",
    "                   \"test_loader_batch_size\": 4,  # each graph contains 5 days correlation, so 4 graphs means a month, 12 graphs means a quarter\n",
    "                  }\n",
    "mts_corr_ad_cfg = {\"gru_layers\": 1,  # range:1~n, for gru\n",
    "                   \"gru_dim_out\": 8,\n",
    "                   }\n",
    "mts_corr_ad_cfg[\"dim_out\"] = gin_enc_cfg[\"num_gin_layers\"] *  gin_enc_cfg[\"gin_dim_h\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904302d0-3d2b-4f4d-8996-1bbf468b3083",
   "metadata": {},
   "source": [
    "## Load Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d1b5110-24fa-4739-b56a-b4f336f518d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [1425911519.py] graph_arr.shape:(2507, 66, 66)\n",
      "INFO     [1425911519.py] data.num_node_features: 1; data.num_edges: 4356; data.num_edge_features: 1; data.is_undirected: True; \n",
      "INFO     [1425911519.py] data.x.shape: torch.Size([66, 1]); data.y.x.shape: torch.Size([66, 1]); data.edge_index.shape: torch.Size([2, 4356]); data.edge_attr.shape: torch.Size([4356, 1])\n",
      "INFO     [1425911519.py] Training set   = 2255 graphs\n",
      "INFO     [1425911519.py] Validation set = 125 graphs\n",
      "INFO     [1425911519.py] Test set       = 126 graphs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.72 s (started: 2023-02-19 12:52:31 +00:00)\n"
     ]
    }
   ],
   "source": [
    "graph_arr = np.load(graph_data_dir/f\"corr_s{s_l}_w{w_l}_graph.npy\")  # each graph consist of 66 node & 66^2 edges\n",
    "logging.info(f\"graph_arr.shape:{graph_arr.shape}\")\n",
    "graph_time_step = graph_arr.shape[0] - 1  # the graph of last \"t\" can't be used as train data\n",
    "node_attr = torch.tensor(np.zeros((graph_arr.shape[1], 1)), dtype=torch.float32)  # each node has only one attribute\n",
    "edge_index = torch.tensor(list(product(range(graph_arr.shape[1]), repeat=2)))\n",
    "dataset = []\n",
    "for g_t in range(graph_time_step):\n",
    "    edge_attr = torch.tensor(np.hstack(graph_arr[g_t]).reshape(-1, 1), dtype=torch.float32)\n",
    "    edge_attr_next_t = torch.tensor(np.hstack(graph_arr[g_t+1]).reshape(-1, 1), dtype=torch.float32)\n",
    "    data_y = Data(x=node_attr, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr_next_t)\n",
    "    data = Data(x=node_attr, y=data_y, edge_index=edge_index.t().contiguous(), edge_attr=edge_attr)\n",
    "    dataset.append(data)\n",
    "else:\n",
    "    #mts_corr_ad_cfg[\"dim_out\"] = data.y.shape[0]  # if the input of loss-function graphs instead of graphs' embedding\n",
    "    gin_enc_cfg[\"num_node_features\"] = data.num_node_features\n",
    "    logging.info(f\"data.num_node_features: {data.num_node_features}; data.num_edges: {data.num_edges}; data.num_edge_features: {data.num_edge_features}; data.is_undirected: {data.is_undirected()}; \")\n",
    "    logging.info(f\"data.x.shape: {data.x.shape}; data.y.x.shape: {data.y.x.shape}; data.edge_index.shape: {data.edge_index.shape}; data.edge_attr.shape: {data.edge_attr.shape}\")\n",
    "\n",
    "# Create training, validation, and test sets\n",
    "train_dataset = dataset[:int(len(dataset)*0.9)]\n",
    "\n",
    "import pickle\n",
    "with open(\"../../tmp/tmp_torch_graph_dataset.pickle\", 'wb') as handle:\n",
    "    pickle.dump(train_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "val_dataset   = dataset[int(len(dataset)*0.9):int(len(dataset)*0.95)]\n",
    "test_dataset  = dataset[int(len(dataset)*0.95):]\n",
    "\n",
    "# Create mini-batches\n",
    "train_loader = DataLoader(train_dataset, batch_size = data_loader_cfg[\"tr_loader_batch_size\"], shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size = data_loader_cfg[\"val_loader_batch_size\"], shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = data_loader_cfg[\"test_loader_batch_size\"], shuffle=False)\n",
    "\n",
    "# show info\n",
    "logging.info(f'Training set   = {len(train_dataset)} graphs')\n",
    "logging.info(f'Validation set = {len(val_dataset)} graphs')\n",
    "logging.info(f'Test set       = {len(test_dataset)} graphs')\n",
    "logging.debug('Train loader:')\n",
    "for i, subgraph in enumerate(train_loader):\n",
    "    logging.debug(f' - Subgraph {i}: {subgraph} ; Subgraph {i}.num_graphs:{subgraph.num_graphs}')\n",
    "\n",
    "logging.debug('Validation loader:')\n",
    "for i, subgraph in enumerate(val_loader):\n",
    "    logging.debug(f' - Subgraph {i}: {subgraph} ; Subgraph{i}.num_graphs:{subgraph.num_graphs}')\n",
    "\n",
    "logging.debug('Test loader:')\n",
    "for i, subgraph in enumerate(test_loader):\n",
    "    logging.debug(f' - Subgraph {i}: {subgraph} ; Subgraph{i}.num_graphs:{subgraph.num_graphs}')\n",
    "\n",
    "logging.debug('Peeking Train data:')\n",
    "data_x_nodes = next(iter(train_loader)).x.reshape(train_loader.batch_size, -1)\n",
    "data_x_edges = next(iter(train_loader)).edge_attr.reshape(train_loader.batch_size, -1)\n",
    "data_y_nodes = torch.cat([y.x for y in next(iter(train_loader)).y]).reshape(train_loader.batch_size, -1)\n",
    "data_y_edges = torch.cat([y.edge_attr for y in next(iter(train_loader)).y]).reshape(train_loader.batch_size, -1)\n",
    "for i in range(12):\n",
    "    logging.debug(f\"\\n batch0_x{i}.shape: {data_x_nodes[i].shape} \\n batch0_x{i}[:5]:{data_x_nodes[i][:5]}\")\n",
    "    logging.debug(f\"\\n batch0_x{i}_edges.shape: {data_x_edges[i].shape} \\n batch0_x{i}_edges[:5]:{data_x_edges[i][:5]}\")\n",
    "    logging.debug(f\"\\n batch0_y{i}.shape: {data_y_nodes[i].shape} \\n batch0_y{i}[:5]:{data_y_nodes[i][:5]}\")\n",
    "    logging.debug(f\"\\n batch0_y{i}_edges.shape: {data_y_edges[i].shape} \\n batch0_y{i}_edges[:5]:{data_y_edges[i][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77157a0c-3ff4-4e6a-a5e1-a32dfdc0b6af",
   "metadata": {},
   "source": [
    "## Multi-Dimension Time-Series Correlation Anomly Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32e5e2b9-8ec8-4d7d-b670-f157597aa1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.81 ms (started: 2023-02-19 12:52:33 +00:00)\n"
     ]
    }
   ],
   "source": [
    "class GinEncoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    num_node_features: number of features per node in the graph, in this model every node has same size of features \n",
    "    gin_dim_h: output size of hidden layer of GINconv\n",
    "    gru_layers: Number of recurrent layers of GRU\n",
    "    \"\"\"\n",
    "    def __init__(self, num_node_features:int, num_gin_layers:int, gin_dim_h:int, **kwargs):\n",
    "        super(GinEncoder, self).__init__()\n",
    "        self.num_gin_layers = num_gin_layers\n",
    "        self.gin_convs = torch.nn.ModuleList()\n",
    "        self.gin_dim_h = gin_dim_h\n",
    "\n",
    "        for i in range(num_gin_layers):\n",
    "            if i:\n",
    "                nn = Sequential(Linear(gin_dim_h, gin_dim_h),\n",
    "                                BatchNorm1d(gin_dim_h), ReLU(),\n",
    "                                Linear(gin_dim_h, gin_dim_h), ReLU())\n",
    "            else:\n",
    "                nn = Sequential(Linear(num_node_features, gin_dim_h),\n",
    "                                BatchNorm1d(gin_dim_h), ReLU(),\n",
    "                                Linear(gin_dim_h, gin_dim_h), ReLU())\n",
    "            self.gin_convs.append(GINConv(nn))\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch_node_id):\n",
    "        # Node embeddings\n",
    "        nodes_emb_layers = []\n",
    "        for i in range(self.num_gin_layers):\n",
    "            if i:\n",
    "                nodes_emb = self.gin_convs[i](nodes_emb, edge_index)\n",
    "            else:\n",
    "                nodes_emb = self.gin_convs[i](x, edge_index)  # the shape of nodes_embeds: [batch_size*num_nodes, gin_dim_h] \n",
    "            nodes_emb_layers.append(nodes_emb)\n",
    "\n",
    "        # Graph-level readout\n",
    "        nodes_emb_pools = [global_add_pool(nodes_emb, batch_node_id) for nodes_emb in nodes_emb_layers]  # the shape of global_add_pool(nodes_emb, batch_node_id): [batch_size, gin_dim_h]\n",
    "                                                                                                         # global_add_pool : make a super-node to represent the graph\n",
    "        # Concatenate and form the graph embeddings\n",
    "        graph_embeds = torch.cat(nodes_emb_pools, dim=1)  # the shape of graph_embeds: [batch_size, num_layers*gin_dim_h]\n",
    "\n",
    "        return graph_embeds\n",
    "\n",
    "\n",
    "    def get_embeddings(self, x, edge_index, batch_node_id):\n",
    "        with torch.no_grad():\n",
    "            graph_embeds = self.forward(x, edge_index, batch_node_id).reshape(-1)\n",
    "\n",
    "        return graph_embeds\n",
    "\n",
    "class MTSCorrAD(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    gru_dim_out: The number of output size of GRU and features in the hidden state h of GRU\n",
    "    dim_out: The number of output size of MTSCorrAD model\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_encoder:torch.nn.Module, gru_layers:int, gru_dim_out:int, dim_out:int, **kwargs):\n",
    "        super(MTSCorrAD, self).__init__()\n",
    "        self.graph_encoder = GinEncoder(**gin_enc_cfg).to(\"cuda\")\n",
    "        gru_input_size = self.graph_encoder.num_gin_layers * self.graph_encoder.gin_dim_h  # the input size of GRU depend on the number of layers of GINconv\n",
    "        self.gru1 = GRU(gru_input_size, gru_dim_out, gru_layers)\n",
    "        self.lin1 = Linear(gru_dim_out, dim_out)\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch_node_id):\n",
    "        # Inter-series modeling\n",
    "        graph_embeds = self.graph_encoder(x, edge_index, batch_node_id)\n",
    "\n",
    "        # Temporal Modeling\n",
    "        gru_output, gru_hn = self.gru1(graph_embeds)  # regarding batch_size as time-steps(sequence length) by using \"unbatched\" input\n",
    "        graph_embed_pred = self.lin1(gru_output[-1])  # gru_output[-1] => only take last time-step\n",
    "\n",
    "        return graph_embed_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "946d826a-0dc6-47dd-a74b-738bd7d09669",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/5000 [00:00<?, ?it/s]INFO     [2275295803.py] \n",
      "MTSCorrAD(\n",
      "  (graph_encoder): GinEncoder(\n",
      "    (gin_convs): ModuleList(\n",
      "      (0): GINConv(nn=Sequential(\n",
      "        (0): Linear(in_features=1, out_features=3, bias=True)\n",
      "        (1): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Linear(in_features=3, out_features=3, bias=True)\n",
      "        (4): ReLU()\n",
      "      ))\n",
      "    )\n",
      "  )\n",
      "  (gru1): GRU(3, 8)\n",
      "  (lin1): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n",
      "====================================================================================================\n",
      "+------------------------------+-----------------------------+-----------------+----------+\n",
      "| Layer                        | Input Shape                 | Output Shape    |   #Param |\n",
      "|------------------------------+-----------------------------+-----------------+----------|\n",
      "| MTSCorrAD                    | [726, 1], [2, 47916], [726] | [3]             |      363 |\n",
      "| ├─(graph_encoder)GinEncoder  | [726, 1], [2, 47916], [726] | [11, 3]         |       24 |\n",
      "| │    └─(gin_convs)ModuleList | --                          | --              |       24 |\n",
      "| │    │    └─(0)GINConv       | [726, 1], [2, 47916]        | [726, 3]        |       24 |\n",
      "| ├─(gru1)GRU                  | [11, 3]                     | [11, 8], [1, 8] |      312 |\n",
      "| ├─(lin1)Linear               | [8]                         | [3]             |       27 |\n",
      "+------------------------------+-----------------------------+-----------------+----------+\n",
      "INFO     [2275295803.py] Epoch   0 | Train Loss: 240.53813 | Val Loss: 6267.65723 \n",
      "  0% 10/5000 [00:08<1:04:36,  1.29it/s]INFO     [2275295803.py] Epoch  10 | Train Loss: 17.91737 | Val Loss: 559.83698 \n",
      "  0% 20/5000 [00:15<1:04:15,  1.29it/s]INFO     [2275295803.py] Epoch  20 | Train Loss: 0.12698 | Val Loss: 30.70437 \n",
      "  1% 30/5000 [00:23<1:03:58,  1.29it/s]INFO     [2275295803.py] Epoch  30 | Train Loss: 0.00000 | Val Loss: 23.83755 \n",
      "  1% 40/5000 [00:31<1:04:07,  1.29it/s]INFO     [2275295803.py] Epoch  40 | Train Loss: 0.00000 | Val Loss: 23.83218 \n",
      "  1% 50/5000 [00:38<1:04:05,  1.29it/s]INFO     [2275295803.py] Epoch  50 | Train Loss: 0.00000 | Val Loss: 23.83175 \n",
      "  1% 60/5000 [00:46<1:04:02,  1.29it/s]INFO     [2275295803.py] Epoch  60 | Train Loss: 0.00000 | Val Loss: 23.83156 \n",
      "  1% 70/5000 [00:54<1:03:56,  1.29it/s]INFO     [2275295803.py] Epoch  70 | Train Loss: 0.00000 | Val Loss: 23.83150 \n",
      "  2% 80/5000 [01:02<1:04:09,  1.28it/s]INFO     [2275295803.py] Epoch  80 | Train Loss: 0.00000 | Val Loss: 23.83146 \n",
      "  2% 90/5000 [01:10<1:02:49,  1.30it/s]INFO     [2275295803.py] Epoch  90 | Train Loss: 0.00000 | Val Loss: 23.83168 \n",
      "  2% 100/5000 [01:17<1:02:26,  1.31it/s]INFO     [2275295803.py] Epoch 100 | Train Loss: 0.00000 | Val Loss: 23.83117 \n",
      "  2% 110/5000 [01:25<1:02:39,  1.30it/s]INFO     [2275295803.py] Epoch 110 | Train Loss: 0.00000 | Val Loss: 23.83059 \n",
      "  2% 120/5000 [01:33<1:02:24,  1.30it/s]INFO     [2275295803.py] Epoch 120 | Train Loss: 0.00000 | Val Loss: 23.82716 \n",
      "  3% 130/5000 [01:40<1:02:20,  1.30it/s]INFO     [2275295803.py] Epoch 130 | Train Loss: 0.00000 | Val Loss: 23.81784 \n",
      "  3% 140/5000 [01:48<1:01:46,  1.31it/s]INFO     [2275295803.py] Epoch 140 | Train Loss: 0.00000 | Val Loss: 23.80182 \n",
      "  3% 150/5000 [01:56<1:02:02,  1.30it/s]INFO     [2275295803.py] Epoch 150 | Train Loss: 0.00000 | Val Loss: 23.75867 \n",
      "  3% 160/5000 [02:03<1:03:02,  1.28it/s]INFO     [2275295803.py] Epoch 160 | Train Loss: 0.00000 | Val Loss: 23.62800 \n",
      "  3% 170/5000 [02:11<1:02:45,  1.28it/s]INFO     [2275295803.py] Epoch 170 | Train Loss: 0.00000 | Val Loss: 23.37289 \n",
      "  4% 180/5000 [02:19<1:02:43,  1.28it/s]INFO     [2275295803.py] Epoch 180 | Train Loss: 0.00013 | Val Loss: 24.16127 \n",
      "  4% 190/5000 [02:27<1:02:58,  1.27it/s]INFO     [2275295803.py] Epoch 190 | Train Loss: 0.00013 | Val Loss: 18.74654 \n",
      "  4% 200/5000 [02:34<1:02:20,  1.28it/s]INFO     [2275295803.py] Epoch 200 | Train Loss: 0.00016 | Val Loss: 14.29588 \n",
      "  4% 210/5000 [02:42<1:02:09,  1.28it/s]INFO     [2275295803.py] Epoch 210 | Train Loss: 0.00024 | Val Loss: 10.37569 \n",
      "  4% 220/5000 [02:50<1:02:02,  1.28it/s]INFO     [2275295803.py] Epoch 220 | Train Loss: 0.00021 | Val Loss: 7.66190 \n",
      "  5% 230/5000 [02:58<1:01:59,  1.28it/s]INFO     [2275295803.py] Epoch 230 | Train Loss: 0.00014 | Val Loss: 6.08240 \n",
      "  5% 240/5000 [03:06<1:01:51,  1.28it/s]INFO     [2275295803.py] Epoch 240 | Train Loss: 0.00008 | Val Loss: 5.17459 \n",
      "  5% 250/5000 [03:14<1:02:10,  1.27it/s]INFO     [2275295803.py] Epoch 250 | Train Loss: 0.00004 | Val Loss: 4.60169 \n",
      "  5% 260/5000 [03:21<1:01:47,  1.28it/s]INFO     [2275295803.py] Epoch 260 | Train Loss: 0.00002 | Val Loss: 4.21196 \n",
      "  5% 270/5000 [03:29<1:01:43,  1.28it/s]INFO     [2275295803.py] Epoch 270 | Train Loss: 0.00001 | Val Loss: 3.93969 \n",
      "  6% 280/5000 [03:37<1:01:38,  1.28it/s]INFO     [2275295803.py] Epoch 280 | Train Loss: 0.00000 | Val Loss: 3.75238 \n",
      "  6% 290/5000 [03:45<1:01:48,  1.27it/s]INFO     [2275295803.py] Epoch 290 | Train Loss: 0.00000 | Val Loss: 3.76497 \n",
      "  6% 300/5000 [03:53<1:01:27,  1.27it/s]INFO     [2275295803.py] Epoch 300 | Train Loss: 0.00000 | Val Loss: 3.81753 \n",
      "  6% 310/5000 [04:01<1:01:11,  1.28it/s]INFO     [2275295803.py] Epoch 310 | Train Loss: 0.00000 | Val Loss: 3.79091 \n",
      "  6% 320/5000 [04:08<1:00:42,  1.28it/s]INFO     [2275295803.py] Epoch 320 | Train Loss: 0.00000 | Val Loss: 3.73172 \n",
      "  7% 330/5000 [04:16<1:00:50,  1.28it/s]INFO     [2275295803.py] Epoch 330 | Train Loss: 0.00000 | Val Loss: 3.66621 \n",
      "  7% 340/5000 [04:24<1:00:47,  1.28it/s]INFO     [2275295803.py] Epoch 340 | Train Loss: 0.00000 | Val Loss: 3.59458 \n",
      "  7% 350/5000 [04:32<1:00:59,  1.27it/s]INFO     [2275295803.py] Epoch 350 | Train Loss: 0.00000 | Val Loss: 3.52807 \n",
      "  7% 360/5000 [04:40<1:00:22,  1.28it/s]INFO     [2275295803.py] Epoch 360 | Train Loss: 0.00000 | Val Loss: 3.48836 \n",
      "  7% 370/5000 [04:48<1:00:25,  1.28it/s]INFO     [2275295803.py] Epoch 370 | Train Loss: 0.00000 | Val Loss: 3.46515 \n",
      "  8% 380/5000 [04:55<1:00:06,  1.28it/s]INFO     [2275295803.py] Epoch 380 | Train Loss: 0.00000 | Val Loss: 3.42738 \n",
      "  8% 390/5000 [05:03<59:46,  1.29it/s]  INFO     [2275295803.py] Epoch 390 | Train Loss: 0.00000 | Val Loss: 3.40234 \n",
      "  8% 400/5000 [05:11<59:23,  1.29it/s]INFO     [2275295803.py] Epoch 400 | Train Loss: 0.00000 | Val Loss: 3.36827 \n",
      "  8% 410/5000 [05:19<59:19,  1.29it/s]INFO     [2275295803.py] Epoch 410 | Train Loss: 0.00000 | Val Loss: 3.27561 \n",
      "  8% 420/5000 [05:26<59:05,  1.29it/s]INFO     [2275295803.py] Epoch 420 | Train Loss: 0.00000 | Val Loss: 3.26147 \n",
      "  9% 430/5000 [05:34<58:49,  1.29it/s]INFO     [2275295803.py] Epoch 430 | Train Loss: 0.00000 | Val Loss: 3.25490 \n",
      "  9% 440/5000 [05:42<58:11,  1.31it/s]INFO     [2275295803.py] Epoch 440 | Train Loss: 0.00000 | Val Loss: 3.21016 \n",
      "  9% 450/5000 [05:50<58:42,  1.29it/s]INFO     [2275295803.py] Epoch 450 | Train Loss: 0.00000 | Val Loss: 3.21304 \n",
      "  9% 460/5000 [05:57<58:20,  1.30it/s]INFO     [2275295803.py] Epoch 460 | Train Loss: 0.00000 | Val Loss: 3.17233 \n",
      "  9% 470/5000 [06:05<58:34,  1.29it/s]INFO     [2275295803.py] Epoch 470 | Train Loss: 0.00000 | Val Loss: 3.12511 \n",
      " 10% 480/5000 [06:13<58:10,  1.29it/s]INFO     [2275295803.py] Epoch 480 | Train Loss: 0.00000 | Val Loss: 3.07857 \n",
      " 10% 490/5000 [06:20<57:47,  1.30it/s]INFO     [2275295803.py] Epoch 490 | Train Loss: 0.00000 | Val Loss: 3.07019 \n",
      " 10% 500/5000 [06:28<57:42,  1.30it/s]INFO     [2275295803.py] Epoch 500 | Train Loss: 0.00000 | Val Loss: 2.98619 \n",
      " 10% 510/5000 [06:36<57:51,  1.29it/s]INFO     [2275295803.py] Epoch 510 | Train Loss: 0.00000 | Val Loss: 2.95788 \n",
      " 10% 520/5000 [06:44<57:35,  1.30it/s]INFO     [2275295803.py] Epoch 520 | Train Loss: 0.00000 | Val Loss: 2.96153 \n",
      " 11% 530/5000 [06:51<57:40,  1.29it/s]INFO     [2275295803.py] Epoch 530 | Train Loss: 0.00000 | Val Loss: 3.00280 \n",
      " 11% 540/5000 [06:59<57:21,  1.30it/s]INFO     [2275295803.py] Epoch 540 | Train Loss: 0.00000 | Val Loss: 3.03828 \n",
      " 11% 550/5000 [07:07<57:22,  1.29it/s]INFO     [2275295803.py] Epoch 550 | Train Loss: 0.00000 | Val Loss: 3.03869 \n",
      " 11% 560/5000 [07:14<56:58,  1.30it/s]INFO     [2275295803.py] Epoch 560 | Train Loss: 0.00000 | Val Loss: 3.03526 \n",
      " 11% 570/5000 [07:22<57:05,  1.29it/s]INFO     [2275295803.py] Epoch 570 | Train Loss: 0.00000 | Val Loss: 3.04045 \n",
      " 12% 580/5000 [07:30<56:38,  1.30it/s]INFO     [2275295803.py] Epoch 580 | Train Loss: 0.00000 | Val Loss: 3.02970 \n",
      " 12% 590/5000 [07:38<56:44,  1.30it/s]INFO     [2275295803.py] Epoch 590 | Train Loss: 0.00000 | Val Loss: 2.99876 \n",
      " 12% 600/5000 [07:45<56:35,  1.30it/s]INFO     [2275295803.py] Epoch 600 | Train Loss: 0.00000 | Val Loss: 2.98648 \n",
      " 12% 610/5000 [07:53<56:25,  1.30it/s]INFO     [2275295803.py] Epoch 610 | Train Loss: 0.00000 | Val Loss: 2.97323 \n",
      " 12% 620/5000 [08:01<56:17,  1.30it/s]INFO     [2275295803.py] Epoch 620 | Train Loss: 0.00000 | Val Loss: 2.95571 \n",
      " 13% 630/5000 [08:09<56:28,  1.29it/s]INFO     [2275295803.py] Epoch 630 | Train Loss: 0.00000 | Val Loss: 2.98832 \n",
      " 13% 640/5000 [08:16<56:13,  1.29it/s]INFO     [2275295803.py] Epoch 640 | Train Loss: 0.00000 | Val Loss: 2.99615 \n",
      " 13% 650/5000 [08:24<56:19,  1.29it/s]INFO     [2275295803.py] Epoch 650 | Train Loss: 0.00000 | Val Loss: 2.98625 \n",
      " 13% 660/5000 [08:32<56:17,  1.29it/s]INFO     [2275295803.py] Epoch 660 | Train Loss: 0.00000 | Val Loss: 2.98356 \n",
      " 13% 670/5000 [08:40<55:49,  1.29it/s]INFO     [2275295803.py] Epoch 670 | Train Loss: 0.00000 | Val Loss: 2.97855 \n",
      " 14% 680/5000 [08:47<55:49,  1.29it/s]INFO     [2275295803.py] Epoch 680 | Train Loss: 0.00000 | Val Loss: 2.99695 \n",
      " 14% 690/5000 [08:55<55:33,  1.29it/s]INFO     [2275295803.py] Epoch 690 | Train Loss: 0.00000 | Val Loss: 3.02656 \n",
      " 14% 700/5000 [09:03<55:24,  1.29it/s]INFO     [2275295803.py] Epoch 700 | Train Loss: 0.00000 | Val Loss: 3.08038 \n",
      " 14% 710/5000 [09:10<55:02,  1.30it/s]INFO     [2275295803.py] Epoch 710 | Train Loss: 0.00000 | Val Loss: 3.09061 \n",
      " 14% 720/5000 [09:18<55:00,  1.30it/s]INFO     [2275295803.py] Epoch 720 | Train Loss: 0.00000 | Val Loss: 3.05383 \n",
      " 15% 730/5000 [09:26<55:06,  1.29it/s]INFO     [2275295803.py] Epoch 730 | Train Loss: 0.00000 | Val Loss: 3.09717 \n",
      " 15% 740/5000 [09:34<55:13,  1.29it/s]INFO     [2275295803.py] Epoch 740 | Train Loss: 0.00000 | Val Loss: 3.07432 \n",
      " 15% 750/5000 [09:42<55:13,  1.28it/s]INFO     [2275295803.py] Epoch 750 | Train Loss: 0.00000 | Val Loss: 3.04082 \n",
      " 15% 760/5000 [09:49<55:04,  1.28it/s]INFO     [2275295803.py] Epoch 760 | Train Loss: 0.00000 | Val Loss: 3.04301 \n",
      " 15% 770/5000 [09:57<54:31,  1.29it/s]INFO     [2275295803.py] Epoch 770 | Train Loss: 0.00000 | Val Loss: 3.02148 \n",
      " 16% 780/5000 [10:05<54:18,  1.30it/s]INFO     [2275295803.py] Epoch 780 | Train Loss: 0.00000 | Val Loss: 3.02636 \n",
      " 16% 790/5000 [10:13<54:50,  1.28it/s]INFO     [2275295803.py] Epoch 790 | Train Loss: 0.00000 | Val Loss: 3.01954 \n",
      " 16% 800/5000 [10:20<54:24,  1.29it/s]INFO     [2275295803.py] Epoch 800 | Train Loss: 0.00000 | Val Loss: 3.00876 \n",
      " 16% 810/5000 [10:28<54:37,  1.28it/s]INFO     [2275295803.py] Epoch 810 | Train Loss: 0.00000 | Val Loss: 2.98494 \n",
      " 16% 820/5000 [10:36<54:19,  1.28it/s]INFO     [2275295803.py] Epoch 820 | Train Loss: 0.00000 | Val Loss: 2.98392 \n",
      " 17% 830/5000 [10:44<54:03,  1.29it/s]INFO     [2275295803.py] Epoch 830 | Train Loss: 0.00000 | Val Loss: 2.97265 \n",
      " 17% 840/5000 [10:52<54:10,  1.28it/s]INFO     [2275295803.py] Epoch 840 | Train Loss: 0.00000 | Val Loss: 2.97953 \n",
      " 17% 850/5000 [10:59<53:55,  1.28it/s]INFO     [2275295803.py] Epoch 850 | Train Loss: 0.00000 | Val Loss: 2.93644 \n",
      " 17% 860/5000 [11:07<53:54,  1.28it/s]INFO     [2275295803.py] Epoch 860 | Train Loss: 0.00000 | Val Loss: 2.95313 \n",
      " 17% 870/5000 [11:15<53:39,  1.28it/s]INFO     [2275295803.py] Epoch 870 | Train Loss: 0.00000 | Val Loss: 2.95249 \n",
      " 18% 880/5000 [11:23<53:41,  1.28it/s]INFO     [2275295803.py] Epoch 880 | Train Loss: 0.00000 | Val Loss: 2.96353 \n",
      " 18% 890/5000 [11:31<53:12,  1.29it/s]INFO     [2275295803.py] Epoch 890 | Train Loss: 0.00000 | Val Loss: 3.01030 \n",
      " 18% 900/5000 [11:38<53:37,  1.27it/s]INFO     [2275295803.py] Epoch 900 | Train Loss: 0.00000 | Val Loss: 3.00600 \n",
      " 18% 910/5000 [11:46<53:15,  1.28it/s]INFO     [2275295803.py] Epoch 910 | Train Loss: 0.00000 | Val Loss: 3.03566 \n",
      " 18% 920/5000 [11:54<53:17,  1.28it/s]INFO     [2275295803.py] Epoch 920 | Train Loss: 0.00000 | Val Loss: 3.06625 \n",
      " 19% 930/5000 [12:02<52:45,  1.29it/s]INFO     [2275295803.py] Epoch 930 | Train Loss: 0.00000 | Val Loss: 3.08034 \n",
      " 19% 940/5000 [12:10<52:36,  1.29it/s]INFO     [2275295803.py] Epoch 940 | Train Loss: 0.00000 | Val Loss: 3.11626 \n",
      " 19% 950/5000 [12:17<52:52,  1.28it/s]INFO     [2275295803.py] Epoch 950 | Train Loss: 0.00000 | Val Loss: 3.11166 \n",
      " 19% 960/5000 [12:25<52:30,  1.28it/s]INFO     [2275295803.py] Epoch 960 | Train Loss: 0.00000 | Val Loss: 3.14471 \n",
      " 19% 970/5000 [12:33<52:13,  1.29it/s]INFO     [2275295803.py] Epoch 970 | Train Loss: 0.00000 | Val Loss: 3.18183 \n",
      " 20% 980/5000 [12:41<52:20,  1.28it/s]INFO     [2275295803.py] Epoch 980 | Train Loss: 0.00000 | Val Loss: 3.15455 \n",
      " 20% 990/5000 [12:49<52:02,  1.28it/s]INFO     [2275295803.py] Epoch 990 | Train Loss: 0.00000 | Val Loss: 3.13497 \n",
      " 20% 1000/5000 [12:56<51:53,  1.28it/s]INFO     [2275295803.py] Epoch 1000 | Train Loss: 0.00000 | Val Loss: 3.19072 \n",
      " 20% 1010/5000 [13:04<51:25,  1.29it/s]INFO     [2275295803.py] Epoch 1010 | Train Loss: 0.00000 | Val Loss: 3.17883 \n",
      " 20% 1020/5000 [13:12<51:34,  1.29it/s]INFO     [2275295803.py] Epoch 1020 | Train Loss: 0.00000 | Val Loss: 3.23810 \n",
      " 21% 1030/5000 [13:20<51:06,  1.29it/s]INFO     [2275295803.py] Epoch 1030 | Train Loss: 0.00000 | Val Loss: 3.27822 \n",
      " 21% 1040/5000 [13:27<50:44,  1.30it/s]INFO     [2275295803.py] Epoch 1040 | Train Loss: 0.00000 | Val Loss: 3.23417 \n",
      " 21% 1050/5000 [13:35<50:48,  1.30it/s]INFO     [2275295803.py] Epoch 1050 | Train Loss: 0.00000 | Val Loss: 3.33082 \n",
      " 21% 1060/5000 [13:43<51:10,  1.28it/s]INFO     [2275295803.py] Epoch 1060 | Train Loss: 0.00000 | Val Loss: 3.27470 \n",
      " 21% 1070/5000 [13:51<51:12,  1.28it/s]INFO     [2275295803.py] Epoch 1070 | Train Loss: 0.00000 | Val Loss: 3.25259 \n",
      " 22% 1080/5000 [13:58<51:03,  1.28it/s]INFO     [2275295803.py] Epoch 1080 | Train Loss: 0.00000 | Val Loss: 3.29739 \n",
      " 22% 1090/5000 [14:06<51:06,  1.28it/s]INFO     [2275295803.py] Epoch 1090 | Train Loss: 0.00000 | Val Loss: 3.37520 \n",
      " 22% 1100/5000 [14:14<50:39,  1.28it/s]INFO     [2275295803.py] Epoch 1100 | Train Loss: 0.00000 | Val Loss: 3.47690 \n",
      " 22% 1110/5000 [14:22<50:44,  1.28it/s]INFO     [2275295803.py] Epoch 1110 | Train Loss: 0.00000 | Val Loss: 3.47915 \n",
      " 22% 1120/5000 [14:30<50:15,  1.29it/s]INFO     [2275295803.py] Epoch 1120 | Train Loss: 0.00000 | Val Loss: 3.49456 \n",
      " 23% 1130/5000 [14:37<50:23,  1.28it/s]INFO     [2275295803.py] Epoch 1130 | Train Loss: 0.00000 | Val Loss: 3.57711 \n",
      " 23% 1140/5000 [14:45<49:51,  1.29it/s]INFO     [2275295803.py] Epoch 1140 | Train Loss: 0.00000 | Val Loss: 3.54307 \n",
      " 23% 1150/5000 [14:53<49:11,  1.30it/s]INFO     [2275295803.py] Epoch 1150 | Train Loss: 0.00000 | Val Loss: 3.61245 \n",
      " 23% 1160/5000 [15:01<49:21,  1.30it/s]INFO     [2275295803.py] Epoch 1160 | Train Loss: 0.00000 | Val Loss: 3.61289 \n",
      " 23% 1170/5000 [15:08<49:20,  1.29it/s]INFO     [2275295803.py] Epoch 1170 | Train Loss: 0.00000 | Val Loss: 3.61538 \n",
      " 24% 1180/5000 [15:16<49:19,  1.29it/s]INFO     [2275295803.py] Epoch 1180 | Train Loss: 0.00000 | Val Loss: 3.63650 \n",
      " 24% 1190/5000 [15:24<48:57,  1.30it/s]INFO     [2275295803.py] Epoch 1190 | Train Loss: 0.00000 | Val Loss: 3.74708 \n",
      " 24% 1200/5000 [15:31<48:31,  1.31it/s]INFO     [2275295803.py] Epoch 1200 | Train Loss: 0.00000 | Val Loss: 3.74171 \n",
      " 24% 1210/5000 [15:39<48:42,  1.30it/s]INFO     [2275295803.py] Epoch 1210 | Train Loss: 0.00000 | Val Loss: 3.73155 \n",
      " 24% 1220/5000 [15:47<48:40,  1.29it/s]INFO     [2275295803.py] Epoch 1220 | Train Loss: 0.00000 | Val Loss: 3.77586 \n",
      " 25% 1230/5000 [15:55<48:28,  1.30it/s]INFO     [2275295803.py] Epoch 1230 | Train Loss: 0.00000 | Val Loss: 3.82105 \n",
      " 25% 1240/5000 [16:02<48:11,  1.30it/s]INFO     [2275295803.py] Epoch 1240 | Train Loss: 0.00000 | Val Loss: 3.87716 \n",
      " 25% 1250/5000 [16:10<48:13,  1.30it/s]INFO     [2275295803.py] Epoch 1250 | Train Loss: 0.00000 | Val Loss: 3.86093 \n",
      " 25% 1260/5000 [16:18<47:02,  1.32it/s]INFO     [2275295803.py] Epoch 1260 | Train Loss: 0.00000 | Val Loss: 3.73644 \n",
      " 25% 1270/5000 [16:25<48:22,  1.29it/s]INFO     [2275295803.py] Epoch 1270 | Train Loss: 0.00000 | Val Loss: 3.80755 \n",
      " 26% 1280/5000 [16:33<48:21,  1.28it/s]INFO     [2275295803.py] Epoch 1280 | Train Loss: 0.00000 | Val Loss: 3.79733 \n",
      " 26% 1290/5000 [16:41<48:19,  1.28it/s]INFO     [2275295803.py] Epoch 1290 | Train Loss: 0.00000 | Val Loss: 3.74556 \n",
      " 26% 1300/5000 [16:49<49:01,  1.26it/s]INFO     [2275295803.py] Epoch 1300 | Train Loss: 0.00000 | Val Loss: 3.72866 \n",
      " 26% 1310/5000 [16:57<47:48,  1.29it/s]INFO     [2275295803.py] Epoch 1310 | Train Loss: 0.00000 | Val Loss: 3.77073 \n",
      " 26% 1320/5000 [17:05<47:25,  1.29it/s]INFO     [2275295803.py] Epoch 1320 | Train Loss: 0.00000 | Val Loss: 3.94115 \n",
      " 27% 1330/5000 [17:12<47:26,  1.29it/s]INFO     [2275295803.py] Epoch 1330 | Train Loss: 0.00000 | Val Loss: 4.01136 \n",
      " 27% 1340/5000 [17:20<47:32,  1.28it/s]INFO     [2275295803.py] Epoch 1340 | Train Loss: 0.00001 | Val Loss: 4.12434 \n",
      " 27% 1350/5000 [17:28<47:08,  1.29it/s]INFO     [2275295803.py] Epoch 1350 | Train Loss: 0.00000 | Val Loss: 4.28128 \n",
      " 27% 1360/5000 [17:36<47:07,  1.29it/s]INFO     [2275295803.py] Epoch 1360 | Train Loss: 0.00000 | Val Loss: 4.20072 \n",
      " 27% 1370/5000 [17:43<47:07,  1.28it/s]INFO     [2275295803.py] Epoch 1370 | Train Loss: 0.00000 | Val Loss: 4.19072 \n",
      " 28% 1380/5000 [17:51<46:59,  1.28it/s]INFO     [2275295803.py] Epoch 1380 | Train Loss: 0.00000 | Val Loss: 4.21246 \n",
      " 28% 1390/5000 [17:59<46:37,  1.29it/s]INFO     [2275295803.py] Epoch 1390 | Train Loss: 0.00000 | Val Loss: 4.17422 \n",
      " 28% 1400/5000 [18:07<46:32,  1.29it/s]INFO     [2275295803.py] Epoch 1400 | Train Loss: 0.00000 | Val Loss: 4.07199 \n",
      " 28% 1410/5000 [18:14<46:07,  1.30it/s]INFO     [2275295803.py] Epoch 1410 | Train Loss: 0.00000 | Val Loss: 4.51455 \n",
      " 28% 1420/5000 [18:22<46:15,  1.29it/s]INFO     [2275295803.py] Epoch 1420 | Train Loss: 0.00000 | Val Loss: 4.62045 \n",
      " 29% 1430/5000 [18:30<46:22,  1.28it/s]INFO     [2275295803.py] Epoch 1430 | Train Loss: 0.00000 | Val Loss: 4.72197 \n",
      " 29% 1440/5000 [18:38<47:04,  1.26it/s]INFO     [2275295803.py] Epoch 1440 | Train Loss: 0.00000 | Val Loss: 4.82981 \n",
      " 29% 1450/5000 [18:46<46:51,  1.26it/s]INFO     [2275295803.py] Epoch 1450 | Train Loss: 0.00000 | Val Loss: 4.82628 \n",
      " 29% 1460/5000 [18:54<46:23,  1.27it/s]INFO     [2275295803.py] Epoch 1460 | Train Loss: 0.00000 | Val Loss: 4.71088 \n",
      " 29% 1470/5000 [19:01<46:20,  1.27it/s]INFO     [2275295803.py] Epoch 1470 | Train Loss: 0.00000 | Val Loss: 4.54385 \n",
      " 30% 1480/5000 [19:09<46:05,  1.27it/s]INFO     [2275295803.py] Epoch 1480 | Train Loss: 0.00000 | Val Loss: 4.52860 \n",
      " 30% 1490/5000 [19:17<45:42,  1.28it/s]INFO     [2275295803.py] Epoch 1490 | Train Loss: 0.00000 | Val Loss: 4.71986 \n",
      " 30% 1500/5000 [19:25<45:41,  1.28it/s]INFO     [2275295803.py] Epoch 1500 | Train Loss: 0.00000 | Val Loss: 4.82455 \n",
      " 30% 1510/5000 [19:33<45:38,  1.27it/s]INFO     [2275295803.py] Epoch 1510 | Train Loss: 0.00000 | Val Loss: 4.93978 \n",
      " 30% 1520/5000 [19:41<45:49,  1.27it/s]INFO     [2275295803.py] Epoch 1520 | Train Loss: 0.00000 | Val Loss: 4.95127 \n",
      " 31% 1530/5000 [19:49<45:22,  1.27it/s]INFO     [2275295803.py] Epoch 1530 | Train Loss: 0.00000 | Val Loss: 4.71085 \n",
      " 31% 1540/5000 [19:56<45:03,  1.28it/s]INFO     [2275295803.py] Epoch 1540 | Train Loss: 0.00000 | Val Loss: 4.96044 \n",
      " 31% 1550/5000 [20:04<44:48,  1.28it/s]INFO     [2275295803.py] Epoch 1550 | Train Loss: 0.00000 | Val Loss: 4.96111 \n",
      " 31% 1560/5000 [20:12<44:30,  1.29it/s]INFO     [2275295803.py] Epoch 1560 | Train Loss: 0.00000 | Val Loss: 4.87507 \n",
      " 31% 1570/5000 [20:20<44:31,  1.28it/s]INFO     [2275295803.py] Epoch 1570 | Train Loss: 0.00000 | Val Loss: 5.10154 \n",
      " 32% 1580/5000 [20:28<44:23,  1.28it/s]INFO     [2275295803.py] Epoch 1580 | Train Loss: 0.00000 | Val Loss: 4.94206 \n",
      " 32% 1590/5000 [20:35<44:23,  1.28it/s]INFO     [2275295803.py] Epoch 1590 | Train Loss: 0.00000 | Val Loss: 5.01624 \n",
      " 32% 1600/5000 [20:43<44:40,  1.27it/s]INFO     [2275295803.py] Epoch 1600 | Train Loss: 0.00000 | Val Loss: 4.77406 \n",
      " 32% 1610/5000 [20:51<44:21,  1.27it/s]INFO     [2275295803.py] Epoch 1610 | Train Loss: 0.00000 | Val Loss: 4.89699 \n",
      " 32% 1620/5000 [20:59<44:16,  1.27it/s]INFO     [2275295803.py] Epoch 1620 | Train Loss: 0.00000 | Val Loss: 5.05567 \n",
      " 33% 1630/5000 [21:07<44:13,  1.27it/s]INFO     [2275295803.py] Epoch 1630 | Train Loss: 0.00001 | Val Loss: 5.06598 \n",
      " 33% 1640/5000 [21:15<44:05,  1.27it/s]INFO     [2275295803.py] Epoch 1640 | Train Loss: 0.00000 | Val Loss: 5.08878 \n",
      " 33% 1650/5000 [21:23<43:53,  1.27it/s]INFO     [2275295803.py] Epoch 1650 | Train Loss: 0.00000 | Val Loss: 5.23328 \n",
      " 33% 1660/5000 [21:30<43:37,  1.28it/s]INFO     [2275295803.py] Epoch 1660 | Train Loss: 0.00000 | Val Loss: 5.19374 \n",
      " 33% 1670/5000 [21:38<43:31,  1.28it/s]INFO     [2275295803.py] Epoch 1670 | Train Loss: 0.00000 | Val Loss: 5.23594 \n",
      " 34% 1680/5000 [21:46<43:27,  1.27it/s]INFO     [2275295803.py] Epoch 1680 | Train Loss: 0.00000 | Val Loss: 4.72146 \n",
      " 34% 1690/5000 [21:54<41:09,  1.34it/s]INFO     [2275295803.py] Epoch 1690 | Train Loss: 0.00000 | Val Loss: 4.59117 \n",
      " 34% 1700/5000 [22:01<40:45,  1.35it/s]INFO     [2275295803.py] Epoch 1700 | Train Loss: 0.00000 | Val Loss: 4.71080 \n",
      " 34% 1710/5000 [22:09<41:53,  1.31it/s]INFO     [2275295803.py] Epoch 1710 | Train Loss: 0.00000 | Val Loss: 4.79258 \n",
      " 34% 1720/5000 [22:16<42:56,  1.27it/s]INFO     [2275295803.py] Epoch 1720 | Train Loss: 0.00000 | Val Loss: 5.06107 \n",
      " 35% 1730/5000 [22:24<42:49,  1.27it/s]INFO     [2275295803.py] Epoch 1730 | Train Loss: 0.00000 | Val Loss: 5.02038 \n",
      " 35% 1740/5000 [22:32<42:43,  1.27it/s]INFO     [2275295803.py] Epoch 1740 | Train Loss: 0.00000 | Val Loss: 5.10196 \n",
      " 35% 1750/5000 [22:40<42:24,  1.28it/s]INFO     [2275295803.py] Epoch 1750 | Train Loss: 0.00000 | Val Loss: 4.91104 \n",
      " 35% 1760/5000 [22:48<42:11,  1.28it/s]INFO     [2275295803.py] Epoch 1760 | Train Loss: 0.00000 | Val Loss: 4.95360 \n",
      " 35% 1770/5000 [22:56<42:09,  1.28it/s]INFO     [2275295803.py] Epoch 1770 | Train Loss: 0.00000 | Val Loss: 5.18314 \n",
      " 36% 1780/5000 [23:04<42:04,  1.28it/s]INFO     [2275295803.py] Epoch 1780 | Train Loss: 0.00000 | Val Loss: 5.20065 \n",
      " 36% 1790/5000 [23:11<41:58,  1.27it/s]INFO     [2275295803.py] Epoch 1790 | Train Loss: 0.00000 | Val Loss: 5.01670 \n",
      " 36% 1800/5000 [23:19<41:59,  1.27it/s]INFO     [2275295803.py] Epoch 1800 | Train Loss: 0.00000 | Val Loss: 5.08184 \n",
      " 36% 1810/5000 [23:27<41:51,  1.27it/s]INFO     [2275295803.py] Epoch 1810 | Train Loss: 0.00000 | Val Loss: 5.35107 \n",
      " 36% 1820/5000 [23:35<41:38,  1.27it/s]INFO     [2275295803.py] Epoch 1820 | Train Loss: 0.00000 | Val Loss: 5.31900 \n",
      " 37% 1830/5000 [23:43<41:23,  1.28it/s]INFO     [2275295803.py] Epoch 1830 | Train Loss: 0.00000 | Val Loss: 5.20255 \n",
      " 37% 1840/5000 [23:51<41:24,  1.27it/s]INFO     [2275295803.py] Epoch 1840 | Train Loss: 0.00000 | Val Loss: 5.25955 \n",
      " 37% 1850/5000 [23:58<40:54,  1.28it/s]INFO     [2275295803.py] Epoch 1850 | Train Loss: 0.00000 | Val Loss: 5.82440 \n",
      " 37% 1860/5000 [24:06<40:48,  1.28it/s]INFO     [2275295803.py] Epoch 1860 | Train Loss: 0.00000 | Val Loss: 5.87229 \n",
      " 37% 1870/5000 [24:14<40:44,  1.28it/s]INFO     [2275295803.py] Epoch 1870 | Train Loss: 0.00000 | Val Loss: 5.43271 \n",
      " 38% 1880/5000 [24:22<40:33,  1.28it/s]INFO     [2275295803.py] Epoch 1880 | Train Loss: 0.00000 | Val Loss: 5.46947 \n",
      " 38% 1890/5000 [24:30<40:25,  1.28it/s]INFO     [2275295803.py] Epoch 1890 | Train Loss: 0.00000 | Val Loss: 5.31483 \n",
      " 38% 1900/5000 [24:37<40:26,  1.28it/s]INFO     [2275295803.py] Epoch 1900 | Train Loss: 0.00000 | Val Loss: 5.16930 \n",
      " 38% 1910/5000 [24:45<40:15,  1.28it/s]INFO     [2275295803.py] Epoch 1910 | Train Loss: 0.00000 | Val Loss: 5.38557 \n",
      " 38% 1920/5000 [24:53<40:13,  1.28it/s]INFO     [2275295803.py] Epoch 1920 | Train Loss: 0.00000 | Val Loss: 5.83397 \n",
      " 39% 1930/5000 [25:01<39:54,  1.28it/s]INFO     [2275295803.py] Epoch 1930 | Train Loss: 0.00000 | Val Loss: 5.67490 \n",
      " 39% 1940/5000 [25:09<39:45,  1.28it/s]INFO     [2275295803.py] Epoch 1940 | Train Loss: 0.00000 | Val Loss: 5.94768 \n",
      " 39% 1950/5000 [25:17<39:38,  1.28it/s]INFO     [2275295803.py] Epoch 1950 | Train Loss: 0.00000 | Val Loss: 6.36591 \n",
      " 39% 1960/5000 [25:24<39:26,  1.28it/s]INFO     [2275295803.py] Epoch 1960 | Train Loss: 0.00000 | Val Loss: 6.27772 \n",
      " 39% 1970/5000 [25:32<39:31,  1.28it/s]INFO     [2275295803.py] Epoch 1970 | Train Loss: 0.00000 | Val Loss: 6.07422 \n",
      " 40% 1980/5000 [25:40<39:48,  1.26it/s]INFO     [2275295803.py] Epoch 1980 | Train Loss: 0.00000 | Val Loss: 6.67612 \n",
      " 40% 1990/5000 [25:48<39:38,  1.27it/s]INFO     [2275295803.py] Epoch 1990 | Train Loss: 0.00000 | Val Loss: 6.19267 \n",
      " 40% 2000/5000 [25:56<39:15,  1.27it/s]INFO     [2275295803.py] Epoch 2000 | Train Loss: 0.00000 | Val Loss: 6.24350 \n",
      " 40% 2010/5000 [26:04<39:20,  1.27it/s]INFO     [2275295803.py] Epoch 2010 | Train Loss: 0.00000 | Val Loss: 6.17219 \n",
      " 40% 2020/5000 [26:11<38:56,  1.28it/s]INFO     [2275295803.py] Epoch 2020 | Train Loss: 0.00000 | Val Loss: 5.93517 \n",
      " 41% 2030/5000 [26:19<38:53,  1.27it/s]INFO     [2275295803.py] Epoch 2030 | Train Loss: 0.00000 | Val Loss: 6.15681 \n",
      " 41% 2040/5000 [26:27<38:43,  1.27it/s]INFO     [2275295803.py] Epoch 2040 | Train Loss: 0.00000 | Val Loss: 6.14279 \n",
      " 41% 2050/5000 [26:35<38:32,  1.28it/s]INFO     [2275295803.py] Epoch 2050 | Train Loss: 0.00000 | Val Loss: 6.41995 \n",
      " 41% 2060/5000 [26:43<38:36,  1.27it/s]INFO     [2275295803.py] Epoch 2060 | Train Loss: 0.00000 | Val Loss: 7.36973 \n",
      " 41% 2070/5000 [26:51<38:21,  1.27it/s]INFO     [2275295803.py] Epoch 2070 | Train Loss: 0.00000 | Val Loss: 7.14274 \n",
      " 42% 2080/5000 [26:59<38:19,  1.27it/s]INFO     [2275295803.py] Epoch 2080 | Train Loss: 0.00000 | Val Loss: 7.48073 \n",
      " 42% 2090/5000 [27:07<38:15,  1.27it/s]INFO     [2275295803.py] Epoch 2090 | Train Loss: 0.00000 | Val Loss: 6.62579 \n",
      " 42% 2100/5000 [27:14<37:57,  1.27it/s]INFO     [2275295803.py] Epoch 2100 | Train Loss: 0.00000 | Val Loss: 6.36247 \n",
      " 42% 2110/5000 [27:22<37:50,  1.27it/s]INFO     [2275295803.py] Epoch 2110 | Train Loss: 0.00000 | Val Loss: 6.36224 \n",
      " 42% 2120/5000 [27:30<37:35,  1.28it/s]INFO     [2275295803.py] Epoch 2120 | Train Loss: 0.00000 | Val Loss: 6.55705 \n",
      " 43% 2130/5000 [27:38<37:31,  1.27it/s]INFO     [2275295803.py] Epoch 2130 | Train Loss: 0.00000 | Val Loss: 6.45352 \n",
      " 43% 2140/5000 [27:46<37:17,  1.28it/s]INFO     [2275295803.py] Epoch 2140 | Train Loss: 0.00000 | Val Loss: 7.12773 \n",
      " 43% 2150/5000 [27:54<37:11,  1.28it/s]INFO     [2275295803.py] Epoch 2150 | Train Loss: 0.00000 | Val Loss: 6.26883 \n",
      " 43% 2160/5000 [28:01<37:00,  1.28it/s]INFO     [2275295803.py] Epoch 2160 | Train Loss: 0.00000 | Val Loss: 6.08903 \n",
      " 43% 2170/5000 [28:09<36:55,  1.28it/s]INFO     [2275295803.py] Epoch 2170 | Train Loss: 0.00000 | Val Loss: 5.81766 \n",
      " 44% 2180/5000 [28:17<36:49,  1.28it/s]INFO     [2275295803.py] Epoch 2180 | Train Loss: 0.00000 | Val Loss: 5.82184 \n",
      " 44% 2190/5000 [28:25<36:30,  1.28it/s]INFO     [2275295803.py] Epoch 2190 | Train Loss: 0.00000 | Val Loss: 5.77589 \n",
      " 44% 2200/5000 [28:33<36:26,  1.28it/s]INFO     [2275295803.py] Epoch 2200 | Train Loss: 0.00000 | Val Loss: 5.79104 \n",
      " 44% 2210/5000 [28:40<36:19,  1.28it/s]INFO     [2275295803.py] Epoch 2210 | Train Loss: 0.00000 | Val Loss: 6.09882 \n",
      " 44% 2220/5000 [28:48<36:12,  1.28it/s]INFO     [2275295803.py] Epoch 2220 | Train Loss: 0.00000 | Val Loss: 5.79513 \n",
      " 45% 2230/5000 [28:56<36:01,  1.28it/s]INFO     [2275295803.py] Epoch 2230 | Train Loss: 0.00000 | Val Loss: 5.77788 \n",
      " 45% 2240/5000 [29:04<36:39,  1.25it/s]INFO     [2275295803.py] Epoch 2240 | Train Loss: 0.00000 | Val Loss: 5.63165 \n",
      " 45% 2250/5000 [29:12<36:15,  1.26it/s]INFO     [2275295803.py] Epoch 2250 | Train Loss: 0.00000 | Val Loss: 5.84464 \n",
      " 45% 2260/5000 [29:20<36:06,  1.26it/s]INFO     [2275295803.py] Epoch 2260 | Train Loss: 0.00000 | Val Loss: 5.79277 \n",
      " 45% 2270/5000 [29:28<35:53,  1.27it/s]INFO     [2275295803.py] Epoch 2270 | Train Loss: 0.00000 | Val Loss: 5.74930 \n",
      " 46% 2280/5000 [29:36<35:32,  1.28it/s]INFO     [2275295803.py] Epoch 2280 | Train Loss: 0.00000 | Val Loss: 5.92917 \n",
      " 46% 2290/5000 [29:43<35:25,  1.28it/s]INFO     [2275295803.py] Epoch 2290 | Train Loss: 0.00000 | Val Loss: 5.59479 \n",
      " 46% 2300/5000 [29:51<35:23,  1.27it/s]INFO     [2275295803.py] Epoch 2300 | Train Loss: 0.00000 | Val Loss: 5.40712 \n",
      " 46% 2310/5000 [29:59<35:16,  1.27it/s]INFO     [2275295803.py] Epoch 2310 | Train Loss: 0.00000 | Val Loss: 5.97160 \n",
      " 46% 2320/5000 [30:07<35:16,  1.27it/s]INFO     [2275295803.py] Epoch 2320 | Train Loss: 0.00000 | Val Loss: 5.83146 \n",
      " 47% 2330/5000 [30:15<35:02,  1.27it/s]INFO     [2275295803.py] Epoch 2330 | Train Loss: 0.00000 | Val Loss: 5.68950 \n",
      " 47% 2340/5000 [30:23<34:56,  1.27it/s]INFO     [2275295803.py] Epoch 2340 | Train Loss: 0.00000 | Val Loss: 5.77994 \n",
      " 47% 2350/5000 [30:31<34:53,  1.27it/s]INFO     [2275295803.py] Epoch 2350 | Train Loss: 0.00000 | Val Loss: 5.73975 \n",
      " 47% 2360/5000 [30:39<34:41,  1.27it/s]INFO     [2275295803.py] Epoch 2360 | Train Loss: 0.00000 | Val Loss: 5.77579 \n",
      " 47% 2370/5000 [30:46<34:22,  1.28it/s]INFO     [2275295803.py] Epoch 2370 | Train Loss: 0.00000 | Val Loss: 5.96119 \n",
      " 48% 2380/5000 [30:54<34:07,  1.28it/s]INFO     [2275295803.py] Epoch 2380 | Train Loss: 0.00000 | Val Loss: 6.03566 \n",
      " 48% 2390/5000 [31:02<34:03,  1.28it/s]INFO     [2275295803.py] Epoch 2390 | Train Loss: 0.00000 | Val Loss: 6.37415 \n",
      " 48% 2400/5000 [31:10<33:54,  1.28it/s]INFO     [2275295803.py] Epoch 2400 | Train Loss: 0.00000 | Val Loss: 6.24875 \n",
      " 48% 2410/5000 [31:18<33:42,  1.28it/s]INFO     [2275295803.py] Epoch 2410 | Train Loss: 0.00000 | Val Loss: 6.00765 \n",
      " 48% 2420/5000 [31:26<33:44,  1.27it/s]INFO     [2275295803.py] Epoch 2420 | Train Loss: 0.00000 | Val Loss: 6.03040 \n",
      " 49% 2430/5000 [31:33<33:37,  1.27it/s]INFO     [2275295803.py] Epoch 2430 | Train Loss: 0.00000 | Val Loss: 5.80936 \n",
      " 49% 2440/5000 [31:41<33:39,  1.27it/s]INFO     [2275295803.py] Epoch 2440 | Train Loss: 0.00000 | Val Loss: 5.75179 \n",
      " 49% 2450/5000 [31:49<34:02,  1.25it/s]INFO     [2275295803.py] Epoch 2450 | Train Loss: 0.00000 | Val Loss: 6.14632 \n",
      " 49% 2460/5000 [31:57<33:14,  1.27it/s]INFO     [2275295803.py] Epoch 2460 | Train Loss: 0.00000 | Val Loss: 5.98633 \n",
      " 49% 2470/5000 [32:05<31:05,  1.36it/s]INFO     [2275295803.py] Epoch 2470 | Train Loss: 0.00000 | Val Loss: 6.74436 \n",
      " 50% 2480/5000 [32:12<30:19,  1.38it/s]INFO     [2275295803.py] Epoch 2480 | Train Loss: 0.00000 | Val Loss: 6.38428 \n",
      " 50% 2490/5000 [32:20<32:25,  1.29it/s]INFO     [2275295803.py] Epoch 2490 | Train Loss: 0.00000 | Val Loss: 6.38669 \n",
      " 50% 2500/5000 [32:27<32:26,  1.28it/s]INFO     [2275295803.py] Epoch 2500 | Train Loss: 0.00000 | Val Loss: 6.03470 \n",
      " 50% 2510/5000 [32:35<32:24,  1.28it/s]INFO     [2275295803.py] Epoch 2510 | Train Loss: 0.00000 | Val Loss: 6.04949 \n",
      " 50% 2520/5000 [32:43<33:43,  1.23it/s]INFO     [2275295803.py] Epoch 2520 | Train Loss: 0.00000 | Val Loss: 5.54076 \n",
      " 51% 2530/5000 [32:51<32:15,  1.28it/s]INFO     [2275295803.py] Epoch 2530 | Train Loss: 0.00000 | Val Loss: 5.67244 \n",
      " 51% 2540/5000 [32:59<32:04,  1.28it/s]INFO     [2275295803.py] Epoch 2540 | Train Loss: 0.00000 | Val Loss: 5.51016 \n",
      " 51% 2550/5000 [33:07<31:53,  1.28it/s]INFO     [2275295803.py] Epoch 2550 | Train Loss: 0.00000 | Val Loss: 5.48968 \n",
      " 51% 2560/5000 [33:15<31:51,  1.28it/s]INFO     [2275295803.py] Epoch 2560 | Train Loss: 0.00000 | Val Loss: 5.59248 \n",
      " 51% 2570/5000 [33:22<31:39,  1.28it/s]INFO     [2275295803.py] Epoch 2570 | Train Loss: 0.00000 | Val Loss: 5.69746 \n",
      " 52% 2580/5000 [33:30<31:31,  1.28it/s]INFO     [2275295803.py] Epoch 2580 | Train Loss: 0.00000 | Val Loss: 5.65645 \n",
      " 52% 2590/5000 [33:38<31:23,  1.28it/s]INFO     [2275295803.py] Epoch 2590 | Train Loss: 0.00000 | Val Loss: 5.49805 \n",
      " 52% 2600/5000 [33:46<31:15,  1.28it/s]INFO     [2275295803.py] Epoch 2600 | Train Loss: 0.00000 | Val Loss: 5.66734 \n",
      " 52% 2610/5000 [33:54<31:19,  1.27it/s]INFO     [2275295803.py] Epoch 2610 | Train Loss: 0.00000 | Val Loss: 5.92963 \n",
      " 52% 2620/5000 [34:01<31:10,  1.27it/s]INFO     [2275295803.py] Epoch 2620 | Train Loss: 0.00000 | Val Loss: 5.42773 \n",
      " 53% 2630/5000 [34:09<30:53,  1.28it/s]INFO     [2275295803.py] Epoch 2630 | Train Loss: 0.00000 | Val Loss: 5.41064 \n",
      " 53% 2640/5000 [34:17<30:43,  1.28it/s]INFO     [2275295803.py] Epoch 2640 | Train Loss: 0.00000 | Val Loss: 5.46507 \n",
      " 53% 2650/5000 [34:25<30:46,  1.27it/s]INFO     [2275295803.py] Epoch 2650 | Train Loss: 0.00000 | Val Loss: 5.39010 \n",
      " 53% 2660/5000 [34:33<30:31,  1.28it/s]INFO     [2275295803.py] Epoch 2660 | Train Loss: 0.00000 | Val Loss: 5.42711 \n",
      " 53% 2670/5000 [34:41<30:25,  1.28it/s]INFO     [2275295803.py] Epoch 2670 | Train Loss: 0.00000 | Val Loss: 5.24865 \n",
      " 54% 2680/5000 [34:49<30:20,  1.27it/s]INFO     [2275295803.py] Epoch 2680 | Train Loss: 0.00000 | Val Loss: 5.31638 \n",
      " 54% 2690/5000 [34:56<30:08,  1.28it/s]INFO     [2275295803.py] Epoch 2690 | Train Loss: 0.00000 | Val Loss: 5.55425 \n",
      " 54% 2700/5000 [35:04<30:05,  1.27it/s]INFO     [2275295803.py] Epoch 2700 | Train Loss: 0.00000 | Val Loss: 5.93996 \n",
      " 54% 2710/5000 [35:12<30:08,  1.27it/s]INFO     [2275295803.py] Epoch 2710 | Train Loss: 0.00000 | Val Loss: 5.96907 \n",
      " 54% 2720/5000 [35:20<29:52,  1.27it/s]INFO     [2275295803.py] Epoch 2720 | Train Loss: 0.00000 | Val Loss: 6.29118 \n",
      " 55% 2730/5000 [35:28<29:40,  1.27it/s]INFO     [2275295803.py] Epoch 2730 | Train Loss: 0.00000 | Val Loss: 5.46199 \n",
      " 55% 2740/5000 [35:36<29:31,  1.28it/s]INFO     [2275295803.py] Epoch 2740 | Train Loss: 0.00000 | Val Loss: 5.56140 \n",
      " 55% 2750/5000 [35:43<29:15,  1.28it/s]INFO     [2275295803.py] Epoch 2750 | Train Loss: 0.00000 | Val Loss: 5.56355 \n",
      " 55% 2760/5000 [35:51<29:10,  1.28it/s]INFO     [2275295803.py] Epoch 2760 | Train Loss: 0.00000 | Val Loss: 5.77376 \n",
      " 55% 2770/5000 [35:59<29:15,  1.27it/s]INFO     [2275295803.py] Epoch 2770 | Train Loss: 0.00000 | Val Loss: 5.90317 \n",
      " 56% 2780/5000 [36:07<29:03,  1.27it/s]INFO     [2275295803.py] Epoch 2780 | Train Loss: 0.00000 | Val Loss: 6.33024 \n",
      " 56% 2790/5000 [36:15<29:02,  1.27it/s]INFO     [2275295803.py] Epoch 2790 | Train Loss: 0.00000 | Val Loss: 6.35415 \n",
      " 56% 2800/5000 [36:23<28:56,  1.27it/s]INFO     [2275295803.py] Epoch 2800 | Train Loss: 0.00000 | Val Loss: 6.21125 \n",
      " 56% 2810/5000 [36:31<28:45,  1.27it/s]INFO     [2275295803.py] Epoch 2810 | Train Loss: 0.00001 | Val Loss: 5.84320 \n",
      " 56% 2820/5000 [36:39<28:35,  1.27it/s]INFO     [2275295803.py] Epoch 2820 | Train Loss: 0.00000 | Val Loss: 5.75404 \n",
      " 57% 2830/5000 [36:46<28:23,  1.27it/s]INFO     [2275295803.py] Epoch 2830 | Train Loss: 0.00000 | Val Loss: 5.54791 \n",
      " 57% 2840/5000 [36:54<28:21,  1.27it/s]INFO     [2275295803.py] Epoch 2840 | Train Loss: 0.00000 | Val Loss: 5.59077 \n",
      " 57% 2850/5000 [37:02<28:08,  1.27it/s]INFO     [2275295803.py] Epoch 2850 | Train Loss: 0.00000 | Val Loss: 5.63979 \n",
      " 57% 2860/5000 [37:10<28:52,  1.24it/s]INFO     [2275295803.py] Epoch 2860 | Train Loss: 0.00000 | Val Loss: 6.00522 \n",
      " 57% 2870/5000 [37:18<28:37,  1.24it/s]INFO     [2275295803.py] Epoch 2870 | Train Loss: 0.00000 | Val Loss: 6.50672 \n",
      " 58% 2880/5000 [37:26<28:02,  1.26it/s]INFO     [2275295803.py] Epoch 2880 | Train Loss: 0.00000 | Val Loss: 5.94796 \n",
      " 58% 2890/5000 [37:34<28:29,  1.23it/s]INFO     [2275295803.py] Epoch 2890 | Train Loss: 0.00000 | Val Loss: 6.73149 \n",
      " 58% 2900/5000 [37:42<27:37,  1.27it/s]INFO     [2275295803.py] Epoch 2900 | Train Loss: 0.00000 | Val Loss: 6.50163 \n",
      " 58% 2910/5000 [37:50<27:35,  1.26it/s]INFO     [2275295803.py] Epoch 2910 | Train Loss: 0.00001 | Val Loss: 6.64940 \n",
      " 58% 2920/5000 [37:58<28:04,  1.23it/s]INFO     [2275295803.py] Epoch 2920 | Train Loss: 0.00000 | Val Loss: 6.52764 \n",
      " 59% 2930/5000 [38:07<27:49,  1.24it/s]INFO     [2275295803.py] Epoch 2930 | Train Loss: 0.00001 | Val Loss: 6.86160 \n",
      " 59% 2940/5000 [38:15<27:38,  1.24it/s]INFO     [2275295803.py] Epoch 2940 | Train Loss: 0.00000 | Val Loss: 6.84358 \n",
      " 59% 2950/5000 [38:23<27:27,  1.24it/s]INFO     [2275295803.py] Epoch 2950 | Train Loss: 0.00000 | Val Loss: 6.40278 \n",
      " 59% 2960/5000 [38:31<27:31,  1.23it/s]INFO     [2275295803.py] Epoch 2960 | Train Loss: 0.00000 | Val Loss: 6.36049 \n",
      " 59% 2970/5000 [38:39<27:06,  1.25it/s]INFO     [2275295803.py] Epoch 2970 | Train Loss: 0.00000 | Val Loss: 6.32425 \n",
      " 60% 2980/5000 [38:47<27:03,  1.24it/s]INFO     [2275295803.py] Epoch 2980 | Train Loss: 0.00000 | Val Loss: 6.67751 \n",
      " 60% 2990/5000 [38:55<27:00,  1.24it/s]INFO     [2275295803.py] Epoch 2990 | Train Loss: 0.00000 | Val Loss: 6.44717 \n",
      " 60% 3000/5000 [39:03<26:18,  1.27it/s]INFO     [2275295803.py] Epoch 3000 | Train Loss: 0.00000 | Val Loss: 6.87759 \n",
      " 60% 3010/5000 [39:11<26:41,  1.24it/s]INFO     [2275295803.py] Epoch 3010 | Train Loss: 0.00000 | Val Loss: 6.93941 \n",
      " 60% 3020/5000 [39:19<26:38,  1.24it/s]INFO     [2275295803.py] Epoch 3020 | Train Loss: 0.00000 | Val Loss: 7.04506 \n",
      " 61% 3030/5000 [39:27<25:53,  1.27it/s]INFO     [2275295803.py] Epoch 3030 | Train Loss: 0.00000 | Val Loss: 7.54771 \n",
      " 61% 3040/5000 [39:35<26:24,  1.24it/s]INFO     [2275295803.py] Epoch 3040 | Train Loss: 0.00000 | Val Loss: 6.80076 \n",
      " 61% 3050/5000 [39:43<26:11,  1.24it/s]INFO     [2275295803.py] Epoch 3050 | Train Loss: 0.00000 | Val Loss: 6.19489 \n",
      " 61% 3060/5000 [39:51<25:55,  1.25it/s]INFO     [2275295803.py] Epoch 3060 | Train Loss: 0.00000 | Val Loss: 6.39099 \n",
      " 61% 3070/5000 [39:59<25:24,  1.27it/s]INFO     [2275295803.py] Epoch 3070 | Train Loss: 0.00000 | Val Loss: 6.22631 \n",
      " 62% 3080/5000 [40:07<25:14,  1.27it/s]INFO     [2275295803.py] Epoch 3080 | Train Loss: 0.00000 | Val Loss: 6.04740 \n",
      " 62% 3090/5000 [40:15<24:38,  1.29it/s]INFO     [2275295803.py] Epoch 3090 | Train Loss: 0.00000 | Val Loss: 6.69130 \n",
      " 62% 3100/5000 [40:22<24:30,  1.29it/s]INFO     [2275295803.py] Epoch 3100 | Train Loss: 0.00000 | Val Loss: 6.53400 \n",
      " 62% 3110/5000 [40:30<24:17,  1.30it/s]INFO     [2275295803.py] Epoch 3110 | Train Loss: 0.00000 | Val Loss: 6.90975 \n",
      " 62% 3120/5000 [40:38<24:08,  1.30it/s]INFO     [2275295803.py] Epoch 3120 | Train Loss: 0.00000 | Val Loss: 5.91955 \n",
      " 63% 3130/5000 [40:46<24:25,  1.28it/s]INFO     [2275295803.py] Epoch 3130 | Train Loss: 0.00000 | Val Loss: 6.02442 \n",
      " 63% 3140/5000 [40:53<24:23,  1.27it/s]INFO     [2275295803.py] Epoch 3140 | Train Loss: 0.00000 | Val Loss: 6.63138 \n",
      " 63% 3150/5000 [41:01<24:15,  1.27it/s]INFO     [2275295803.py] Epoch 3150 | Train Loss: 0.00000 | Val Loss: 6.83330 \n",
      " 63% 3160/5000 [41:09<24:02,  1.28it/s]INFO     [2275295803.py] Epoch 3160 | Train Loss: 0.00000 | Val Loss: 6.50106 \n",
      " 63% 3170/5000 [41:17<23:54,  1.28it/s]INFO     [2275295803.py] Epoch 3170 | Train Loss: 0.00000 | Val Loss: 6.51203 \n",
      " 64% 3180/5000 [41:25<23:38,  1.28it/s]INFO     [2275295803.py] Epoch 3180 | Train Loss: 0.00000 | Val Loss: 7.11389 \n",
      " 64% 3190/5000 [41:33<23:24,  1.29it/s]INFO     [2275295803.py] Epoch 3190 | Train Loss: 0.00000 | Val Loss: 6.67594 \n",
      " 64% 3200/5000 [41:40<23:14,  1.29it/s]INFO     [2275295803.py] Epoch 3200 | Train Loss: 0.00000 | Val Loss: 6.05445 \n",
      " 64% 3210/5000 [41:48<23:04,  1.29it/s]INFO     [2275295803.py] Epoch 3210 | Train Loss: 0.00000 | Val Loss: 6.61966 \n",
      " 64% 3220/5000 [41:56<22:59,  1.29it/s]INFO     [2275295803.py] Epoch 3220 | Train Loss: 0.00000 | Val Loss: 6.62336 \n",
      " 65% 3230/5000 [42:04<22:47,  1.29it/s]INFO     [2275295803.py] Epoch 3230 | Train Loss: 0.00000 | Val Loss: 6.21840 \n",
      " 65% 3240/5000 [42:11<22:36,  1.30it/s]INFO     [2275295803.py] Epoch 3240 | Train Loss: 0.00000 | Val Loss: 6.13011 \n",
      " 65% 3250/5000 [42:19<22:38,  1.29it/s]INFO     [2275295803.py] Epoch 3250 | Train Loss: 0.00000 | Val Loss: 5.72470 \n",
      " 65% 3260/5000 [42:27<22:23,  1.29it/s]INFO     [2275295803.py] Epoch 3260 | Train Loss: 0.00000 | Val Loss: 5.73628 \n",
      " 65% 3270/5000 [42:34<22:14,  1.30it/s]INFO     [2275295803.py] Epoch 3270 | Train Loss: 0.00000 | Val Loss: 5.83928 \n",
      " 66% 3280/5000 [42:42<22:08,  1.29it/s]INFO     [2275295803.py] Epoch 3280 | Train Loss: 0.00000 | Val Loss: 6.12958 \n",
      " 66% 3290/5000 [42:50<22:05,  1.29it/s]INFO     [2275295803.py] Epoch 3290 | Train Loss: 0.00000 | Val Loss: 5.74777 \n",
      " 66% 3300/5000 [42:58<21:55,  1.29it/s]INFO     [2275295803.py] Epoch 3300 | Train Loss: 0.00000 | Val Loss: 5.92349 \n",
      " 66% 3310/5000 [43:05<21:42,  1.30it/s]INFO     [2275295803.py] Epoch 3310 | Train Loss: 0.00000 | Val Loss: 5.98327 \n",
      " 66% 3320/5000 [43:13<21:59,  1.27it/s]INFO     [2275295803.py] Epoch 3320 | Train Loss: 0.00000 | Val Loss: 6.00141 \n",
      " 67% 3330/5000 [43:21<21:53,  1.27it/s]INFO     [2275295803.py] Epoch 3330 | Train Loss: 0.00000 | Val Loss: 6.20313 \n",
      " 67% 3340/5000 [43:29<21:38,  1.28it/s]INFO     [2275295803.py] Epoch 3340 | Train Loss: 0.00000 | Val Loss: 6.33311 \n",
      " 67% 3350/5000 [43:37<21:37,  1.27it/s]INFO     [2275295803.py] Epoch 3350 | Train Loss: 0.00000 | Val Loss: 6.02189 \n",
      " 67% 3360/5000 [43:45<21:30,  1.27it/s]INFO     [2275295803.py] Epoch 3360 | Train Loss: 0.00000 | Val Loss: 5.79678 \n",
      " 67% 3370/5000 [43:53<21:32,  1.26it/s]INFO     [2275295803.py] Epoch 3370 | Train Loss: 0.00000 | Val Loss: 5.93236 \n",
      " 68% 3380/5000 [44:00<20:47,  1.30it/s]INFO     [2275295803.py] Epoch 3380 | Train Loss: 0.00000 | Val Loss: 5.87295 \n",
      " 68% 3390/5000 [44:08<20:44,  1.29it/s]INFO     [2275295803.py] Epoch 3390 | Train Loss: 0.00000 | Val Loss: 5.61889 \n",
      " 68% 3400/5000 [44:16<20:55,  1.27it/s]INFO     [2275295803.py] Epoch 3400 | Train Loss: 0.00000 | Val Loss: 5.65398 \n",
      " 68% 3410/5000 [44:24<20:46,  1.28it/s]INFO     [2275295803.py] Epoch 3410 | Train Loss: 0.00000 | Val Loss: 5.55130 \n",
      " 68% 3420/5000 [44:32<20:43,  1.27it/s]INFO     [2275295803.py] Epoch 3420 | Train Loss: 0.00000 | Val Loss: 5.40168 \n",
      " 69% 3430/5000 [44:40<20:35,  1.27it/s]INFO     [2275295803.py] Epoch 3430 | Train Loss: 0.00000 | Val Loss: 5.41132 \n",
      " 69% 3440/5000 [44:47<20:17,  1.28it/s]INFO     [2275295803.py] Epoch 3440 | Train Loss: 0.00000 | Val Loss: 5.33349 \n",
      " 69% 3450/5000 [44:55<20:16,  1.27it/s]INFO     [2275295803.py] Epoch 3450 | Train Loss: 0.00000 | Val Loss: 5.28661 \n",
      " 69% 3460/5000 [45:03<20:07,  1.28it/s]INFO     [2275295803.py] Epoch 3460 | Train Loss: 0.00000 | Val Loss: 5.39509 \n",
      " 69% 3470/5000 [45:11<19:54,  1.28it/s]INFO     [2275295803.py] Epoch 3470 | Train Loss: 0.00000 | Val Loss: 5.65725 \n",
      " 70% 3480/5000 [45:19<19:45,  1.28it/s]INFO     [2275295803.py] Epoch 3480 | Train Loss: 0.00000 | Val Loss: 5.57113 \n",
      " 70% 3490/5000 [45:26<19:40,  1.28it/s]INFO     [2275295803.py] Epoch 3490 | Train Loss: 0.00000 | Val Loss: 5.82711 \n",
      " 70% 3500/5000 [45:34<19:31,  1.28it/s]INFO     [2275295803.py] Epoch 3500 | Train Loss: 0.00000 | Val Loss: 5.65178 \n",
      " 70% 3510/5000 [45:42<19:28,  1.28it/s]INFO     [2275295803.py] Epoch 3510 | Train Loss: 0.00000 | Val Loss: 6.08402 \n",
      " 70% 3520/5000 [45:50<19:02,  1.30it/s]INFO     [2275295803.py] Epoch 3520 | Train Loss: 0.00000 | Val Loss: 6.08883 \n",
      " 71% 3530/5000 [45:58<18:54,  1.30it/s]INFO     [2275295803.py] Epoch 3530 | Train Loss: 0.00000 | Val Loss: 5.73350 \n",
      " 71% 3540/5000 [46:05<18:50,  1.29it/s]INFO     [2275295803.py] Epoch 3540 | Train Loss: 0.00000 | Val Loss: 5.99670 \n",
      " 71% 3550/5000 [46:13<18:34,  1.30it/s]INFO     [2275295803.py] Epoch 3550 | Train Loss: 0.00000 | Val Loss: 6.31868 \n",
      " 71% 3560/5000 [46:21<18:30,  1.30it/s]INFO     [2275295803.py] Epoch 3560 | Train Loss: 0.00000 | Val Loss: 6.02553 \n",
      " 71% 3570/5000 [46:28<18:22,  1.30it/s]INFO     [2275295803.py] Epoch 3570 | Train Loss: 0.00000 | Val Loss: 5.91623 \n",
      " 72% 3580/5000 [46:36<18:17,  1.29it/s]INFO     [2275295803.py] Epoch 3580 | Train Loss: 0.00000 | Val Loss: 5.66558 \n",
      " 72% 3590/5000 [46:44<18:05,  1.30it/s]INFO     [2275295803.py] Epoch 3590 | Train Loss: 0.00000 | Val Loss: 5.63833 \n",
      " 72% 3600/5000 [46:52<18:03,  1.29it/s]INFO     [2275295803.py] Epoch 3600 | Train Loss: 0.00000 | Val Loss: 5.64341 \n",
      " 72% 3610/5000 [46:59<17:57,  1.29it/s]INFO     [2275295803.py] Epoch 3610 | Train Loss: 0.00000 | Val Loss: 5.46990 \n",
      " 72% 3620/5000 [47:07<17:59,  1.28it/s]INFO     [2275295803.py] Epoch 3620 | Train Loss: 0.00000 | Val Loss: 5.59028 \n",
      " 73% 3630/5000 [47:15<17:58,  1.27it/s]INFO     [2275295803.py] Epoch 3630 | Train Loss: 0.00000 | Val Loss: 5.63388 \n",
      " 73% 3640/5000 [47:23<17:45,  1.28it/s]INFO     [2275295803.py] Epoch 3640 | Train Loss: 0.00000 | Val Loss: 5.52093 \n",
      " 73% 3650/5000 [47:30<16:37,  1.35it/s]INFO     [2275295803.py] Epoch 3650 | Train Loss: 0.00000 | Val Loss: 5.61141 \n",
      " 73% 3660/5000 [47:38<15:53,  1.41it/s]INFO     [2275295803.py] Epoch 3660 | Train Loss: 0.00000 | Val Loss: 5.55705 \n",
      " 73% 3670/5000 [47:45<15:50,  1.40it/s]INFO     [2275295803.py] Epoch 3670 | Train Loss: 0.00000 | Val Loss: 5.42592 \n",
      " 74% 3680/5000 [47:52<17:19,  1.27it/s]INFO     [2275295803.py] Epoch 3680 | Train Loss: 0.00000 | Val Loss: 5.43855 \n",
      " 74% 3690/5000 [48:00<17:16,  1.26it/s]INFO     [2275295803.py] Epoch 3690 | Train Loss: 0.00000 | Val Loss: 5.54840 \n",
      " 74% 3700/5000 [48:08<17:09,  1.26it/s]INFO     [2275295803.py] Epoch 3700 | Train Loss: 0.00000 | Val Loss: 5.56927 \n",
      " 74% 3710/5000 [48:16<16:52,  1.27it/s]INFO     [2275295803.py] Epoch 3710 | Train Loss: 0.00000 | Val Loss: 5.87426 \n",
      " 74% 3720/5000 [48:24<16:51,  1.27it/s]INFO     [2275295803.py] Epoch 3720 | Train Loss: 0.00000 | Val Loss: 5.74053 \n",
      " 75% 3730/5000 [48:32<16:33,  1.28it/s]INFO     [2275295803.py] Epoch 3730 | Train Loss: 0.00000 | Val Loss: 5.69021 \n",
      " 75% 3740/5000 [48:40<16:27,  1.28it/s]INFO     [2275295803.py] Epoch 3740 | Train Loss: 0.00000 | Val Loss: 5.74059 \n",
      " 75% 3750/5000 [48:48<16:20,  1.27it/s]INFO     [2275295803.py] Epoch 3750 | Train Loss: 0.00000 | Val Loss: 5.67502 \n",
      " 75% 3760/5000 [48:56<16:11,  1.28it/s]INFO     [2275295803.py] Epoch 3760 | Train Loss: 0.00005 | Val Loss: 5.94412 \n",
      " 75% 3770/5000 [49:03<16:02,  1.28it/s]INFO     [2275295803.py] Epoch 3770 | Train Loss: 0.00000 | Val Loss: 6.13412 \n",
      " 76% 3780/5000 [49:11<15:55,  1.28it/s]INFO     [2275295803.py] Epoch 3780 | Train Loss: 0.00000 | Val Loss: 5.92157 \n",
      " 76% 3790/5000 [49:19<15:48,  1.28it/s]INFO     [2275295803.py] Epoch 3790 | Train Loss: 0.00000 | Val Loss: 5.77153 \n",
      " 76% 3800/5000 [49:27<15:44,  1.27it/s]INFO     [2275295803.py] Epoch 3800 | Train Loss: 0.00000 | Val Loss: 6.04245 \n",
      " 76% 3810/5000 [49:35<15:36,  1.27it/s]INFO     [2275295803.py] Epoch 3810 | Train Loss: 0.00000 | Val Loss: 6.36048 \n",
      " 76% 3820/5000 [49:43<15:26,  1.27it/s]INFO     [2275295803.py] Epoch 3820 | Train Loss: 0.00000 | Val Loss: 5.89530 \n",
      " 77% 3830/5000 [49:50<15:19,  1.27it/s]INFO     [2275295803.py] Epoch 3830 | Train Loss: 0.00000 | Val Loss: 6.05098 \n",
      " 77% 3840/5000 [49:58<15:15,  1.27it/s]INFO     [2275295803.py] Epoch 3840 | Train Loss: 0.00013 | Val Loss: 6.25826 \n",
      " 77% 3850/5000 [50:06<15:11,  1.26it/s]INFO     [2275295803.py] Epoch 3850 | Train Loss: 0.00000 | Val Loss: 6.29750 \n",
      " 77% 3860/5000 [50:14<15:03,  1.26it/s]INFO     [2275295803.py] Epoch 3860 | Train Loss: 0.00000 | Val Loss: 6.46789 \n",
      " 77% 3870/5000 [50:22<14:59,  1.26it/s]INFO     [2275295803.py] Epoch 3870 | Train Loss: 0.00000 | Val Loss: 6.90415 \n",
      " 78% 3880/5000 [50:30<14:47,  1.26it/s]INFO     [2275295803.py] Epoch 3880 | Train Loss: 0.00000 | Val Loss: 5.64453 \n",
      " 78% 3890/5000 [50:38<14:40,  1.26it/s]INFO     [2275295803.py] Epoch 3890 | Train Loss: 0.00000 | Val Loss: 5.66110 \n",
      " 78% 3900/5000 [50:46<14:29,  1.27it/s]INFO     [2275295803.py] Epoch 3900 | Train Loss: 0.00000 | Val Loss: 5.66271 \n",
      " 78% 3910/5000 [50:54<14:14,  1.27it/s]INFO     [2275295803.py] Epoch 3910 | Train Loss: 0.00000 | Val Loss: 5.88648 \n",
      " 78% 3920/5000 [51:02<14:05,  1.28it/s]INFO     [2275295803.py] Epoch 3920 | Train Loss: 0.00000 | Val Loss: 5.86121 \n",
      " 79% 3930/5000 [51:09<13:58,  1.28it/s]INFO     [2275295803.py] Epoch 3930 | Train Loss: 0.00000 | Val Loss: 5.78752 \n",
      " 79% 3940/5000 [51:17<13:47,  1.28it/s]INFO     [2275295803.py] Epoch 3940 | Train Loss: 0.00000 | Val Loss: 5.96569 \n",
      " 79% 3950/5000 [51:25<13:43,  1.28it/s]INFO     [2275295803.py] Epoch 3950 | Train Loss: 0.00000 | Val Loss: 6.03491 \n",
      " 79% 3960/5000 [51:33<13:38,  1.27it/s]INFO     [2275295803.py] Epoch 3960 | Train Loss: 0.00000 | Val Loss: 6.01311 \n",
      " 79% 3970/5000 [51:41<13:29,  1.27it/s]INFO     [2275295803.py] Epoch 3970 | Train Loss: 0.00000 | Val Loss: 6.02465 \n",
      " 80% 3980/5000 [51:49<13:17,  1.28it/s]INFO     [2275295803.py] Epoch 3980 | Train Loss: 0.00000 | Val Loss: 5.97626 \n",
      " 80% 3990/5000 [51:56<13:10,  1.28it/s]INFO     [2275295803.py] Epoch 3990 | Train Loss: 0.00000 | Val Loss: 5.87008 \n",
      " 80% 4000/5000 [52:04<13:01,  1.28it/s]INFO     [2275295803.py] Epoch 4000 | Train Loss: 0.00000 | Val Loss: 6.06857 \n",
      " 80% 4010/5000 [52:12<12:57,  1.27it/s]INFO     [2275295803.py] Epoch 4010 | Train Loss: 0.00000 | Val Loss: 6.06156 \n",
      " 80% 4020/5000 [52:20<12:44,  1.28it/s]INFO     [2275295803.py] Epoch 4020 | Train Loss: 0.00000 | Val Loss: 6.06040 \n",
      " 81% 4030/5000 [52:28<12:37,  1.28it/s]INFO     [2275295803.py] Epoch 4030 | Train Loss: 0.00000 | Val Loss: 6.03582 \n",
      " 81% 4040/5000 [52:36<12:29,  1.28it/s]INFO     [2275295803.py] Epoch 4040 | Train Loss: 0.00000 | Val Loss: 6.04344 \n",
      " 81% 4050/5000 [52:43<12:24,  1.28it/s]INFO     [2275295803.py] Epoch 4050 | Train Loss: 0.00000 | Val Loss: 6.17124 \n",
      " 81% 4060/5000 [52:51<12:16,  1.28it/s]INFO     [2275295803.py] Epoch 4060 | Train Loss: 0.00000 | Val Loss: 6.53732 \n",
      " 81% 4070/5000 [52:59<12:04,  1.28it/s]INFO     [2275295803.py] Epoch 4070 | Train Loss: 0.00000 | Val Loss: 6.07364 \n",
      " 82% 4080/5000 [53:07<12:01,  1.27it/s]INFO     [2275295803.py] Epoch 4080 | Train Loss: 0.00000 | Val Loss: 6.13081 \n",
      " 82% 4090/5000 [53:15<11:49,  1.28it/s]INFO     [2275295803.py] Epoch 4090 | Train Loss: 0.00000 | Val Loss: 5.84313 \n",
      " 82% 4100/5000 [53:23<11:41,  1.28it/s]INFO     [2275295803.py] Epoch 4100 | Train Loss: 0.00000 | Val Loss: 5.83303 \n",
      " 82% 4110/5000 [53:30<11:36,  1.28it/s]INFO     [2275295803.py] Epoch 4110 | Train Loss: 0.00000 | Val Loss: 5.96437 \n",
      " 82% 4120/5000 [53:38<11:27,  1.28it/s]INFO     [2275295803.py] Epoch 4120 | Train Loss: 0.00000 | Val Loss: 6.07194 \n",
      " 83% 4130/5000 [53:46<11:21,  1.28it/s]INFO     [2275295803.py] Epoch 4130 | Train Loss: 0.00000 | Val Loss: 6.46838 \n",
      " 83% 4140/5000 [53:54<11:10,  1.28it/s]INFO     [2275295803.py] Epoch 4140 | Train Loss: 0.00000 | Val Loss: 6.68524 \n",
      " 83% 4150/5000 [54:02<11:05,  1.28it/s]INFO     [2275295803.py] Epoch 4150 | Train Loss: 0.00000 | Val Loss: 6.48135 \n",
      " 83% 4160/5000 [54:09<10:57,  1.28it/s]INFO     [2275295803.py] Epoch 4160 | Train Loss: 0.00000 | Val Loss: 6.26393 \n",
      " 83% 4170/5000 [54:17<10:51,  1.27it/s]INFO     [2275295803.py] Epoch 4170 | Train Loss: 0.00000 | Val Loss: 6.36749 \n",
      " 84% 4180/5000 [54:25<10:40,  1.28it/s]INFO     [2275295803.py] Epoch 4180 | Train Loss: 0.00000 | Val Loss: 6.37728 \n",
      " 84% 4190/5000 [54:33<10:32,  1.28it/s]INFO     [2275295803.py] Epoch 4190 | Train Loss: 0.00000 | Val Loss: 6.46025 \n",
      " 84% 4200/5000 [54:41<10:23,  1.28it/s]INFO     [2275295803.py] Epoch 4200 | Train Loss: 0.00000 | Val Loss: 5.28071 \n",
      " 84% 4210/5000 [54:49<10:21,  1.27it/s]INFO     [2275295803.py] Epoch 4210 | Train Loss: 0.00000 | Val Loss: 5.39872 \n",
      " 84% 4220/5000 [54:56<10:12,  1.27it/s]INFO     [2275295803.py] Epoch 4220 | Train Loss: 0.00000 | Val Loss: 5.02070 \n",
      " 85% 4230/5000 [55:04<10:14,  1.25it/s]INFO     [2275295803.py] Epoch 4230 | Train Loss: 0.00000 | Val Loss: 5.03935 \n",
      " 85% 4240/5000 [55:12<10:00,  1.27it/s]INFO     [2275295803.py] Epoch 4240 | Train Loss: 0.00000 | Val Loss: 5.14565 \n",
      " 85% 4250/5000 [55:20<10:01,  1.25it/s]INFO     [2275295803.py] Epoch 4250 | Train Loss: 0.00000 | Val Loss: 5.13824 \n",
      " 85% 4260/5000 [55:28<09:45,  1.26it/s]INFO     [2275295803.py] Epoch 4260 | Train Loss: 0.00000 | Val Loss: 5.20428 \n",
      " 85% 4270/5000 [55:36<09:35,  1.27it/s]INFO     [2275295803.py] Epoch 4270 | Train Loss: 0.00000 | Val Loss: 5.30929 \n",
      " 86% 4280/5000 [55:44<09:27,  1.27it/s]INFO     [2275295803.py] Epoch 4280 | Train Loss: 0.00000 | Val Loss: 5.47933 \n",
      " 86% 4290/5000 [55:52<09:20,  1.27it/s]INFO     [2275295803.py] Epoch 4290 | Train Loss: 0.00000 | Val Loss: 5.40437 \n",
      " 86% 4300/5000 [56:00<09:11,  1.27it/s]INFO     [2275295803.py] Epoch 4300 | Train Loss: 0.00000 | Val Loss: 5.49341 \n",
      " 86% 4310/5000 [56:08<09:04,  1.27it/s]INFO     [2275295803.py] Epoch 4310 | Train Loss: 0.00000 | Val Loss: 5.60651 \n",
      " 86% 4320/5000 [56:15<08:57,  1.27it/s]INFO     [2275295803.py] Epoch 4320 | Train Loss: 0.00000 | Val Loss: 5.64575 \n",
      " 87% 4330/5000 [56:23<08:51,  1.26it/s]INFO     [2275295803.py] Epoch 4330 | Train Loss: 0.00000 | Val Loss: 5.72559 \n",
      " 87% 4340/5000 [56:31<08:39,  1.27it/s]INFO     [2275295803.py] Epoch 4340 | Train Loss: 0.00000 | Val Loss: 5.69956 \n",
      " 87% 4350/5000 [56:39<08:32,  1.27it/s]INFO     [2275295803.py] Epoch 4350 | Train Loss: 0.00000 | Val Loss: 5.59852 \n",
      " 87% 4360/5000 [56:47<08:31,  1.25it/s]INFO     [2275295803.py] Epoch 4360 | Train Loss: 0.00000 | Val Loss: 5.56085 \n",
      " 87% 4370/5000 [56:55<08:15,  1.27it/s]INFO     [2275295803.py] Epoch 4370 | Train Loss: 0.00000 | Val Loss: 5.52525 \n",
      " 88% 4380/5000 [57:03<08:19,  1.24it/s]INFO     [2275295803.py] Epoch 4380 | Train Loss: 0.00000 | Val Loss: 5.49066 \n",
      " 88% 4390/5000 [57:11<07:58,  1.27it/s]INFO     [2275295803.py] Epoch 4390 | Train Loss: 0.00000 | Val Loss: 5.47681 \n",
      " 88% 4400/5000 [57:19<08:08,  1.23it/s]INFO     [2275295803.py] Epoch 4400 | Train Loss: 0.00000 | Val Loss: 5.46440 \n",
      " 88% 4410/5000 [57:27<07:46,  1.27it/s]INFO     [2275295803.py] Epoch 4410 | Train Loss: 0.00000 | Val Loss: 5.52929 \n",
      " 88% 4420/5000 [57:35<07:54,  1.22it/s]INFO     [2275295803.py] Epoch 4420 | Train Loss: 0.00000 | Val Loss: 5.51767 \n",
      " 89% 4430/5000 [57:42<07:29,  1.27it/s]INFO     [2275295803.py] Epoch 4430 | Train Loss: 0.00000 | Val Loss: 5.54947 \n",
      " 89% 4440/5000 [57:50<07:23,  1.26it/s]INFO     [2275295803.py] Epoch 4440 | Train Loss: 0.00000 | Val Loss: 5.55814 \n",
      " 89% 4450/5000 [57:58<07:09,  1.28it/s]INFO     [2275295803.py] Epoch 4450 | Train Loss: 0.00000 | Val Loss: 5.48561 \n",
      " 89% 4460/5000 [58:06<07:01,  1.28it/s]INFO     [2275295803.py] Epoch 4460 | Train Loss: 0.00000 | Val Loss: 5.57092 \n",
      " 89% 4470/5000 [58:14<06:54,  1.28it/s]INFO     [2275295803.py] Epoch 4470 | Train Loss: 0.00000 | Val Loss: 5.71062 \n",
      " 90% 4480/5000 [58:22<06:46,  1.28it/s]INFO     [2275295803.py] Epoch 4480 | Train Loss: 0.00000 | Val Loss: 5.83427 \n",
      " 90% 4490/5000 [58:30<06:39,  1.28it/s]INFO     [2275295803.py] Epoch 4490 | Train Loss: 0.00000 | Val Loss: 5.78909 \n",
      " 90% 4500/5000 [58:37<06:08,  1.36it/s]INFO     [2275295803.py] Epoch 4500 | Train Loss: 0.00000 | Val Loss: 5.85177 \n",
      " 90% 4510/5000 [58:45<06:22,  1.28it/s]INFO     [2275295803.py] Epoch 4510 | Train Loss: 0.00000 | Val Loss: 5.94683 \n",
      " 90% 4520/5000 [58:52<06:16,  1.28it/s]INFO     [2275295803.py] Epoch 4520 | Train Loss: 0.00000 | Val Loss: 6.07894 \n",
      " 91% 4530/5000 [59:00<06:06,  1.28it/s]INFO     [2275295803.py] Epoch 4530 | Train Loss: 0.00000 | Val Loss: 6.44193 \n",
      " 91% 4540/5000 [59:08<05:59,  1.28it/s]INFO     [2275295803.py] Epoch 4540 | Train Loss: 0.00000 | Val Loss: 6.48424 \n",
      " 91% 4550/5000 [59:16<05:50,  1.28it/s]INFO     [2275295803.py] Epoch 4550 | Train Loss: 0.00000 | Val Loss: 6.49084 \n",
      " 91% 4560/5000 [59:24<05:43,  1.28it/s]INFO     [2275295803.py] Epoch 4560 | Train Loss: 0.00000 | Val Loss: 6.76813 \n",
      " 91% 4570/5000 [59:32<05:34,  1.28it/s]INFO     [2275295803.py] Epoch 4570 | Train Loss: 0.00000 | Val Loss: 6.59754 \n",
      " 92% 4580/5000 [59:39<05:26,  1.29it/s]INFO     [2275295803.py] Epoch 4580 | Train Loss: 0.00000 | Val Loss: 6.57469 \n",
      " 92% 4590/5000 [59:47<05:20,  1.28it/s]INFO     [2275295803.py] Epoch 4590 | Train Loss: 0.00000 | Val Loss: 6.75346 \n",
      " 92% 4600/5000 [59:55<05:13,  1.27it/s]INFO     [2275295803.py] Epoch 4600 | Train Loss: 0.00000 | Val Loss: 6.71548 \n",
      " 92% 4610/5000 [1:00:03<05:05,  1.28it/s]INFO     [2275295803.py] Epoch 4610 | Train Loss: 0.00000 | Val Loss: 7.24215 \n",
      " 92% 4620/5000 [1:00:11<04:57,  1.28it/s]INFO     [2275295803.py] Epoch 4620 | Train Loss: 0.00000 | Val Loss: 6.92609 \n",
      " 93% 4630/5000 [1:00:18<04:48,  1.28it/s]INFO     [2275295803.py] Epoch 4630 | Train Loss: 0.00000 | Val Loss: 6.74587 \n",
      " 93% 4640/5000 [1:00:26<04:40,  1.28it/s]INFO     [2275295803.py] Epoch 4640 | Train Loss: 0.00000 | Val Loss: 6.62973 \n",
      " 93% 4650/5000 [1:00:34<04:32,  1.28it/s]INFO     [2275295803.py] Epoch 4650 | Train Loss: 0.00000 | Val Loss: 6.67719 \n",
      " 93% 4660/5000 [1:00:42<04:24,  1.28it/s]INFO     [2275295803.py] Epoch 4660 | Train Loss: 0.00000 | Val Loss: 6.63513 \n",
      " 93% 4670/5000 [1:00:50<04:16,  1.28it/s]INFO     [2275295803.py] Epoch 4670 | Train Loss: 0.00000 | Val Loss: 6.66527 \n",
      " 94% 4680/5000 [1:00:57<04:09,  1.28it/s]INFO     [2275295803.py] Epoch 4680 | Train Loss: 0.00000 | Val Loss: 7.13810 \n",
      " 94% 4690/5000 [1:01:05<04:02,  1.28it/s]INFO     [2275295803.py] Epoch 4690 | Train Loss: 0.00000 | Val Loss: 7.69226 \n",
      " 94% 4700/5000 [1:01:13<03:54,  1.28it/s]INFO     [2275295803.py] Epoch 4700 | Train Loss: 0.00000 | Val Loss: 7.42762 \n",
      " 94% 4710/5000 [1:01:21<03:46,  1.28it/s]INFO     [2275295803.py] Epoch 4710 | Train Loss: 0.00000 | Val Loss: 7.35907 \n",
      " 94% 4720/5000 [1:01:29<03:39,  1.28it/s]INFO     [2275295803.py] Epoch 4720 | Train Loss: 0.00000 | Val Loss: 6.80452 \n",
      " 95% 4730/5000 [1:01:37<03:31,  1.27it/s]INFO     [2275295803.py] Epoch 4730 | Train Loss: 0.00000 | Val Loss: 6.92129 \n",
      " 95% 4740/5000 [1:01:44<03:15,  1.33it/s]INFO     [2275295803.py] Epoch 4740 | Train Loss: 0.00000 | Val Loss: 7.06061 \n",
      " 95% 4750/5000 [1:01:52<03:17,  1.27it/s]INFO     [2275295803.py] Epoch 4750 | Train Loss: 0.00000 | Val Loss: 7.34194 \n",
      " 95% 4760/5000 [1:02:00<03:08,  1.27it/s]INFO     [2275295803.py] Epoch 4760 | Train Loss: 0.00000 | Val Loss: 7.29969 \n",
      " 95% 4770/5000 [1:02:08<03:01,  1.27it/s]INFO     [2275295803.py] Epoch 4770 | Train Loss: 0.00000 | Val Loss: 7.28963 \n",
      " 96% 4780/5000 [1:02:16<02:53,  1.27it/s]INFO     [2275295803.py] Epoch 4780 | Train Loss: 0.00000 | Val Loss: 7.01301 \n",
      " 96% 4790/5000 [1:02:24<02:43,  1.28it/s]INFO     [2275295803.py] Epoch 4790 | Train Loss: 0.00000 | Val Loss: 6.73128 \n",
      " 96% 4800/5000 [1:02:32<02:38,  1.26it/s]INFO     [2275295803.py] Epoch 4800 | Train Loss: 0.00002 | Val Loss: 6.38086 \n",
      " 96% 4810/5000 [1:02:39<02:30,  1.26it/s]INFO     [2275295803.py] Epoch 4810 | Train Loss: 0.00000 | Val Loss: 6.40850 \n",
      " 96% 4820/5000 [1:02:47<02:21,  1.27it/s]INFO     [2275295803.py] Epoch 4820 | Train Loss: 0.00000 | Val Loss: 6.52347 \n",
      " 97% 4830/5000 [1:02:55<02:14,  1.27it/s]INFO     [2275295803.py] Epoch 4830 | Train Loss: 0.00000 | Val Loss: 6.49364 \n",
      " 97% 4840/5000 [1:03:03<02:05,  1.27it/s]INFO     [2275295803.py] Epoch 4840 | Train Loss: 0.00000 | Val Loss: 6.37954 \n",
      " 97% 4850/5000 [1:03:11<01:53,  1.32it/s]INFO     [2275295803.py] Epoch 4850 | Train Loss: 0.00000 | Val Loss: 6.22456 \n",
      " 97% 4860/5000 [1:03:18<01:45,  1.33it/s]INFO     [2275295803.py] Epoch 4860 | Train Loss: 0.00000 | Val Loss: 6.45362 \n",
      " 97% 4870/5000 [1:03:26<01:42,  1.26it/s]INFO     [2275295803.py] Epoch 4870 | Train Loss: 0.00000 | Val Loss: 6.80029 \n",
      " 98% 4880/5000 [1:03:34<01:34,  1.26it/s]INFO     [2275295803.py] Epoch 4880 | Train Loss: 0.00000 | Val Loss: 6.87418 \n",
      " 98% 4890/5000 [1:03:42<01:27,  1.26it/s]INFO     [2275295803.py] Epoch 4890 | Train Loss: 0.00000 | Val Loss: 6.35299 \n",
      " 98% 4900/5000 [1:03:50<01:18,  1.27it/s]INFO     [2275295803.py] Epoch 4900 | Train Loss: 0.00000 | Val Loss: 6.35390 \n",
      " 98% 4910/5000 [1:03:58<01:11,  1.27it/s]INFO     [2275295803.py] Epoch 4910 | Train Loss: 0.00000 | Val Loss: 6.31943 \n",
      " 98% 4920/5000 [1:04:06<01:03,  1.27it/s]INFO     [2275295803.py] Epoch 4920 | Train Loss: 0.00000 | Val Loss: 6.29428 \n",
      " 99% 4930/5000 [1:04:14<00:54,  1.27it/s]INFO     [2275295803.py] Epoch 4930 | Train Loss: 0.00000 | Val Loss: 6.25734 \n",
      " 99% 4940/5000 [1:04:21<00:47,  1.26it/s]INFO     [2275295803.py] Epoch 4940 | Train Loss: 0.00000 | Val Loss: 6.20671 \n",
      " 99% 4950/5000 [1:04:29<00:39,  1.27it/s]INFO     [2275295803.py] Epoch 4950 | Train Loss: 0.00000 | Val Loss: 5.99983 \n",
      " 99% 4960/5000 [1:04:37<00:31,  1.26it/s]INFO     [2275295803.py] Epoch 4960 | Train Loss: 0.00000 | Val Loss: 6.10122 \n",
      " 99% 4970/5000 [1:04:45<00:23,  1.26it/s]INFO     [2275295803.py] Epoch 4970 | Train Loss: 0.00000 | Val Loss: 6.15631 \n",
      "100% 4980/5000 [1:04:53<00:15,  1.26it/s]INFO     [2275295803.py] Epoch 4980 | Train Loss: 0.00000 | Val Loss: 6.04651 \n",
      "100% 4990/5000 [1:05:01<00:07,  1.27it/s]INFO     [2275295803.py] Epoch 4990 | Train Loss: 0.00000 | Val Loss: 6.23475 \n",
      "100% 5000/5000 [1:05:09<00:00,  1.28it/s]\n",
      "INFO     [2275295803.py] model has been saved in:save_models/sp500_20082017_corr_ser_reg_corr_mat_hrchy_11_cluster-train_train/corr_s1_w5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1h 5min 11s (started: 2023-02-19 12:52:33 +00:00)\n"
     ]
    }
   ],
   "source": [
    "def train(model:torch.nn.Module, train_loader:torch_geometric.loader.dataloader.DataLoader,\n",
    "          val_loader:torch_geometric.loader.dataloader.DataLoader, optimizer, criterion, epochs:int =5, show_model_info=False):\n",
    "    best_model_info = {\"epochs\": epochs,\n",
    "                       \"train_batch\": train_loader.batch_size,\n",
    "                       \"val_batch\": val_loader.batch_size,\n",
    "                       \"optimizer\": optimizer.__str__(),\n",
    "                       \"criterion\": criterion.__str__(),\n",
    "                       \"min_val_loss\": float('inf'),\n",
    "                       \"train_loss_history\": [],\n",
    "                       \"val_loss_history\": [],\n",
    "                      }\n",
    "    model_num_layers = sum(1 for _ in model.parameters())\n",
    "    graph_enc_num_layers =  sum(1 for _ in model.graph_encoder.parameters())\n",
    "    graph_enc_w_grad_after = 0\n",
    "    for epoch_i in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        # Train on batches\n",
    "        for batch_i, data in enumerate(train_loader):\n",
    "            data.to(\"cuda\")\n",
    "            x, x_edge_index, x_batch_node_id, x_edge_attr = data.x, data.edge_index, data.batch, data.edge_attr\n",
    "            y, y_edge_index, y_batch_node_id, y_edge_attr = data.y[-1].x, data.y[-1].edge_index, torch.zeros(data.y[-1].x.shape[0], dtype=torch.int64).to(\"cuda\"), data.y[-1].edge_attr  # only take y of x with last time-step on training\n",
    "            optimizer.zero_grad()\n",
    "            graph_embeds_pred = model(x, x_edge_index, x_batch_node_id)\n",
    "            y_graph_embeds = model.graph_encoder.get_embeddings(y, y_edge_index, y_batch_node_id)\n",
    "            loss =  criterion(graph_embeds_pred, y_graph_embeds)\n",
    "            train_loss += loss / len(train_loader)\n",
    "            loss.backward()\n",
    "            graph_enc_w_grad_after += sum(sum(torch.abs(torch.reshape(p.grad if p.grad!=None else torch.zeros((1,)).to('cuda'), (-1,)))) for p in islice(model.graph_encoder.parameters(), 0, graph_enc_num_layers))\n",
    "            optimizer.step()\n",
    "\n",
    "        # Check if graph_encoder.parameters() have been updated in each epoch\n",
    "        assert graph_enc_w_grad_after>0, f\"After loss.backward(), Sum of MainModel.graph_encoder weights in epoch_{epoch_i}:{graph_enc_w_grad_after}\"\n",
    "\n",
    "        # Validation\n",
    "        val_loss = test(model, val_loader, criterion)\n",
    "\n",
    "        # save best model\n",
    "        if val_loss<best_model_info[\"min_val_loss\"]:\n",
    "            best_model = model\n",
    "            best_model_info[\"best_val_epoch\"] = epoch_i\n",
    "            best_model_info[\"min_val_loss\"] = val_loss.item()\n",
    "\n",
    "        best_model_info[\"train_loss_history\"].append(train_loss.item())\n",
    "        best_model_info[\"val_loss_history\"].append(val_loss.item())\n",
    "\n",
    "        # observe model info in console\n",
    "        if show_model_info and epoch_i==0:\n",
    "            best_model_info[\"model_structure\"] = model.__str__() + \"\\n\" + \"=\"*100 + \"\\n\" + summary(model, data.x, data.edge_index, data.batch, max_depth=20).__str__()\n",
    "            logging.info(f\"\\n{best_model_info['model_structure']}\")\n",
    "        if(epoch_i % 10 == 0):  # show metrics every 10 epochs\n",
    "            logging.info(f\"Epoch {epoch_i:>3} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f} \")\n",
    "\n",
    "    return best_model, best_model_info\n",
    "\n",
    "\n",
    "def test(model:torch.nn.Module, loader:torch_geometric.loader.dataloader.DataLoader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_i, data in enumerate(loader):\n",
    "            data.to(\"cuda\")\n",
    "            x, x_edge_index, x_batch_node_id, x_edge_attr = data.x, data.edge_index, data.batch, data.edge_attr\n",
    "            y, y_edge_index, y_batch_node_id, y_edge_attr = data.y[-1].x, data.y[-1].edge_index, torch.zeros(data.y[-1].x.shape[0], dtype=torch.int64).to(\"cuda\"), data.y[-1].edge_attr  # only take y of x with last time-step on training\n",
    "            graph_embeds_pred = model(x, x_edge_index, x_batch_node_id)\n",
    "            y_graph_embeds = model.graph_encoder.get_embeddings(y, y_edge_index, y_batch_node_id)\n",
    "            loss = criterion(graph_embeds_pred, y_graph_embeds)\n",
    "            # test_loss += loss / len(loader)\n",
    "            test_loss += loss\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "def save_model(model:torch.nn.Module, model_info:dict, data_gen_cfg:dict):\n",
    "    e_i = model_info[\"best_val_epoch\"]\n",
    "    t = datetime.strftime(datetime.now(),\"%Y%m%d%H%M%S\")\n",
    "    torch.save(model, model_dir/f\"epoch_{e_i}-{t}.pt\")\n",
    "    with open(model_log_dir/f\"epoch_{e_i}-{t}.json\",\"w\") as f:\n",
    "        json_str = json.dumps(model_info)\n",
    "        f.write(json_str)\n",
    "    logging.info(f\"model has been saved in:{model_dir}\")\n",
    "\n",
    "gin_encoder = GinEncoder(**gin_enc_cfg).to(\"cuda\")\n",
    "mts_corr_ad_cfg[\"graph_encoder\"] = gin_encoder\n",
    "model =  MTSCorrAD(**mts_corr_ad_cfg).to(\"cuda\")\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model, model_info = train(model, train_loader, val_loader, optimizer, criterion, epochs=5000, show_model_info=True)\n",
    "save_model(model, model_info, data_gen_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23989b6-e790-42e1-84f7-03fab9ffa5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

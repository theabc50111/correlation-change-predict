{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda428b1-2127-4c72-8ac3-95dc0b8c2646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pformat, pprint\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from math import ceil\n",
    "from itertools import repeat, chain, product\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "\n",
    "logging.basicConfig(format='%(levelname)-8s [%(filename)s] %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "matplotlib_logger = logging.getLogger(\"matplotlib\")\n",
    "matplotlib_logger.setLevel(logging.ERROR)\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2243b-4553-44f4-9982-75a4292206b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gae_tr_proc_est(log_path_list: list, condition_dict: dict,  plot_pic:bool = True):\n",
    "    try:\n",
    "        df = pd.DataFrame()\n",
    "        for log_path in log_path_list:\n",
    "            with open(log_path, \"r\") as source:\n",
    "                log_dict = json.load(source)\n",
    "\n",
    "            for k in log_dict.keys():\n",
    "                locals()[k] = log_dict[k]\n",
    "            model_struct_info_fields = {\"opt_lr\": \".?initial_lr: (?P<opt_lr>\\d\\.\\d+)\\n\",\n",
    "                                        \"opt_weight_decay\": \".?weight_decay: (?P<opt_weight_decay>\\d\\.\\d+)\\n\",\n",
    "                                        \"gra_enc_h\": \"(\\(\\d\\)\\:\\s.*Conv.*\\n.*)(out_features\\=)(?P<gra_enc_h>\\d*)\",\n",
    "                                        \"gra_enc_l\": \"\\(\\d\\)\\:\\s.*Conv\"}\n",
    "            if model_struct_str := log_dict.get('model_structure')+log_dict.get('optimizer'):\n",
    "                for field, pattern in model_struct_info_fields.items():\n",
    "                    if field == \"gra_enc_l\":\n",
    "                        locals()[field] = len(re.findall(pattern, model_struct_str))\n",
    "                        continue\n",
    "                    match = re.search(pattern, model_struct_str)\n",
    "                    if match:\n",
    "                        locals()[field] = float(match.group(field))\n",
    "                    else:\n",
    "                        locals()[field] = None\n",
    "                        logging.info(f\"Can't detect {field}\")\n",
    "\n",
    "\n",
    "            assert not(set(condition_dict.keys()) - set(locals().keys())), \"one of condition_dict.keys() doesn't match the local variables if mts_corr_ad_est()\"\n",
    "            corr_info = str(next(filter(lambda p: p.startswith(\"corr\"), log_path.parts)))\n",
    "            min_tr_loss = min(locals()[\"tr_loss_history\"])\n",
    "            min_tr_loss_edge_acc = locals()[\"tr_edge_acc_history\"][np.argmin(np.array(locals()[\"tr_loss_history\"]))]\n",
    "            max_tr_edge_acc = max(locals()[\"tr_edge_acc_history\"])\n",
    "            max_val_edge_acc = max(locals()[\"val_edge_acc_history\"])\n",
    "            record_fields = list(log_dict.keys()) + [\"corr_info\", \"min_tr_loss\", \"min_tr_loss_edge_acc\", \"max_tr_edge_acc\", \"max_val_edge_acc\"] + list(model_struct_info_fields.keys())\n",
    "            est_values_dict = locals()\n",
    "            filtered_dict = dict(filter(lambda x: est_values_dict[x[0]] == x[1], condition_dict.items()))\n",
    "            if filtered_dict == condition_dict:\n",
    "                main_title_str = (f\"Nodes mode-{locals().get('graph_nodes_v_mode')} + {locals().get('corr_info')} with filt:{locals().get('filt_mode')}-{locals().get('filt_quan')} \"\n",
    "                                  f\"and batch_size({locals().get('batch_size')}) and seq_len({locals().get('seq_len')}) \"\n",
    "                                  f\"input to MTSCorrAD with gra_enc_aggr{locals().get('gra_enc_aggr')}-gra_enc_l{locals().get('gra_enc_l'):.0f}-gra_enc_h{locals().get('gra_enc_h'):.0f}\"\n",
    "                                  f\"-gru_l{locals().get('gru_l')}-gru_h{locals().get('gru_h')}\\n\"\n",
    "                                  f\"with drop: {locals().get('drop_p')} and loss_fns:{locals().get('loss_fns')}\\n\"\n",
    "                                  f\"min val-loss:{locals().get('min_val_loss'):8f} min tr-loss:{locals().get('min_tr_loss'):8f}\\n\"\n",
    "                                  f\"max_tr_edge_acc:{locals().get('max_tr_edge_acc')}, max_val_edge_acc:{locals().get('max_val_edge_acc')}\")\n",
    "                logging.info(f\"file_name:{log_path.parts[-1]}\")\n",
    "                logging.info(f\"file_path:{log_path.parts[2:-2]}\")\n",
    "                logging.info(f\"main_title_str:\\n{main_title_str}\")\n",
    "                comparison_dict = dict(filter(lambda x: x[0] in record_fields, locals().items()))\n",
    "                df = pd.concat([df, pd.DataFrame([comparison_dict])])\n",
    "                if plot_pic:\n",
    "                    plot_mts_corr_ad_tr_process(main_title=main_title_str, model_struct=model_struct_str,\n",
    "                                                metrics_history={k:log_dict[k] for k in record_fields if \"history\" in k},\n",
    "                                                best_epoch=locals()['best_val_epoch'], batches_per_epoch=locals()['batches_per_epoch'],\n",
    "                                                gra_emb_size=int(locals().get('gra_enc_l')*locals().get('gra_enc_h')))\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            df = df.reindex([\"corr_info\", \"epochs\", \"batch_size\", \"graph_nodes_v_mode\", \"filt_mode\", \"filt_quan\", \"seq_len\",\n",
    "                             \"loss_fns\", \"optimizer\", \"opt_lr\", \"opt_weight_decay\", \"gra_enc_weight_l2_reg_lambda\", \"drop_pos\", \"drop_p\", \"graph_enc\", \"gra_enc_aggr\", \"gra_enc_l\", \"gra_enc_h\", \"gru_l\", \"gru_h\",\n",
    "                             \"min_tr_loss\", \"min_tr_loss_edge_acc\", \"max_tr_edge_acc\",\n",
    "                             \"min_val_loss\", \"max_val_edge_acc\", \"min_val_loss_edge_acc\"], axis=1)\n",
    "            df = df.sort_values([\"batch_size\", \"seq_len\", \"gra_enc_aggr\", \"gra_enc_l\", \"gra_enc_h\", \"gru_l\", \"gru_h\",\n",
    "                                 \"filt_mode\", \"filt_quan\", \"graph_enc\", \"graph_nodes_v_mode\", \"loss_fns\", \"opt_lr\", \"drop_p\"], ascending=False)\n",
    "            df = df.reset_index(drop=True)\n",
    "            df.style.set_caption('Info of MTSCorrAD model with different hyperparameters')\n",
    "            pd.options.display.float_format = '{:.6f}'.format\n",
    "            pd.set_option('display.max_columns', None)\n",
    "            display(df)\n",
    "    except Exception as e:\n",
    "        error_class = e.__class__.__name__ #⬞取得錯誤類型\n",
    "        detail = e.args[0]  #⬞取得詳細內容\n",
    "        cl, exc, tb = sys.exc_info() #⬞取得Call⬞Stack\n",
    "        last_call_stack = traceback.extract_tb(tb)[-1] #⬞取得Call⬞Stack的最後一筆資料↵\n",
    "        file_name = last_call_stack[0] #⬞取得發生的檔案名稱↵\n",
    "        line_num = last_call_stack[1] #⬞取得發生的行號↵\n",
    "        func_name = last_call_stack[2] #⬞取得發生的函數名稱\n",
    "        err_msg = \"File \\\"{}\\\", line {}, in {}: [{}] {}\".format(file_name, line_num, func_name, error_class, detail)\n",
    "        logging.error(f\"file:{log_path.parts[-1]}, path:{log_path}\")\n",
    "        logging.error(f\"===\\n{err_msg}\")\n",
    "        logging.error(f\"===\\n{traceback.extract_tb(tb)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_mts_corr_ad_tr_process(main_title: str, model_struct: str, metrics_history: dict, best_epoch: int, batches_per_epoch: int, gra_emb_size: int):\n",
    "    max_batch = batches_per_epoch * len(metrics_history['tr_loss_history'])  # epochs == len(metrics_history['tr_loss'])\n",
    "    data_info_dict = [{\"sub_title\": 'train loss_history & edge_acc_history',\n",
    "                       \"data\": {'tr_loss_history': metrics_history['tr_loss_history'],\n",
    "                                'tr_edge_acc_history': metrics_history['tr_edge_acc_history']},\n",
    "                       \"xticks\": None,\n",
    "                       \"xlabel\": \"epochs\",\n",
    "                       \"double_y\": True},\n",
    "                      {\"sub_title\": 'val  loss_history & edge_acc_history',\n",
    "                       \"data\": {'val_loss_history': metrics_history['val_loss_history'],\n",
    "                                'val_edge_acc_history': metrics_history['val_edge_acc_history']},\n",
    "                       \"xticks\": None,\n",
    "                       \"xlabel\": \"epochs\",\n",
    "                       \"double_y\": True},\n",
    "                      # {\"sub_title\": f\"train_loss_history-epoch{(max(0, best_epoch-100), max(200, best_epoch+100))}\",\n",
    "                      #  \"data\": metrics_history['tr_loss_history'][max(0, best_epoch-100):max(201, best_epoch+101)],\n",
    "                      #  \"xticks\": {\"label\": loss_xticks_label, \"intv\": xticks_intv['loss']},\n",
    "                      #  \"xlabel\": \"epochs\"},\n",
    "                      # {\"sub_title\": f\"val_loss_history-epoch{(max(0, best_epoch-100), max(200, best_epoch+100))}\",\n",
    "                      #  \"data\": metrics_history['val_loss_history'][max(0, best_epoch-100):max(201, best_epoch+101)],\n",
    "                      #  \"xticks\": {\"label\": loss_xticks_label, \"intv\": xticks_intv['loss']},\n",
    "                      #  \"xlabel\": \"epochs\"},\n",
    "                      # {\"sub_title\": f'pred_embeds, embeds size:[{pred_embeds.shape[1]}]',\n",
    "                      #  \"data\": pred_embeds,\n",
    "                      #  \"xticks\": {\"label\": fr_ls_embeds_xticks_label, \"intv\": xticks_intv[\"fr_ls_embeds\"]},\n",
    "                      #  \"xlabel\": \"batches\",\n",
    "                      #  \"axvline\": (batches_per_epoch, batches_per_epoch*3+20)},\n",
    "                      # {\"sub_title\": f'y_embeds, embeds size:[{y_embeds.shape[1]}]',\n",
    "                      #  \"data\": y_embeds,\n",
    "                      #  \"xticks\": {\"label\": fr_ls_embeds_xticks_label, \"intv\": xticks_intv[\"fr_ls_embeds\"]},\n",
    "                      #  \"xlabel\": \"batches\",\n",
    "                      #  \"axvline\": (batches_per_epoch, batches_per_epoch*3+20)},\n",
    "                      # {\"sub_title\": f\"y_embeds in last five epochs; embeds size:{y_embeds.shape[1]}\",\n",
    "                      #  \"data\": last_y_embeds,\n",
    "                      #  \"xticks\": {\"label\": range(max_batch - batches_per_epoch * 5, max_batch + 1, batches_per_epoch), \"intv\": batches_per_epoch},\n",
    "                      #  \"xlabel\": \"batches\",\n",
    "                      #  \"axvline\": [i*batches_per_epoch for i in range(1, 5)]},\n",
    "                      {\"sub_title\": f\"model structure\",\n",
    "                       \"data\": str(model_struct)}]\n",
    "\n",
    "    # figrue settings\n",
    "    line_style = {\"linewidth\": 2, \"alpha\": 0.5}\n",
    "    axvline_style = {\"color\": 'k', \"linewidth\": 5, \"linestyle\": '--', \"alpha\": 0.3}\n",
    "    fig, axs = plt.subplot_mosaic(\"\"\"\n",
    "                                  ab\n",
    "                                  cc\n",
    "                                  cc\n",
    "                                  cc\n",
    "                                  \"\"\",\n",
    "                                  figsize=(25, 40))\n",
    "    fig.suptitle(main_title, fontsize=30)\n",
    "\n",
    "    try:\n",
    "        for ax, data_plot in zip(axs.values(), data_info_dict):\n",
    "            ax.set_title(data_plot[\"sub_title\"], fontsize=30)\n",
    "            ax.yaxis.offsetText.set_fontsize(18)\n",
    "            ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "            if isinstance(data_plot[\"data\"], dict) and data_plot.get(\"double_y\"):\n",
    "                for i, key in enumerate(data_plot[\"data\"]):\n",
    "                    if i == 0:\n",
    "                        ax.plot(data_plot[\"data\"][key], label=key, **line_style)\n",
    "                        ax.set_ylabel(key, fontsize=24)\n",
    "                        ax.legend(fontsize=18)\n",
    "                    else:\n",
    "                        new_ax = ax.twinx()\n",
    "                        new_ax.plot(data_plot[\"data\"][key], label=key, color='r')\n",
    "                        new_ax.set_ylabel(key, color='r', fontsize=24)\n",
    "                        new_ax.legend(fontsize=18)\n",
    "                        new_ax.tick_params(axis='both', colors='r', which='major', labelsize=24)\n",
    "            elif isinstance(data_plot[\"data\"], dict):\n",
    "                [ax.plot(data_plot[\"data\"][key], label=key, **line_style) for key in data_plot[\"data\"]]\n",
    "                ax.legend(fontsize=18)\n",
    "            elif isinstance(data_plot[\"data\"], str):\n",
    "                ax.annotate(text=f\"{data_plot['data']}\",\n",
    "                            xy=(0.15, 0.5), bbox={'facecolor': 'green', 'alpha': 0.4, 'pad': 5},\n",
    "                            fontsize=20, fontfamily='monospace', xycoords='axes fraction', va='center')\n",
    "            else:\n",
    "                ax.plot(data_plot[\"data\"], **line_style)\n",
    "            if pos_tuple := data_plot.get(\"axvline\"):\n",
    "                for x_pos in pos_tuple:\n",
    "                    ax.axvline(x=x_pos, **axvline_style)\n",
    "            if xlabel := data_plot.get(\"xlabel\"):\n",
    "                ax.set_xlabel(xlabel, fontsize=24)\n",
    "            if t := data_plot.get(\"xticks\"):\n",
    "                ax.set_xticks(ticks=range(0, len(t[\"label\"])*t[\"intv\"], t[\"intv\"]), labels=t[\"label\"], rotation=45)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Encounter error when draw figure of {data_plot['sub_title']}\")\n",
    "        raise e\n",
    "\n",
    "    fig.tight_layout(rect=(0, 0, 1, 0.97))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b18f07-4833-4e92-9310-5da01c698b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gae_model_log_dir = Path(\"./save_models/gae_model/sp500_20082017_corr_ser_reg_std_corr_mat_hrchy_10_cluster_label_half_mix-train_train/\")\n",
    "log_path_list1 = gae_model_log_dir.glob(\"./*[!deprecated][!archive][!.ipynb_checkpoints]*/train_logs/*[!.ipynb_checkpoints]*[.json]\")\n",
    "log_path_list2 = gae_model_log_dir.glob(\"./*[archive][!deprecated][!.ipynb_checkpoints]*/**/train_logs/*[!.ipynb_checkpoints]*[.json]\")\n",
    "log_path_list3 = gae_model_log_dir.glob(\"./**/train_logs/*[!.ipynb_checkpoints]*[.json]\")\n",
    "\n",
    "# model_tr_summary_df = mts_corr_ad_tr_proc_est(log_path_list1, {\"corr_info\": \"corr_s1_w10\", \"tr_batch\": 32, \"gra_enc_l\": 1, \"gra_enc_h\": 4, \"gru_l\": 1, \"gru_h\": 8})\n",
    "# model_tr_summary_df = mts_corr_ad_tr_proc_est(log_path_list1, {\"corr_info\": \"corr_s1_w10\", \"gra_enc_l\": 5, \"gru_l\": 1, \"gru_h\": 8})\n",
    "# model_tr_summary_df = mts_corr_ad_tr_proc_est(log_path_list1, {\"corr_info\": \"corr_s1_w10\", \"gra_enc_l\": 5, \"gra_enc_h\": 16, \"filt_mode\": \"keep_strong\", \"graph_enc\":\"GineEncoder\"}, plot_pic=True)\n",
    "# model_tr_summary_df = mts_corr_ad_tr_proc_est(log_path_list1, {\"corr_info\": \"corr_s1_w10\", \"loss_fns\": str(['MSELoss()', 'discr_loss'])}, plot_pic=True)\n",
    "# model_tr_summary_df = mts_corr_ad_tr_proc_est(log_path_list2, {\"corr_info\": \"corr_s1_w10\", \"loss_fns\": str(['MSELoss()'])}, plot_pic=True)\n",
    "model_tr_summary_df = gae_tr_proc_est(log_path_list2, {}, plot_pic=True)\n",
    "filt_model_tr_summary_df = model_tr_summary_df.loc[::, [\"opt_lr\", \"opt_weight_decay\", 'gra_enc_weight_l2_reg_lambda', \"drop_pos\", \"drop_p\", \"gra_enc_aggr\", \"gra_enc_l\", \"gra_enc_h\", \"max_tr_edge_acc\", \"max_val_edge_acc\"]]\n",
    "filt_model_tr_summary_df = filt_model_tr_summary_df.sort_values([\"opt_weight_decay\", \"drop_p\", \"opt_lr\", \"gra_enc_aggr\", \"gra_enc_l\", \"gra_enc_h\", \"max_tr_edge_acc\", \"max_val_edge_acc\"], ascending=False)\n",
    "filt_model_tr_summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

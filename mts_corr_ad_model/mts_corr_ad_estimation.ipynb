{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b2c178-aa69-4c4c-8ac1-90ba2563a03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 405 ms (started: 2023-03-03 15:59:17 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pformat, pprint\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import dynamic_yaml\n",
    "import yaml\n",
    "\n",
    "logging.basicConfig(format='%(levelname)-8s [%(filename)s] %(message)s',\n",
    "                    level=logging.INFO)\n",
    "matplotlib_logger = logging.getLogger(\"matplotlib\")\n",
    "matplotlib_logger.setLevel(logging.ERROR)\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e45d9e3-28b5-47a9-9560-c5c4e4a433c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Find the most differ graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8cba67d-92de-4d4f-9fad-89660ae90268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [2586445745.py] ===== file_name basis:sp500_20082017_corr_ser_reg_corr_mat_hrchy_11_cluster-train_train =====\n",
      "INFO     [2586445745.py] train_arr.shape: (2247, 66, 66)\n",
      "INFO     [2586445745.py] train_diff_arr.shape: (2235, 66, 66)\n",
      "INFO     [2586445745.py] train_arr[0][0][:5]: \n",
      "[ 1.         -0.7845055  -0.35839325  0.23613496  0.03113716]\n",
      "INFO     [2586445745.py] max_difference index of train_arr: 1902\n",
      "INFO     [2586445745.py] train_diff_arr[1902][0]: \n",
      "[ 0.          1.0869076   0.80756148  1.10147876  0.27583836  1.4311462\n",
      "  0.31798946  0.77423705  1.49131504  0.06400973  0.35000056  1.02577531\n",
      "  1.54352727  1.31498903  0.71837798  1.37400844  0.53681407  1.7463089\n",
      "  1.50096265  0.55053766  0.14724983  1.23417145  1.64226315  1.54879715\n",
      "  1.8150735   1.3664364   1.2108747   0.38212797  0.62011885  1.26466605\n",
      "  0.10248986  1.46270668  0.23049925  0.21841866  1.6698941   1.70031337\n",
      "  1.75067461  1.8054871   0.2055773   0.15378154  0.24515754  0.01484384\n",
      "  1.7717906   1.38432037  0.7822887   0.4782894   0.03289954  1.7230563\n",
      "  0.55196813  0.37387385 -0.16031051  1.39184639  0.37748157  0.48425672\n",
      "  1.09877191  1.53314972  0.13842196  0.25321023  0.18714564 -0.00925254\n",
      "  1.4719439  -0.0415034   1.75451446  0.25031685  1.44172274  1.37178004]\n",
      "INFO     [2586445745.py] train_arr[1902][0]: \n",
      "[ 1.         -0.19251946  0.15294836 -0.11165966  0.71004504 -0.435997\n",
      "  0.6558196   0.22110312 -0.55191934  0.8987652   0.63092434 -0.04919196\n",
      " -0.5531316  -0.34571618  0.26206556 -0.40689984  0.41732928 -0.9308405\n",
      " -0.64681065  0.42882884  0.84205157 -0.24409525 -0.71424955 -0.59141195\n",
      " -0.8413064  -0.4919742  -0.2150695   0.5917798   0.37391445 -0.68525875\n",
      "  0.88279164 -0.48047248  0.73232925  0.7241134  -0.6801586  -0.72492427\n",
      " -0.76324964 -0.8107647   0.7758371   0.808654    0.73116446  0.8697962\n",
      " -0.8043782  -0.40068257  0.16705707  0.5150674   0.7962047  -0.8217475\n",
      "  0.43587607  0.54891825  0.91347474 -0.46093103  0.58346283  0.49162492\n",
      " -0.16822378 -0.54492205  0.84866124  0.70204467  0.80147696  0.884117\n",
      " -0.5226105   0.8888677  -0.77459466  0.7042985  -0.45784664 -0.3899625 ]\n",
      "INFO     [2586445745.py] train_arr[1914][0]: \n",
      "[1.         0.89438814 0.96050984 0.9898191  0.9858834  0.9951492\n",
      " 0.97380906 0.99534017 0.9393957  0.96277493 0.9809249  0.97658336\n",
      " 0.99039567 0.96927285 0.98044354 0.9671086  0.95414335 0.8154684\n",
      " 0.854152   0.9793665  0.9893014  0.9900762  0.9280136  0.9573852\n",
      " 0.9737671  0.8744622  0.9958052  0.97390777 0.9940333  0.5794073\n",
      " 0.9852815  0.9822342  0.9628285  0.94253206 0.9897355  0.9753891\n",
      " 0.98742497 0.9947224  0.9814144  0.96243554 0.976322   0.88464004\n",
      " 0.9674124  0.9836378  0.94934577 0.9933568  0.82910424 0.9013088\n",
      " 0.9878442  0.9227921  0.75316423 0.93091536 0.9609444  0.97588164\n",
      " 0.93054813 0.98822767 0.9870832  0.9552549  0.9886226  0.87486446\n",
      " 0.9493334  0.8473643  0.9799198  0.95461535 0.9838761  0.98181754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 159 ms (started: 2023-03-03 15:59:17 +08:00)\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/workspace/correlation-change-predict/ywt_library\")\n",
    "current_dir = Path(__file__).parent\n",
    "data_config_path = current_dir/\"../config/data_config.yaml\"\n",
    "with open(data_config_path) as f:\n",
    "    data = dynamic_yaml.load(f)\n",
    "    data_cfg = yaml.full_load(dynamic_yaml.dump(data))\n",
    "\n",
    "# ## Data implement & output setting & testset setting\n",
    "# data implement setting\n",
    "data_implement = \"SP500_20082017_CORR_SER_REG_CORR_MAT_HRCHY_11_CLUSTER\"  # watch options by operate: logging.info(data_cfg[\"DATASETS\"].keys())\n",
    "# train set setting\n",
    "train_items_setting = \"-train_train\"  # -train_train|-train_all\n",
    "# setting of name of output files and pictures title\n",
    "output_file_name = data_cfg[\"DATASETS\"][data_implement]['OUTPUT_FILE_NAME_BASIS'] + train_items_setting\n",
    "# setting of output files\n",
    "logging.info(f\"===== file_name basis:{output_file_name} =====\")\n",
    "graph_data_dir = Path(data_cfg[\"DIRS\"][\"PIPELINE_DATA_DIR\"])/f\"{output_file_name}-graph_data\"\n",
    "graph_arr = np.load(graph_data_dir/f\"corr_s1_w10_graph.npy\")  # each graph consist of 66 node & 66^2 edges\n",
    "\n",
    "stride = 12\n",
    "train_arr = graph_arr[:int(len(graph_arr)*0.9)]\n",
    "val_arr = graph_arr[int(len(graph_arr)*0.9):int(len(graph_arr)*0.95)]\n",
    "test_arr = graph_arr[int(len(graph_arr)*0.95):]\n",
    "train_diff_arr = train_arr[stride:] - train_arr[:-stride] # this is what I want\n",
    "max_diff_ind = np.argmax(train_diff_arr.sum(axis=1).sum(axis=1))\n",
    "logging.info(f\"train_arr.shape: {train_arr.shape}\")\n",
    "logging.info(f\"train_diff_arr.shape: {train_diff_arr.shape}\")\n",
    "logging.info(f\"train_arr[0][0][:5]: \\n{train_arr[0][0][:5]}\")\n",
    "logging.info(f\"max_difference index of train_arr: {max_diff_ind}\")\n",
    "logging.info(f\"train_diff_arr[{max_diff_ind}][0]: \\n{train_diff_arr[max_diff_ind][0]}\")\n",
    "logging.info(f\"train_arr[{max_diff_ind}][0]: \\n{train_arr[max_diff_ind][0]}\")\n",
    "logging.info(f\"train_arr[{max_diff_ind+stride}][0]: \\n{train_arr[max_diff_ind+stride][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bd00b-5f02-45ab-84f7-4f532d108249",
   "metadata": {},
   "source": [
    "# Draw the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c4d0a4-4862-400f-aee9-5ee1d5a7f30e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.06 ms (started: 2023-03-03 15:59:24 +08:00)\n"
     ]
    }
   ],
   "source": [
    "def mts_corr_ad_estimation(log_path_list: list, filter_dict: dict):\n",
    "    model_info = {\"gin_l\": None, \"gin_h\": None}\n",
    "    try:\n",
    "        for log_path in log_path_list:\n",
    "            with open(log_path, \"r\") as source:\n",
    "                log_dict = json.load(source)\n",
    "\n",
    "            if model_str := log_dict.get('model_structure'):\n",
    "                gin_l = len(re.findall(\"\\(\\d\\)\\:\\s.*Conv\", model_str))\n",
    "                gin_h = int(re.search(\"(\\(\\d\\)\\:\\s.*Conv.*\\n.*)(out_features\\=)(\\d*)\", model_str).group(3))\n",
    "                gru_l = int(re.search(\"(\\(gru1\\)\\:.*)(num_layers\\=)(\\d*)\", model_str)[0][-1] if re.search(\"(\\(gru1\\)\\:.*)(num_layers\\=)(\\d*)\", model_str) else 1)\n",
    "                gru_h = int(re.search(\"(\\(gru1\\)\\:\\sGRU\\(\\d*\\,)\\s(\\d*)\", model_str).group(2))\n",
    "            else:\n",
    "                gin_l = None\n",
    "                gin_h = None\n",
    "                gru_l = None\n",
    "                gru_h = None\n",
    "            corr_info = [p for p in log_path.parts if p.startswith(\"corr\")][0]\n",
    "            best_epoch = log_dict['best_val_epoch'] if log_dict.get('best_val_epoch') else 500\n",
    "            min_val_loss = min(log_dict['val_loss_history'])\n",
    "            tr_batch = log_dict.get('train_batch') if log_dict.get('train_batch') else None\n",
    "            batchs_per_epoch = log_dict.get('batchs_per_epoch')\n",
    "            tr_loss = log_dict.get('train_loss_history')\n",
    "            val_loss = log_dict.get('val_loss_history')\n",
    "            # pred_embeds = np.array(log_dict.get('graph_embeds_history').get('graph_embeds_pred')[:batchs_per_epoch*2]\\\n",
    "            #                        + [([np.nan]*(gin_l*gin_h)) for _ in range(20)]\\\n",
    "            #                        + log_dict.get('graph_embeds_history').get('graph_embeds_pred')[-batchs_per_epoch*2:])\n",
    "            # y_embeds = np.array(log_dict.get('graph_embeds_history').get('y_graph_embeds')[:batchs_per_epoch*2]\\\n",
    "            #                     + [([np.nan]*(gin_l*gin_h)) for _ in range(20)]\\\n",
    "            #                     + log_dict.get('graph_embeds_history').get('y_graph_embeds')[-batchs_per_epoch*2:])\n",
    "            # if corr_info != \"corr_s1_w10\" or gin_l != 1 or gin_h != 3 or gru_l != 1 or gru_h != 8:\n",
    "            # if corr_info != \"corr_s1_w10\" or tr_batch != 12:\n",
    "                # continue\n",
    "            # logging.info(f\"file_name:{log_path.parts[-1]}\")\n",
    "            # logging.info(f'{corr_info} with tr_batch({tr_batch}) input to model with gin_l{gin_l}-gin_h{gin_h}-gru_l{gru_l}-gru_h{gru_h}; min val-loss:{min_val_loss:8f}')\n",
    "            if corr_info == \"corr_s1_w10\" and gin_l == 1 and gin_h == 3 and gru_l == 1 and gru_h == 8:\n",
    "            # if corr_info == \"corr_s1_w10\" and tr_batch == 12:\n",
    "                logging.info(f\"file_name:{log_path.parts[-1]}\")\n",
    "                logging.info(f'{corr_info} with tr_batch({tr_batch}) input to model with gin_l{gin_l}-gin_h{gin_h}-gru_l{gru_l}-gru_h{gru_h}; min val-loss:{min_val_loss:8f}')\n",
    "            else:\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(log_path)\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def plot_estimation():\n",
    "    # plot results\n",
    "    fig, axs = plt.subplots(ncols=2, nrows=6, figsize=(25,50))\n",
    "    fig.suptitle(f'{corr_info} with tr_batch({tr_batch}) input to model with gin_l{gin_l}-gin_h{gin_h}-gru_l{gru_l}-gru_h{gru_h}; min val-loss:{min_val_loss:8f}', fontsize=30)\n",
    "    gs = axs[0, 0].get_gridspec()\n",
    "    # remove the upper axes\n",
    "    for ncol in range(2):\n",
    "        for ax in axs[3:, ncol]:\n",
    "            ax.remove()\n",
    "    axbig = fig.add_subplot(gs[3:, :2])\n",
    "    axbig.set_xticks([]); axbig.set_yticks([])\n",
    "    axbig.annotate(text=f\"{str(model_str)}\",\n",
    "                   xy=(0.15, 0.5), bbox={'facecolor': 'green', 'alpha': 0.4, 'pad': 5},\n",
    "                   fontsize=20, fontfamily='monospace', xycoords='axes fraction', va='center')\n",
    "    axs[0, 0].plot(tr_loss)\n",
    "    axs[0, 1].plot(val_loss)\n",
    "    axs[1, 0].plot(tr_loss[max(0, best_epoch-100):max(201, best_epoch+101)])\n",
    "    axs[1, 1].plot(tr_loss[max(0, best_epoch-100):max(201, best_epoch+101)])\n",
    "    axs[2, 0].plot(pred_embeds, linewidth=5, alpha=0.3)\n",
    "    axs[2, 0].axvline(x=batchs_per_epoch, ymin=pred_embeds[~np.isnan(pred_embeds)].min(), ymax=pred_embeds[~np.isnan(pred_embeds)].max(),\n",
    "                      color='k', linewidth=5, linestyle='--', alpha=0.3)\n",
    "    axs[2, 0].axvline(x=batchs_per_epoch*3+20, ymin=pred_embeds[~np.isnan(pred_embeds)].min(), ymax=pred_embeds[~np.isnan(pred_embeds)].max(),\n",
    "                      color='k', linewidth=5, linestyle='--', alpha=0.3)\n",
    "    axs[2, 1].plot(y_embeds, linewidth=5, alpha=0.3)\n",
    "    axs[2, 1].axvline(x=batchs_per_epoch, ymin=y_embeds[~np.isnan(y_embeds)].min(), ymax=y_embeds[~np.isnan(y_embeds)].max(),\n",
    "                      color='k', linewidth=5, linestyle='--', alpha=0.3)\n",
    "    axs[2, 1].axvline(x=batchs_per_epoch*3+20, ymin=y_embeds[~np.isnan(y_embeds)].min(), ymax=y_embeds[~np.isnan(y_embeds)].max(),\n",
    "                      color='k', linewidth=5, linestyle='--', alpha=0.3)\n",
    "    axs[0, 0].set_title('train_loss_history', fontsize=30)\n",
    "    axs[0, 1].set_title('val_loss_history', fontsize=30)\n",
    "    axs[1, 0].set_title(f\"train_loss_history-epoch{(max(0, best_epoch-100), max(200, best_epoch+100))}\", fontsize=30)\n",
    "    axs[1, 1].set_title(f\"val_loss_history-epoch{(max(0, best_epoch-100), max(200, best_epoch+100))}\", fontsize=30)\n",
    "    axs[2, 0].set_title(f'pred_embeds-[{pred_embeds.shape[1]}]', fontsize=30)\n",
    "    axs[2, 1].set_title(f'y_embeds-[{y_embeds.shape[1]}]', fontsize=30)\n",
    "    axs[1, 0].set_xticks(ticks=range(0, 201, 20), labels=[f\"{x:02d}\" for x in range(max(0, best_epoch-100), max(201, best_epoch+101), 20)])\n",
    "    axs[1, 1].set_xticks(ticks=range(0, 201, 20), labels=[f\"{x:02d}\" for x in range(max(0, best_epoch-100), max(201, best_epoch+101), 20)])\n",
    "    for ax in axs.ravel():\n",
    "        ax.yaxis.offsetText.set_fontsize(30)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "    fig.tight_layout(rect=(0, 0, 1, 0.97))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87825fad-c2a3-4c17-af2d-7aa3edc0bf35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO     [1519991322.py] file_name:epoch_983-20230227170140.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(48) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:13.127180\n",
      "INFO     [1519991322.py] file_name:epoch_674-20230227021740.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(12) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:0.000029\n",
      "INFO     [1519991322.py] file_name:epoch_371-20230227194116.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(4) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:0.009373\n",
      "INFO     [1519991322.py] file_name:epoch_859-20230227185254.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(24) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:0.604734\n",
      "INFO     [1519991322.py] file_name:epoch_4871-20230224171155.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(48) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:0.000044\n",
      "INFO     [1519991322.py] file_name:epoch_2297-20230224234740.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(4) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:0.000002\n",
      "INFO     [1519991322.py] file_name:epoch_1943-20230224192346.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(24) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:0.002132\n",
      "INFO     [1519991322.py] file_name:epoch_385-20230218143745.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(12) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:0.000003\n",
      "INFO     [1519991322.py] file_name:epoch_4999.json\n",
      "INFO     [1519991322.py] corr_s1_w10 with tr_batch(12) input to model with gin_l1-gin_h3-gru_l1-gru_h8; min val-loss:0.000041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.6 s (started: 2023-03-03 15:59:25 +08:00)\n"
     ]
    }
   ],
   "source": [
    "mts_corr_model_log_dir = Path(\"./save_models/sp500_20082017_corr_ser_reg_corr_mat_hrchy_11_cluster-train_train/\")\n",
    "#log_path_list = mts_corr_model_log_dir.glob(\"./*[!deprecated][!.ipynb_checkpoints]*/train_logs/*[!.ipynb_checkpoints]*[.json]\")\n",
    "log_path_list = mts_corr_model_log_dir.glob(\"./**/train_logs/*[!.ipynb_checkpoints]*[.json]\")\n",
    "# log_path_list = mts_corr_model_log_dir.glob(\"./**/train_logs/*[.json]\")\n",
    "# pprint(list(log_path_list))\n",
    "\n",
    "mts_corr_ad_estimation(log_path_list, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfee75-07a0-4224-8f20-0bd1a70cd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_log_p = mts_corr_model_log_dir/f\"corr_s1_w10/train_logs/epoch_754-20230227112450.json\"\n",
    "\n",
    "with open(specific_log_p, \"r\") as source:\n",
    "    log_dict = json.load(source)\n",
    "\n",
    "if log_dict.get('model_structure'):\n",
    "    gin_l = len(re.findall(\"\\(\\d\\)GINConv\", log_dict.get('model_structure')))\n",
    "    gin_h = int(re.search(\"(\\(\\d\\)\\:\\sGINConv.*\\n.*)(out_features\\=)(\\d*)\", log_dict.get('model_structure')).group(3))\n",
    "    gru_l = int(re.search(\"(\\(gru1\\)\\:.*)(num_layers\\=)(\\d*)\", log_dict.get('model_structure'))[0][-1] if re.search(\"(\\(gru1\\)\\:.*)(num_layers\\=)(\\d*)\", log_dict.get('model_structure')) else 1)\n",
    "    gru_h = int(re.search(\"(\\(gru1\\)\\:\\sGRU\\(\\d*\\,)\\s(\\d*)\", log_dict.get('model_structure')).group(2))\n",
    "else:\n",
    "    gin_l = None\n",
    "    gin_h = None\n",
    "    gru_l = None\n",
    "    gru_h = None\n",
    "corr_info = [p for p in specific_log_p.parts if p.startswith(\"corr\")][0]\n",
    "best_epoch = log_dict['best_val_epoch'] if log_dict.get('best_val_epoch') else 500\n",
    "min_val_loss = min(log_dict['val_loss_history'])\n",
    "tr_batch = log_dict.get('train_batch') if log_dict.get('train_batch') else None\n",
    "batchs_per_epoch = log_dict.get('batchs_per_epoch')\n",
    "tr_loss = log_dict.get('train_loss_history')\n",
    "val_loss = log_dict.get('val_loss_history')\n",
    "pred_embeds = np.array(log_dict.get('graph_embeds_history').get('graph_embeds_pred')[:batchs_per_epoch*2]\\\n",
    "                       + [([np.nan]*(gin_l*gin_h)) for _ in range(20)]\\\n",
    "                       + log_dict.get('graph_embeds_history').get('graph_embeds_pred')[-batchs_per_epoch*2:])\n",
    "y_embeds = np.array(log_dict.get('graph_embeds_history').get('y_graph_embeds')[:batchs_per_epoch*2]\\\n",
    "                    + [([np.nan]*(gin_l*gin_h)) for _ in range(20)]\\\n",
    "                    + log_dict.get('graph_embeds_history').get('y_graph_embeds')[-batchs_per_epoch*2:])\n",
    "plt.figure(figsize=(14.5, 8))\n",
    "plt.plot(y_embeds, linewidth=5, alpha=0.3)\n",
    "plt.axvline(x=batchs_per_epoch, ymin=y_embeds[~np.isnan(y_embeds)].min(), ymax=y_embeds[~np.isnan(y_embeds)].max(),\n",
    "                  color='k', linewidth=5, linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=batchs_per_epoch*3+20, ymin=y_embeds[~np.isnan(y_embeds)].min(), ymax=y_embeds[~np.isnan(y_embeds)].max(),\n",
    "                  color='k', linewidth=5, linestyle='--', alpha=0.3)\n",
    "plt.annotate(text=f\"188\", xy=(0.19, 0.5),\n",
    "             bbox={'facecolor': 'gray', 'alpha': 0.4, 'pad': 5},\n",
    "             fontsize=20, fontfamily='monospace', xycoords='axes fraction', va='center')\n",
    "plt.annotate(text=f\"187811\", xy=(0.77, 0.5),\n",
    "             bbox={'facecolor': 'gray', 'alpha': 0.4, 'pad': 5},\n",
    "             fontsize=20, fontfamily='monospace', xycoords='axes fraction', va='center')\n",
    "plt.title(f'y_embeds-[{y_embeds.shape[1]}]', fontsize=30)\n",
    "xticks_label = list(range(0, 301, 100)) + list(range(187600, 188001, 100))\n",
    "plt.xticks(ticks=list(range(0, 801, 100)), labels=xticks_label, fontsize=18)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee47b6f-8565-4e2e-b058-b311de672224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
